{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6Tx9pXZq5tVCVGZqyIoo4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alikaiser12/AI/blob/main/Rizwan_recipe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpxaE_Hj6Fro",
        "outputId": "7d5b78ff-ce19-472f-b8c8-63ab2d00c2fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kq6pvpY06JR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# One-cell Colab script:\n",
        "# Recipe→Property predictor + Forward optimization to hit target specs\n",
        "# Works with stress–strain columns like:\n",
        "#   Strain(%)_Cel10_e, Stress(kPa)_Cel10_e, ...\n",
        "# If you already have true formulation columns (e.g., monomer%, crosslinker%), set RECIPE_FEATURES below.\n",
        "# ================================\n",
        "!pip -q install scikit-learn pandas numpy scipy\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import Dict, Tuple, Optional\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "from scipy.optimize import differential_evolution\n",
        "\n",
        "# ========= CONFIG (edit these) =========\n",
        "DATA_PATH = \"/content/drive/MyDrive/AI Training/paam_hydrogel_stress_strain_data_v2.xlsx\"  # <-- upload or mount Drive and set the path\n",
        "\n",
        "# If you have explicit formulation columns in your sheet (e.g., 'monomer_wt%', 'crosslinker_wt%', ...), put them here:\n",
        "RECIPE_FEATURES: list = []   # e.g., [\"monomer_wt%\", \"crosslinker_wt%\", \"initiator_wt%\", \"temp_C\", \"cure_min\"]\n",
        "\n",
        "# Choose which properties to target. Provide *any subset*; others will be ignored in the objective.\n",
        "# Common property keys computed by this script:\n",
        "#   \"E0_5_kPa\",\"E5_10_kPa\",\"TanE10_kPa\",\"Yield_strain_frac\",\"Yield_stress_kPa\",\n",
        "#   \"Resilience_kJ_m3\",\"UTS_kPa\",\"Strain_UTS_frac\",\"Fracture_strain_frac\",\n",
        "#   \"Fracture_stress_kPa\",\"Toughness_kJ_m3\",\"Stress@5%_kPa\",\"Stress@10%_kPa\",\n",
        "#   \"Stress@15%_kPa\",\"Stress@20%_kPa\",\"Secant_0_15_kPa\"\n",
        "TARGETS: Dict[str, float] = {\n",
        "    \"UTS_kPa\": 90.0,            # example: optimize for UTS only\n",
        "    # \"Toughness_kJ_m3\": 7.0,   # add more targets if you want\n",
        "    # \"Strain_UTS_frac\": 0.16,\n",
        "}\n",
        "\n",
        "# Optimization settings (tweak if needed)\n",
        "DE_MAXITER = 180\n",
        "DE_POPSIZE = 18\n",
        "# ======================================\n",
        "\n",
        "# ---------- Helpers for stress–strain parsing ----------\n",
        "def find_pairs(df: pd.DataFrame) -> Tuple[Dict[str, str], Dict[str, str], list]:\n",
        "    strain_cols = [c for c in df.columns if c.lower().startswith(\"strain\")]\n",
        "    stress_cols = [c for c in df.columns if c.lower().startswith(\"stress\")]\n",
        "    def lab(c): return c.split(\"_\", 1)[1] if \"_\" in c else None\n",
        "    labels_strain = {lab(c): c for c in strain_cols if lab(c) is not None}\n",
        "    labels_stress = {lab(c): c for c in stress_cols if lab(c) is not None}\n",
        "    labels = sorted(set(labels_strain).intersection(labels_stress))\n",
        "    return labels_strain, labels_stress, labels\n",
        "\n",
        "def to_fraction(eps_raw: np.ndarray) -> np.ndarray:\n",
        "    # Your data is like 0, 500, 1000 ⇒ 0.0%, 5.0%, 10.0%. Convert to strain fraction.\n",
        "    return (eps_raw.astype(float) / 100.0) / 100.0\n",
        "\n",
        "def ensure_sorted(eps: np.ndarray, sig: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    idx = np.argsort(eps)\n",
        "    return eps[idx], sig[idx]\n",
        "\n",
        "def interp_curve(eps: np.ndarray, sig: np.ndarray):\n",
        "    x = np.asarray(eps, float); y = np.asarray(sig, float)\n",
        "    lo, hi = float(x.min()), float(x.max())\n",
        "    def f(xq):\n",
        "        xq = np.asarray(xq, float)\n",
        "        return np.interp(np.clip(xq, lo, hi), x, y)\n",
        "    return f, (lo, hi)\n",
        "\n",
        "def linear_fit_window(eps: np.ndarray, sig: np.ndarray, a: float, b: float):\n",
        "    if b <= a: return None\n",
        "    f, (lo, hi) = interp_curve(eps, sig)\n",
        "    a, b = max(lo, a), min(hi, b)\n",
        "    if b <= a: return None\n",
        "    xs = np.linspace(a, b, 20); ys = f(xs)\n",
        "    X = np.vstack([xs, np.ones_like(xs)]).T\n",
        "    slope, intercept = np.linalg.lstsq(X, ys, rcond=None)[0]\n",
        "    return float(slope), float(intercept)\n",
        "\n",
        "def secant_modulus(f, a: float, b: float) -> Optional[float]:\n",
        "    if b <= a: return None\n",
        "    return float((f(b) - f(a)) / (b - a))\n",
        "\n",
        "def yield_offset(eps: np.ndarray, sig: np.ndarray, E_init: Optional[float], offset: float = 0.002):\n",
        "    if E_init is None or not np.isfinite(E_init): return None, None\n",
        "    f, (lo, hi) = interp_curve(eps, sig)\n",
        "    xs = np.linspace(lo, hi, 400)\n",
        "    g = f(xs) - E_init * (xs - offset)\n",
        "    s = np.sign(g); idx = np.where(np.diff(s) != 0)[0]\n",
        "    if len(idx) == 0: return None, None\n",
        "    i = idx[0]; x0, x1 = xs[i], xs[i+1]; y0, y1 = g[i], g[i+1]\n",
        "    eps_y = x0 if (y1 - y0) == 0 else x0 - y0 * (x1 - x0) / (y1 - y0)\n",
        "    return float(eps_y), float(f(eps_y))\n",
        "\n",
        "def integrate_toughness(eps: np.ndarray, sig: np.ndarray, up_to: Optional[float] = None) -> float:\n",
        "    f, (lo, hi) = interp_curve(eps, sig)\n",
        "    b = hi if up_to is None else max(lo, min(hi, up_to))\n",
        "    xs = np.linspace(lo, b, 400)\n",
        "    return float(np.trapz(f(xs), xs))\n",
        "\n",
        "def stress_at(f, p: float, lo: float, hi: float) -> Optional[float]:\n",
        "    x = p / 100.0\n",
        "    return float(f(x)) if lo <= x <= hi else np.nan\n",
        "\n",
        "def parse_recipe_from_label(label: str):\n",
        "    import re\n",
        "    m = re.match(r\"([A-Za-z]+)(\\d+)?\", label)\n",
        "    mat_type = m.group(1) if m else None\n",
        "    mat_level = float(m.group(2)) if (m and m.group(2)) else 0.0\n",
        "    return mat_type, mat_level\n",
        "\n",
        "# ---------- Load & derive properties ----------\n",
        "df = pd.read_excel(DATA_PATH)\n",
        "labels_strain, labels_stress, labels = find_pairs(df)\n",
        "\n",
        "records = []\n",
        "for lab in labels:\n",
        "    eps_raw = df[labels_strain[lab]].to_numpy(dtype=float)\n",
        "    sig_raw = df[labels_stress[lab]].to_numpy(dtype=float)\n",
        "    mask = np.isfinite(eps_raw) & np.isfinite(sig_raw)\n",
        "    eps_raw, sig_raw = eps_raw[mask], sig_raw[mask]\n",
        "    if len(eps_raw) < 3: continue\n",
        "\n",
        "    eps = to_fraction(eps_raw)\n",
        "    eps, sig = ensure_sorted(eps, sig_raw)\n",
        "    f, (lo, hi) = interp_curve(eps, sig)\n",
        "\n",
        "    # Moduli\n",
        "    E0_5  = (linear_fit_window(eps, sig, 0.00, 0.05) or (np.nan, np.nan))[0]\n",
        "    E5_10 = secant_modulus(f, 0.05, 0.10) if hi >= 0.10 else np.nan\n",
        "    TanE10 = (linear_fit_window(eps, sig, 0.08, 0.12) or (np.nan, np.nan))[0] if hi >= 0.12 else np.nan\n",
        "\n",
        "    # Yield via 0.2% offset, resilience\n",
        "    eps_y, sig_y = yield_offset(eps, sig, E0_5, offset=0.002)\n",
        "    resilience = integrate_toughness(eps, sig, up_to=eps_y) if eps_y is not None else (integrate_toughness(eps, sig, up_to=0.02) if hi >= 0.02 else np.nan)\n",
        "\n",
        "    # UTS & fracture\n",
        "    uts = float(sig.max()); i_uts = int(sig.argmax()); strain_uts = float(eps[i_uts])\n",
        "    frac_strain = float(eps.max()); frac_stress = float(sig[-1])\n",
        "    toughness = integrate_toughness(eps, sig, None)\n",
        "\n",
        "    # Probes\n",
        "    s5  = stress_at(f, 5, lo, hi)\n",
        "    s10 = stress_at(f, 10, lo, hi)\n",
        "    s15 = stress_at(f, 15, lo, hi)\n",
        "    s20 = stress_at(f, 20, lo, hi)\n",
        "    Sec_0_15 = secant_modulus(f, 0.00, 0.15) if hi >= 0.15 else np.nan\n",
        "\n",
        "    rec = {\n",
        "        \"label\": lab,\n",
        "        \"E0_5_kPa\": E0_5, \"E5_10_kPa\": E5_10, \"TanE10_kPa\": TanE10,\n",
        "        \"Yield_strain_frac\": eps_y if eps_y is not None else np.nan,\n",
        "        \"Yield_stress_kPa\":  sig_y if sig_y is not None else np.nan,\n",
        "        \"Resilience_kJ_m3\":  resilience,\n",
        "        \"UTS_kPa\": uts, \"Strain_UTS_frac\": strain_uts,\n",
        "        \"Fracture_strain_frac\": frac_strain, \"Fracture_stress_kPa\": frac_stress,\n",
        "        \"Toughness_kJ_m3\": toughness,\n",
        "        \"Stress@5%_kPa\": s5, \"Stress@10%_kPa\": s10, \"Stress@15%_kPa\": s15, \"Stress@20%_kPa\": s20,\n",
        "        \"Secant_0_15_kPa\": Sec_0_15,\n",
        "    }\n",
        "\n",
        "    # Recipe features\n",
        "    if RECIPE_FEATURES:\n",
        "        # Expect these columns to be present in df (per-row constants or per-label sheet)\n",
        "        # If your recipe data is in another sheet/table, merge it here on \"label\".\n",
        "        for c in RECIPE_FEATURES:\n",
        "            rec[c] = df[c].iloc[0] if c in df.columns else np.nan\n",
        "    else:\n",
        "        mat_type, mat_level = parse_recipe_from_label(lab)\n",
        "        rec[\"mat_type\"] = mat_type\n",
        "        rec[\"mat_level\"] = mat_level\n",
        "\n",
        "    records.append(rec)\n",
        "\n",
        "props_df = pd.DataFrame(records)\n",
        "\n",
        "# ---------- Build model dataset ----------\n",
        "# Choose X (recipe) and Y (properties). If RECIPE_FEATURES empty, use mat_type + mat_level from labels.\n",
        "if RECIPE_FEATURES:\n",
        "    Xcols = RECIPE_FEATURES\n",
        "else:\n",
        "    Xcols = [\"mat_type\", \"mat_level\"]\n",
        "\n",
        "Ycols_all = [\n",
        "    \"E0_5_kPa\",\"E5_10_kPa\",\"TanE10_kPa\",\"Yield_strain_frac\",\"Yield_stress_kPa\",\n",
        "    \"Resilience_kJ_m3\",\"UTS_kPa\",\"Strain_UTS_frac\",\"Fracture_strain_frac\",\n",
        "    \"Fracture_stress_kPa\",\"Toughness_kJ_m3\",\"Stress@5%_kPa\",\"Stress@10%_kPa\",\n",
        "    \"Stress@15%_kPa\",\"Stress@20%_kPa\",\"Secant_0_15_kPa\"\n",
        "]\n",
        "# Only keep Y columns that exist (depending on curve coverage)\n",
        "Ycols = [c for c in Ycols_all if c in props_df.columns]\n",
        "\n",
        "# Fill NaN values in target columns with the mean of existing values\n",
        "for col in Ycols:\n",
        "    if props_df[col].isnull().any():\n",
        "        mean_val = props_df[col].mean()\n",
        "        props_df[col].fillna(mean_val, inplace=True)\n",
        "\n",
        "data = props_df[Xcols + Ycols].dropna()\n",
        "\n",
        "if len(data) < 3:\n",
        "    raise RuntimeError(\"Not enough complete rows to train. Ensure recipe features are set or label parsing works and curves cover the needed ranges.\")\n",
        "\n",
        "\n",
        "X = data[Xcols].copy()\n",
        "Y = data[Ycols].copy()\n",
        "\n",
        "# ---------- Model pipeline ----------\n",
        "transformers = []\n",
        "if any(X[c].dtype == \"O\" for c in X.columns):  # has categorical\n",
        "    cat_cols = [c for c in X.columns if X[c].dtype == \"O\"]\n",
        "    transformers.append((\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols))\n",
        "num_cols = [c for c in X.columns if np.issubdtype(X[c].dtype, np.number)]\n",
        "if num_cols:\n",
        "    transformers.append((\"num\", StandardScaler(), num_cols))\n",
        "preprocess = ColumnTransformer(transformers) if transformers else \"passthrough\"\n",
        "\n",
        "base = RandomForestRegressor(n_estimators=500, random_state=42, n_jobs=-1)\n",
        "reg = Pipeline([(\"prep\", preprocess), (\"rf\", MultiOutputRegressor(base))])\n",
        "\n",
        "# Train / quick eval\n",
        "ts = 0.33 if len(X) >= 6 else 0.5 if len(X) >= 4 else 0.0\n",
        "if ts > 0:\n",
        "    X_tr, X_te, Y_tr, Y_te = train_test_split(X, Y, test_size=ts, random_state=42)\n",
        "else:\n",
        "    X_tr, Y_tr = X, Y\n",
        "    X_te, Y_te = X.iloc[:0], Y.iloc[:0]\n",
        "\n",
        "reg.fit(X_tr, Y_tr)\n",
        "\n",
        "if len(X_te) > 0:\n",
        "    Y_hat = reg.predict(X_te)\n",
        "    for i, col in enumerate(Y.columns):\n",
        "        r2 = r2_score(Y_te.iloc[:, i], Y_hat[:, i])\n",
        "        mae = mean_absolute_error(Y_te.iloc[:, i], Y_hat[:, i])\n",
        "        print(f\"[Test] {col:>18} | R2={r2:6.3f} MAE={mae:8.3f}\")\n",
        "else:\n",
        "    print(\"Trained on all rows (dataset small).\")\n",
        "\n",
        "# ---------- Forward optimization ----------\n",
        "# We only consider the properties listed in TARGETS.\n",
        "target_keys = [k for k in TARGETS.keys() if k in Y.columns]\n",
        "if len(target_keys) == 0:\n",
        "    raise ValueError(\"None of the TARGETS keys match the computed properties. Check your TARGETS dict.\")\n",
        "\n",
        "target_vec = np.array([TARGETS[k] for k in target_keys], float)\n",
        "\n",
        "# feature bounds for continuous variables\n",
        "bounds = []\n",
        "discrete_enums = {}  # for categorical enumeration\n",
        "for c in X.columns:\n",
        "    if np.issubdtype(X[c].dtype, np.number):\n",
        "        lo, hi = float(X[c].min()), float(X[c].max())\n",
        "        span = hi - lo if hi > lo else 1.0\n",
        "        bounds.append((lo - 0.05*span, hi + 0.05*span))\n",
        "    else:\n",
        "        # categorical -> enumerate later; mark placeholder in bounds to keep indexing aligned\n",
        "        discrete_enums[c] = sorted(X[c].unique().tolist())\n",
        "        bounds.append(None)\n",
        "\n",
        "# Build a template row for prediction\n",
        "def build_row(vec, cat_choice):\n",
        "    row = {}\n",
        "    j = 0\n",
        "    for i, col in enumerate(X.columns):\n",
        "        if col in discrete_enums:\n",
        "            row[col] = cat_choice[col]\n",
        "        else:\n",
        "            row[col] = float(vec[j]); j += 1\n",
        "    return pd.DataFrame([row])\n",
        "\n",
        "# Loss over selected targets (weighted MSE + MAPE)\n",
        "Y_slice_idx = [Y.columns.get_loc(k) for k in target_keys]\n",
        "var = np.var(Y.iloc[:, Y_slice_idx].values, axis=0)\n",
        "weights = 1.0 / np.where(var <= 1e-12, 1.0, var)\n",
        "\n",
        "def loss_from_row(dfrow):\n",
        "    yhat = reg.predict(dfrow)[0]\n",
        "    ysel = yhat[Y_slice_idx]\n",
        "    eps = 1e-8\n",
        "    mse = np.mean(weights * (ysel - target_vec)**2)\n",
        "    mape = np.mean(np.abs(ysel - target_vec) / (np.abs(target_vec) + eps))\n",
        "    return 0.5*mse + 0.5*mape, yhat\n",
        "\n",
        "best = {\"loss\": np.inf, \"row\": None, \"yhat\": None}\n",
        "\n",
        "# Enumerate categoricals (if any), optimize continuous with differential evolution\n",
        "cat_product = [{}]\n",
        "for c, vals in discrete_enums.items():\n",
        "    new = []\n",
        "    for base_choice in cat_product:\n",
        "        for v in vals:\n",
        "            choice = base_choice.copy(); choice[c] = v\n",
        "            new.append(choice)\n",
        "    cat_product = new\n",
        "\n",
        "if len(cat_product) == 0:\n",
        "    cat_product = [{}]\n",
        "\n",
        "for cat_choice in cat_product:\n",
        "    # collect bounds for this subspace\n",
        "    cont_bounds = [b for (b, col) in zip(bounds, X.columns) if col not in discrete_enums]\n",
        "\n",
        "    if len(cont_bounds) == 0:\n",
        "        # No continuous features — just evaluate categorical combo\n",
        "        dfrow = build_row([], cat_choice)\n",
        "        loss, yhat = loss_from_row(dfrow)\n",
        "        if loss < best[\"loss\"]:\n",
        "            best.update({\"loss\": loss, \"row\": dfrow, \"yhat\": yhat})\n",
        "        continue\n",
        "\n",
        "    def _wrap(x):\n",
        "        dfrow = build_row(x, cat_choice)\n",
        "        loss, _ = loss_from_row(dfrow)\n",
        "        return loss\n",
        "\n",
        "    result = differential_evolution(_wrap, bounds=cont_bounds, maxiter=DE_MAXITER, popsize=DE_POPSIZE, tol=1e-6, polish=True, seed=42)\n",
        "    dfrow = build_row(result.x, cat_choice)\n",
        "    loss, yhat = loss_from_row(dfrow)\n",
        "    if loss < best[\"loss\"]:\n",
        "        best.update({\"loss\": loss, \"row\": dfrow, \"yhat\": yhat})\n",
        "\n",
        "opt_recipe = best[\"row\"]\n",
        "opt_pred = pd.DataFrame([best[\"yhat\"]], columns=Y.columns)\n",
        "report = pd.concat({\"recipe_opt\": opt_recipe.reset_index(drop=True), \"predicted_props\": opt_pred[target_keys].reset_index(drop=True)}, axis=1)\n",
        "\n",
        "print(\"\\n=== Optimal recipe (for the specified TARGETS) ===\")\n",
        "display_cols = list(opt_recipe.columns)\n",
        "print(opt_recipe[display_cols].to_string(index=False))\n",
        "\n",
        "print(\"\\n=== Predicted properties on targets ===\")\n",
        "print(opt_pred[target_keys].to_string(index=False))\n",
        "\n",
        "# Save artifacts\n",
        "props_out = \"/content/derived_properties_table.csv\"\n",
        "opt_out = \"/content/optimal_recipe_and_predictions.csv\"\n",
        "props_df.to_csv(props_out, index=False)\n",
        "report.to_csv(opt_out, index=False)\n",
        "print(f\"\\nSaved:\\n  {props_out}\\n  {opt_out}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "N2IxmBFy6JZn",
        "outputId": "7ef24ffb-93fa-42b3-d411-c6089202e0cf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3831001079.py:101: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
            "  return float(np.trapz(f(xs), xs))\n",
            "/tmp/ipython-input-3831001079.py:199: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  props_df[col].fillna(mean_val, inplace=True)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Not enough complete rows to train. Ensure recipe features are set or label parsing works and curves cover the needed ranges.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3831001079.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Not enough complete rows to train. Ensure recipe features are set or label parsing works and curves cover the needed ranges.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Not enough complete rows to train. Ensure recipe features are set or label parsing works and curves cover the needed ranges."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Build model dataset (robust to sparse columns / NaNs) ----------\n",
        "# Choose X (recipe) and Y (properties). If RECIPE_FEATURES empty, use mat_type + mat_level from labels.\n",
        "if RECIPE_FEATURES:\n",
        "    Xcols = RECIPE_FEATURES\n",
        "else:\n",
        "    Xcols = [\"mat_type\", \"mat_level\"]\n",
        "\n",
        "# Which targets do you want to fit/optimize on?\n",
        "all_cols_available = set(props_df.columns)\n",
        "target_keys = [k for k in TARGETS.keys() if k in all_cols_available]\n",
        "\n",
        "if len(target_keys) == 0:\n",
        "    raise ValueError(\n",
        "        f\"None of your TARGETS {list(TARGETS.keys())} exist in computed properties. \"\n",
        "        f\"Available: {sorted(all_cols_available)}\"\n",
        "    )\n",
        "\n",
        "# Count how many non-NaN rows exist per requested target\n",
        "counts = {k: int(props_df[k].notna().sum()) for k in target_keys}\n",
        "print(\"Non-NaN rows per requested target:\", counts)\n",
        "\n",
        "# Keep only targets with at least 2 rows (so the model can learn something)\n",
        "Ycols = [k for k in target_keys if counts[k] >= 2]\n",
        "\n",
        "# If nothing qualifies, fall back to a single, common property such as UTS_kPa (if present)\n",
        "if len(Ycols) == 0:\n",
        "    if \"UTS_kPa\" in props_df.columns and props_df[\"UTS_kPa\"].notna().sum() >= 2:\n",
        "        print(\"No requested target has >=2 rows. Falling back to Y=['UTS_kPa'].\")\n",
        "        Ycols = [\"UTS_kPa\"]\n",
        "        target_keys = [\"UTS_kPa\"]\n",
        "        TARGETS = {\"UTS_kPa\": TARGETS.get(\"UTS_kPa\", float(props_df[\"UTS_kPa\"].median()))}\n",
        "    else:\n",
        "        # Print helpful diagnostics and stop\n",
        "        avail_counts = {c: int(props_df[c].notna().sum()) for c in [\n",
        "            \"UTS_kPa\",\"Toughness_kJ_m3\",\"Strain_UTS_frac\",\"E0_5_kPa\",\"Stress@5%_kPa\",\"Stress@10%_kPa\"\n",
        "        ] if c in props_df.columns}\n",
        "        raise RuntimeError(\n",
        "            \"Not enough complete rows for your selected targets. \"\n",
        "            f\"Try targeting a property with more coverage. Coverage snapshot: {avail_counts}\"\n",
        "        )\n",
        "\n",
        "use_cols = Xcols + Ycols\n",
        "data = props_df[use_cols].dropna(subset=Ycols)\n",
        "if len(data) < 2:\n",
        "    raise RuntimeError(\n",
        "        f\"After filtering to X={Xcols} and Y={Ycols}, \"\n",
        "        f\"only {len(data)} complete rows remain. \"\n",
        "        \"Remove sparsely available targets or expand your dataset.\"\n",
        "    )\n",
        "\n",
        "X = data[Xcols].copy()\n",
        "Y = data[Ycols].copy()\n",
        "\n",
        "# ---------- Model pipeline ----------\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "transformers = []\n",
        "cat_cols = [c for c in X.columns if X[c].dtype == \"O\"]\n",
        "num_cols = [c for c in X.columns if np.issubdtype(X[c].dtype, np.number)]\n",
        "\n",
        "if cat_cols:\n",
        "    transformers.append((\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols))\n",
        "if num_cols:\n",
        "    transformers.append((\"num\", StandardScaler(), num_cols))\n",
        "\n",
        "preprocess = ColumnTransformer(transformers) if transformers else \"passthrough\"\n",
        "\n",
        "base = RandomForestRegressor(n_estimators=500, random_state=42, n_jobs=-1)\n",
        "reg = Pipeline([(\"prep\", preprocess), (\"rf\", MultiOutputRegressor(base))])\n",
        "\n",
        "# Train / quick eval (handles tiny datasets)\n",
        "ts = 0.33 if len(X) >= 6 else 0.5 if len(X) >= 4 else 0.0\n",
        "if ts > 0:\n",
        "    X_tr, X_te, Y_tr, Y_te = train_test_split(X, Y, test_size=ts, random_state=42)\n",
        "else:\n",
        "    X_tr, Y_tr = X, Y\n",
        "    X_te, Y_te = X.iloc[:0], Y.iloc[:0]\n",
        "\n",
        "reg.fit(X_tr, Y_tr)\n",
        "\n",
        "if len(X_te) > 0:\n",
        "    Y_hat = reg.predict(X_te)\n",
        "    for i, col in enumerate(Y.columns):\n",
        "        r2 = r2_score(Y_te.iloc[:, i], Y_hat[:, i])\n",
        "        mae = mean_absolute_error(Y_te.iloc[:, i], Y_hat[:, i])\n",
        "        print(f\"[Test] {col:>18} | R2={r2:6.3f} MAE={mae:8.3f}\")\n",
        "else:\n",
        "    print(\"Trained on all rows (dataset small).\")\n",
        "\n",
        "# ---------- Forward optimization (only on your selected targets) ----------\n",
        "# bounds for continuous features; enumerate any categoricals\n",
        "bounds = []\n",
        "discrete_enums = {}\n",
        "for c in X.columns:\n",
        "    if np.issubdtype(X[c].dtype, np.number):\n",
        "        lo, hi = float(X[c].min()), float(X[c].max())\n",
        "        span = hi - lo if hi > lo else 1.0\n",
        "        bounds.append((lo - 0.05*span, hi + 0.05*span))\n",
        "    else:\n",
        "        discrete_enums[c] = sorted(X[c].unique().tolist())\n",
        "        bounds.append(None)\n",
        "\n",
        "def build_row(vec, cat_choice):\n",
        "    row = {}\n",
        "    j = 0\n",
        "    for i, col in enumerate(X.columns):\n",
        "        if col in discrete_enums:\n",
        "            row[col] = cat_choice[col]\n",
        "        else:\n",
        "            row[col] = float(vec[j]); j += 1\n",
        "    return pd.DataFrame([row])\n",
        "\n",
        "# assemble the target vector in the same order as Ycols\n",
        "target_vec = np.array([TARGETS[k] for k in Ycols], float)\n",
        "\n",
        "# weights for loss: inverse variance of Y-train slice to balance scales\n",
        "var = np.var(Y_tr[Ycols].values, axis=0) if len(Y_tr) > 0 else np.var(Y[Ycols].values, axis=0)\n",
        "weights = 1.0 / np.where(var <= 1e-12, 1.0, var)\n",
        "\n",
        "def loss_from_row(dfrow):\n",
        "    yhat = reg.predict(dfrow)[0]\n",
        "    # yhat aligns to Ycols order\n",
        "    eps = 1e-8\n",
        "    mse = np.mean(weights * (yhat - target_vec)**2)\n",
        "    mape = np.mean(np.abs(yhat - target_vec) / (np.abs(target_vec) + eps))\n",
        "    return 0.5*mse + 0.5*mape, yhat\n",
        "\n",
        "# enumerate categoricals; DE over continuous\n",
        "from scipy.optimize import differential_evolution\n",
        "best = {\"loss\": np.inf, \"row\": None, \"yhat\": None}\n",
        "\n",
        "cat_product = [{}]\n",
        "for c, vals in discrete_enums.items():\n",
        "    new = []\n",
        "    for base_choice in cat_product:\n",
        "        for v in vals:\n",
        "            tmp = base_choice.copy(); tmp[c] = v\n",
        "            new.append(tmp)\n",
        "    cat_product = new\n",
        "if len(cat_product) == 0:\n",
        "    cat_product = [{}]\n",
        "\n",
        "for cat_choice in cat_product:\n",
        "    cont_bounds = [b for (b, col) in zip(bounds, X.columns) if col not in discrete_enums]\n",
        "    if len(cont_bounds) == 0:\n",
        "        dfrow = build_row([], cat_choice)\n",
        "        loss, yhat = loss_from_row(dfrow)\n",
        "        if loss < best[\"loss\"]:\n",
        "            best.update({\"loss\": loss, \"row\": dfrow, \"yhat\": yhat})\n",
        "        continue\n",
        "\n",
        "    def _wrap(x):\n",
        "        dfrow = build_row(x, cat_choice)\n",
        "        loss, _ = loss_from_row(dfrow)\n",
        "        return loss\n",
        "\n",
        "    result = differential_evolution(_wrap, bounds=cont_bounds, maxiter=DE_MAXITER, popsize=DE_POPSIZE, tol=1e-6, polish=True, seed=42)\n",
        "    dfrow = build_row(result.x, cat_choice)\n",
        "    loss, yhat = loss_from_row(dfrow)\n",
        "    if loss < best[\"loss\"]:\n",
        "        best.update({\"loss\": loss, \"row\": dfrow, \"yhat\": yhat})\n",
        "\n",
        "opt_recipe = best[\"row\"]\n",
        "opt_pred = pd.DataFrame([best[\"yhat\"]], columns=Ycols)\n",
        "\n",
        "print(\"\\n=== Optimal recipe (for YOUR targets only) ===\")\n",
        "print(opt_recipe.to_string(index=False))\n",
        "print(\"\\n=== Predicted properties (on those targets) ===\")\n",
        "print(opt_pred.to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPuMMj2B7N83",
        "outputId": "c1c9c12b-3ddc-4b15-a416-95aedc15469f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non-NaN rows per requested target: {'UTS_kPa': 10}\n",
            "[Test]            UTS_kPa | R2=-0.526 MAE=  13.781\n",
            "\n",
            "=== Optimal recipe (for YOUR targets only) ===\n",
            "mat_type  mat_level\n",
            "     Cel  15.148414\n",
            "\n",
            "=== Predicted properties (on those targets) ===\n",
            "  UTS_kPa\n",
            "82.020833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(props_df.isna().mean().sort_values())  # fraction of NaNs per column\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJeAu_ZF7Og-",
        "outputId": "8361cf6f-b314-406c-bca6-3709a109fe27"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label                   0.0\n",
            "E0_5_kPa                0.0\n",
            "E5_10_kPa               0.0\n",
            "TanE10_kPa              0.0\n",
            "Yield_strain_frac       0.0\n",
            "Yield_stress_kPa        0.0\n",
            "Resilience_kJ_m3        0.0\n",
            "UTS_kPa                 0.0\n",
            "Strain_UTS_frac         0.0\n",
            "Fracture_strain_frac    0.0\n",
            "Fracture_stress_kPa     0.0\n",
            "Toughness_kJ_m3         0.0\n",
            "Stress@5%_kPa           0.0\n",
            "Stress@10%_kPa          0.0\n",
            "Stress@15%_kPa          0.0\n",
            "Secant_0_15_kPa         0.0\n",
            "mat_level               0.0\n",
            "mat_type                0.0\n",
            "Stress@20%_kPa          1.0\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# Single-cell: Composition design for target UTS (and others)\n",
        "# ============================\n",
        "!pip -q install numpy pandas scikit-learn scipy\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import Dict, Tuple, Optional, List\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "# ========== USER CONFIG ==========\n",
        "# 1) Stress–strain file (must have paired columns like Strain(%)_X and Stress(kPa)_X, where X is a label)\n",
        "DATA_PATH = \"/content/drive/MyDrive/AI Training/paam_hydrogel_stress_strain_data_v2.xlsx\"\n",
        "\n",
        "# 2) Composition source (choose ONE of the two):\n",
        "#    (A) Separate file (CSV or XLSX) with a table that contains 'label' + composition columns\n",
        "COMPOSITION_PATH = \"/content/composition_table.xlsx\"   # e.g., \"/content/recipe_table.csv\" or \"\"\n",
        "#    (B) OR a sheet *inside* DATA_PATH:\n",
        "COMPOSITION_SHEET = \"\"  # e.g., \"composition\" if you kept it in the same workbook\n",
        "\n",
        "# 3) Which columns in your composition table are the actual composition variables you want the optimizer to choose?\n",
        "#    Examples: wt% columns that sum to ~100, or molar ratios, etc. These must be numeric.\n",
        "#    If empty, the code will fall back to ('mat_type', 'mat_level') parsed from labels (coarse).\n",
        "COMPOSITION_COLS: List[str] = [\n",
        "    # \"monomer_wt%\", \"crosslinker_wt%\", \"initiator_wt%\", \"solvent_wt%\", \"salt_mM\"\n",
        "]\n",
        "\n",
        "# 4) Sum constraint for composition variables (e.g., sum of wt% must equal 100)\n",
        "#    Set to None if not applicable. Otherwise set a float like 100.0\n",
        "COMPOSITION_TOTAL = 100.0  # or None\n",
        "\n",
        "# 5) Targets (use any subset). Start with UTS only, then add more as needed.\n",
        "TARGETS: Dict[str, float] = {\n",
        "    \"UTS_kPa\": 90.0,\n",
        "    # \"Toughness_kJ_m3\": 7.0,\n",
        "    # \"Strain_UTS_frac\": 0.16,\n",
        "}\n",
        "# =================================\n",
        "\n",
        "# ======== Stress–strain utilities ========\n",
        "def find_pairs(df: pd.DataFrame) -> Tuple[Dict[str, str], Dict[str, str], list]:\n",
        "    strain_cols = [c for c in df.columns if c.lower().startswith(\"strain\")]\n",
        "    stress_cols = [c for c in df.columns if c.lower().startswith(\"stress\")]\n",
        "    def lab(c): return c.split(\"_\", 1)[1] if \"_\" in c else None\n",
        "    labels_strain = {lab(c): c for c in strain_cols if lab(c) is not None}\n",
        "    labels_stress = {lab(c): c for c in stress_cols if lab(c) is not None}\n",
        "    labels = sorted(set(labels_strain).intersection(labels_stress))\n",
        "    return labels_strain, labels_stress, labels\n",
        "\n",
        "def to_fraction(eps_raw: np.ndarray) -> np.ndarray:\n",
        "    # Your data pattern looks like: [0, 500, 1000, ...] -> 0.0%, 5.0%, 10.0% -> 0.0, 0.05, 0.10 (fraction)\n",
        "    return (eps_raw.astype(float)/100.0)/100.0\n",
        "\n",
        "def ensure_sorted(eps: np.ndarray, sig: np.ndarray):\n",
        "    idx = np.argsort(eps)\n",
        "    return eps[idx], sig[idx]\n",
        "\n",
        "def interp_curve(eps: np.ndarray, sig: np.ndarray):\n",
        "    x = np.asarray(eps, float); y = np.asarray(sig, float)\n",
        "    lo, hi = float(x.min()), float(x.max())\n",
        "    def f(xq):\n",
        "        xq = np.asarray(xq, float)\n",
        "        return np.interp(np.clip(xq, lo, hi), x, y)\n",
        "    return f, (lo, hi)\n",
        "\n",
        "def linear_fit_window(eps: np.ndarray, sig: np.ndarray, a: float, b: float):\n",
        "    if b <= a: return None\n",
        "    f, (lo, hi) = interp_curve(eps, sig)\n",
        "    a, b = max(lo, a), min(hi, b)\n",
        "    if b <= a: return None\n",
        "    xs = np.linspace(a, b, 20); ys = f(xs)\n",
        "    X = np.vstack([xs, np.ones_like(xs)]).T\n",
        "    slope, intercept = np.linalg.lstsq(X, ys, rcond=None)[0]\n",
        "    return float(slope), float(intercept)\n",
        "\n",
        "def secant_modulus(f, a: float, b: float):\n",
        "    if b <= a: return np.nan\n",
        "    return float((f(b) - f(a)) / (b - a))\n",
        "\n",
        "def yield_offset(eps: np.ndarray, sig: np.ndarray, E_init: Optional[float], offset: float = 0.002):\n",
        "    if E_init is None or not np.isfinite(E_init): return None, None\n",
        "    f, (lo, hi) = interp_curve(eps, sig)\n",
        "    xs = np.linspace(lo, hi, 400)\n",
        "    g = f(xs) - E_init*(xs - offset)\n",
        "    s = np.sign(g); idx = np.where(np.diff(s) != 0)[0]\n",
        "    if len(idx) == 0: return None, None\n",
        "    i = idx[0]; x0, x1 = xs[i], xs[i+1]; y0, y1 = g[i], g[i+1]\n",
        "    eps_y = x0 if (y1 - y0) == 0 else x0 - y0*(x1 - x0)/(y1 - y0)\n",
        "    return float(eps_y), float(f(eps_y))\n",
        "\n",
        "def integrate_toughness(eps: np.ndarray, sig: np.ndarray, up_to: Optional[float] = None) -> float:\n",
        "    f, (lo, hi) = interp_curve(eps, sig)\n",
        "    b = hi if up_to is None else max(lo, min(hi, up_to))\n",
        "    xs = np.linspace(lo, b, 400)\n",
        "    return float(np.trapz(f(xs), xs))\n",
        "\n",
        "def stress_at(f, p: float, lo: float, hi: float):\n",
        "    x = p/100.0\n",
        "    return float(f(x)) if lo <= x <= hi else np.nan\n",
        "\n",
        "def parse_label_recipe(label: str):\n",
        "    import re\n",
        "    m = re.match(r\"([A-Za-z]+)(\\d+)?\", label)\n",
        "    mat_type = m.group(1) if m else None\n",
        "    mat_level = float(m.group(2)) if (m and m.group(2)) else 0.0\n",
        "    return mat_type, mat_level\n",
        "\n",
        "# ======== Derive properties from curves ========\n",
        "def derive_properties_table(stress_strain_path: str) -> pd.DataFrame:\n",
        "    df = pd.read_excel(stress_strain_path)\n",
        "    labels_strain, labels_stress, labels = find_pairs(df)\n",
        "    rows = []\n",
        "    for lab in labels:\n",
        "        eps_raw = df[labels_strain[lab]].to_numpy(dtype=float)\n",
        "        sig_raw = df[labels_stress[lab]].to_numpy(dtype=float)\n",
        "        m = np.isfinite(eps_raw) & np.isfinite(sig_raw)\n",
        "        eps_raw, sig_raw = eps_raw[m], sig_raw[m]\n",
        "        if len(eps_raw) < 3: continue\n",
        "\n",
        "        eps = to_fraction(eps_raw)\n",
        "        eps, sig = ensure_sorted(eps, sig_raw)\n",
        "        f, (lo, hi) = interp_curve(eps, sig)\n",
        "\n",
        "        E0_5  = (linear_fit_window(eps, sig, 0.00, 0.05) or (np.nan, np.nan))[0]\n",
        "        E5_10 = secant_modulus(f, 0.05, 0.10) if hi >= 0.10 else np.nan\n",
        "        TanE10 = (linear_fit_window(eps, sig, 0.08, 0.12) or (np.nan, np.nan))[0] if hi >= 0.12 else np.nan\n",
        "        eps_y, sig_y = yield_offset(eps, sig, E0_5, offset=0.002)\n",
        "        resilience = integrate_toughness(eps, sig, up_to=eps_y) if eps_y is not None else (integrate_toughness(eps, sig, up_to=0.02) if hi >= 0.02 else np.nan)\n",
        "        uts = float(sig.max()); i_uts = int(sig.argmax()); strain_uts = float(eps[i_uts])\n",
        "        frac_strain = float(eps.max()); frac_stress = float(sig[-1])\n",
        "        toughness = integrate_toughness(eps, sig, None)\n",
        "        s5  = stress_at(f, 5, lo, hi); s10 = stress_at(f, 10, lo, hi)\n",
        "        s15 = stress_at(f, 15, lo, hi); s20 = stress_at(f, 20, lo, hi)\n",
        "        sec_0_15 = secant_modulus(f, 0.00, 0.15) if hi >= 0.15 else np.nan\n",
        "\n",
        "        mat_type, mat_level = parse_label_recipe(lab)\n",
        "        rows.append({\n",
        "            \"label\": lab, \"mat_type\": mat_type, \"mat_level\": mat_level,\n",
        "            \"E0_5_kPa\": E0_5, \"E5_10_kPa\": E5_10, \"TanE10_kPa\": TanE10,\n",
        "            \"Yield_strain_frac\": eps_y if eps_y is not None else np.nan,\n",
        "            \"Yield_stress_kPa\":  sig_y if sig_y is not None else np.nan,\n",
        "            \"Resilience_kJ_m3\":  resilience,\n",
        "            \"UTS_kPa\": uts, \"Strain_UTS_frac\": strain_uts,\n",
        "            \"Fracture_strain_frac\": frac_strain, \"Fracture_stress_kPa\": frac_stress,\n",
        "            \"Toughness_kJ_m3\": toughness,\n",
        "            \"Stress@5%_kPa\": s5, \"Stress@10%_kPa\": s10, \"Stress@15%_kPa\": s15, \"Stress@20%_kPa\": s20,\n",
        "            \"Secant_0_15_kPa\": sec_0_15\n",
        "        })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "props_df = derive_properties_table(DATA_PATH)\n",
        "if props_df.empty:\n",
        "    raise RuntimeError(\"No valid stress–strain pairs found. Check column names like Strain(%)_<label> and Stress(kPa)_<label>.\")\n",
        "\n",
        "# ======== Load composition table if provided ========\n",
        "def load_composition() -> pd.DataFrame:\n",
        "    comp_df = None\n",
        "    if COMPOSITION_PATH and Path(COMPOSITION_PATH).exists():\n",
        "        if COMPOSITION_PATH.lower().endswith(\".csv\"):\n",
        "            comp_df = pd.read_csv(COMPOSITION_PATH)\n",
        "        else:\n",
        "            comp_df = pd.read_excel(COMPOSITION_PATH)\n",
        "    elif COMPOSITION_SHEET:\n",
        "        comp_df = pd.read_excel(DATA_PATH, sheet_name=COMPOSITION_SHEET)\n",
        "    return comp_df\n",
        "\n",
        "comp_df = load_composition()\n",
        "\n",
        "# ======== Build modeling table ========\n",
        "if comp_df is not None and len(COMPOSITION_COLS) > 0 and all(c in comp_df.columns for c in COMPOSITION_COLS) and \"label\" in comp_df.columns:\n",
        "    MODE = \"composition\"\n",
        "    df_model = props_df.merge(comp_df[[\"label\"] + COMPOSITION_COLS], on=\"label\", how=\"inner\")\n",
        "    X = df_model[COMPOSITION_COLS].astype(float).copy()\n",
        "    # Optional: detect if columns are percentages that should sum to ~COMPOSITION_TOTAL\n",
        "    sum_close = None\n",
        "    if COMPOSITION_TOTAL is not None:\n",
        "        s = X[COMPOSITION_COLS].sum(axis=1)\n",
        "        sum_close = np.median(np.isclose(s, COMPOSITION_TOTAL, rtol=0.01, atol=1e-2))\n",
        "        print(f\"[Info] Median samples match sum≈{COMPOSITION_TOTAL}? -> {bool(sum_close)}\")\n",
        "else:\n",
        "    MODE = \"label_fallback\"\n",
        "    print(\"[Warn] No composition table recognized. Falling back to ('mat_type','mat_level') from labels.\")\n",
        "    # Encode mat_type as categorical + mat_level numeric\n",
        "    X = props_df[[\"mat_type\", \"mat_level\"]].copy()\n",
        "\n",
        "# Y: ONLY use the targets you care about (robust against NaNs in other properties)\n",
        "available = set(props_df.columns)\n",
        "target_keys = [k for k in TARGETS if k in available]\n",
        "if not target_keys:\n",
        "    raise ValueError(f\"None of your TARGETS {list(TARGETS.keys())} exist in derived properties. Available: {sorted(available)}\")\n",
        "Y = props_df[[\"label\"] + target_keys].dropna(subset=target_keys)\n",
        "\n",
        "# Align X and Y by label\n",
        "if MODE == \"composition\":\n",
        "    XY = df_model[[\"label\"] + COMPOSITION_COLS + target_keys].dropna(subset=target_keys + COMPOSITION_COLS)\n",
        "    X = XY[COMPOSITION_COLS].astype(float)\n",
        "    Y = XY[target_keys].astype(float)\n",
        "else:\n",
        "    XY = props_df[[\"label\", \"mat_type\", \"mat_level\"] + target_keys].dropna(subset=target_keys)\n",
        "    X = XY[[\"mat_type\", \"mat_level\"]].copy()\n",
        "    Y = XY[target_keys].astype(float)\n",
        "\n",
        "\n",
        "if len(X) < 2:\n",
        "    raise RuntimeError(\"Not enough rows to train. Ensure targets have at least 2 valid samples and composition columns are present (if using composition mode).\")\n",
        "\n",
        "# ======== Model pipeline ========\n",
        "transformers = []\n",
        "if MODE == \"composition\":\n",
        "    # all numeric\n",
        "    num_cols = X.columns.tolist()\n",
        "    preprocess = ColumnTransformer([(\"num\", StandardScaler(), num_cols)])\n",
        "else:\n",
        "    # mat_type categorical + mat_level numeric\n",
        "    cat_cols = [\"mat_type\"]\n",
        "    num_cols = [\"mat_level\"]\n",
        "    preprocess = ColumnTransformer([\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
        "        (\"num\", StandardScaler(), num_cols),\n",
        "    ])\n",
        "\n",
        "base = RandomForestRegressor(n_estimators=600, random_state=42, n_jobs=-1)\n",
        "reg = Pipeline([(\"prep\", preprocess), (\"rf\", MultiOutputRegressor(base))])\n",
        "\n",
        "ts = 0.33 if len(X) >= 6 else 0.0\n",
        "if ts > 0:\n",
        "    X_tr, X_te, Y_tr, Y_te = train_test_split(X, Y, test_size=ts, random_state=42)\n",
        "else:\n",
        "    X_tr, Y_tr = X, Y\n",
        "    X_te, Y_te = X.iloc[:0], Y.iloc[:0]\n",
        "\n",
        "reg.fit(X_tr, Y_tr)\n",
        "\n",
        "if len(X_te) > 0:\n",
        "    Y_hat = reg.predict(X_te)\n",
        "    print(\"=== Quick holdout ===\")\n",
        "    for i, col in enumerate(Y.columns):\n",
        "        print(f\"{col:>18}  R2={r2_score(Y_te.iloc[:, i], Y_hat[:, i]):6.3f}  MAE={mean_absolute_error(Y_te.iloc[:, i], Y_hat[:, i]):8.3f}\")\n",
        "else:\n",
        "    print(\"Trained on all rows (small dataset).\")\n",
        "\n",
        "# ======== Forward design: get composition (or knobs) for TARGETS ========\n",
        "# Build loss on your targets only\n",
        "tgt = np.array([TARGETS[k] for k in target_keys], float)\n",
        "\n",
        "# Separate bounds for numeric and handle categoricals\n",
        "bounds = []\n",
        "cont_cols = [c for c in X.columns if np.issubdtype(X[c].dtype, np.number)]\n",
        "cat_cols = [c for c in X.columns if X[c].dtype == \"O\"]\n",
        "discrete_enums = {c: sorted(X[c].unique().tolist()) for c in cat_cols}\n",
        "\n",
        "for c in cont_cols:\n",
        "    lo, hi = float(X[c].min()), float(X[c].max())\n",
        "    span = hi - lo if hi > lo else 1.0\n",
        "    bounds.append((lo - 0.05*span, hi + 0.05*span))\n",
        "\n",
        "# Build a template row for prediction\n",
        "def build_row(cont_vec, cat_choice):\n",
        "    row = {}\n",
        "    j = 0\n",
        "    for col in X.columns:\n",
        "        if col in cat_cols:\n",
        "            row[col] = cat_choice[col]\n",
        "        else:\n",
        "            row[col] = float(cont_vec[j]); j += 1\n",
        "    return pd.DataFrame([row], columns=X.columns) # Ensure columns order matches X\n",
        "\n",
        "# Sum-to-constant constraint (if composition percentages)\n",
        "constraints = []\n",
        "if MODE == \"composition\" and COMPOSITION_TOTAL is not None:\n",
        "    def sum_eq(cont_vec, cont_cols=cont_cols, total=COMPOSITION_TOTAL):\n",
        "        # This assumes cont_cols are the composition components that sum\n",
        "        return float(np.sum(cont_vec) - total)\n",
        "    constraints.append({\"type\": \"eq\", \"fun\": sum_eq})\n",
        "\n",
        "# penalty for going outside historical range (soft corners)\n",
        "if cont_cols:\n",
        "    mins = X[cont_cols].min().values\n",
        "    maxs = X[cont_cols].max().values\n",
        "else:\n",
        "    mins = np.array([])\n",
        "    maxs = np.array([])\n",
        "\n",
        "\n",
        "def objective(cont_vec, cat_choice):\n",
        "    row = build_row(cont_vec, cat_choice)\n",
        "    pred = reg.predict(row)[0]\n",
        "    # Weighted MSE + MAPE on targets\n",
        "    var = np.var(Y_tr.values, axis=0) if len(Y_tr) else np.var(Y.values, axis=0)\n",
        "    var = var if var.size == pred.size else np.ones_like(pred)  # safeguard\n",
        "    w = 1.0 / np.where(var <= 1e-12, 1.0, var)\n",
        "    eps = 1e-8\n",
        "    # align only the target indices (Y order == target_keys order)\n",
        "    # our Y_tr columns equal target_keys in order already\n",
        "    y_pred_targets = pred[[Y.columns.get_loc(k) for k in target_keys]] # Ensure target columns are selected from prediction\n",
        "    mse = np.mean(w * (y_pred_targets - tgt)**2)\n",
        "    mape = np.mean(np.abs(y_pred_targets - tgt)/(np.abs(tgt)+eps))\n",
        "    base_loss = 0.5*mse + 0.5*mape\n",
        "\n",
        "    # Soft penalty if outside observed domain (only for continuous features)\n",
        "    penalty = 0.0\n",
        "    if cont_cols:\n",
        "        over_low = np.maximum(0.0, mins - cont_vec)\n",
        "        over_high = np.maximum(0.0, cont_vec - maxs)\n",
        "        penalty = 1e-3 * np.sum(over_low**2 + over_high**2)\n",
        "\n",
        "    return base_loss + penalty\n",
        "\n",
        "\n",
        "# Initial guess for continuous: median of continuous columns\n",
        "x0_cont = X[cont_cols].median().values if cont_cols else np.array([])\n",
        "\n",
        "# Enumerate categoricals; minimize continuous for each category combination\n",
        "from scipy.optimize import minimize\n",
        "best = {\"loss\": np.inf, \"row\": None, \"yhat\": None}\n",
        "\n",
        "cat_product = [{}]\n",
        "if cat_cols:\n",
        "    import itertools\n",
        "    cat_values = [discrete_enums[c] for c in cat_cols]\n",
        "    cat_product = [{c: v for c, v in zip(cat_cols, combo)} for combo in itertools.product(*cat_values)]\n",
        "\n",
        "\n",
        "for cat_choice in cat_product:\n",
        "    if not cont_cols:\n",
        "        # No continuous features — just evaluate categorical combo\n",
        "        dfrow = build_row(np.array([]), cat_choice)\n",
        "        loss, yhat = objective(np.array([]), cat_choice), reg.predict(dfrow)[0] # Evaluate loss with objective directly\n",
        "        if loss < best[\"loss\"]:\n",
        "            best.update({\"loss\": loss, \"row\": dfrow, \"yhat\": yhat})\n",
        "        continue\n",
        "\n",
        "    def _wrap(cont_vec):\n",
        "        return objective(cont_vec, cat_choice)\n",
        "\n",
        "    result = minimize(\n",
        "        _wrap, x0_cont,\n",
        "        method=\"SLSQP\",\n",
        "        bounds=bounds,\n",
        "        constraints=constraints,\n",
        "        options={\"maxiter\": 1000, \"ftol\": 1e-9, \"disp\": False}\n",
        "    )\n",
        "\n",
        "    if result.success:\n",
        "        loss = result.fun\n",
        "        dfrow = build_row(result.x, cat_choice)\n",
        "        yhat = reg.predict(dfrow)[0]\n",
        "        if loss < best[\"loss\"]:\n",
        "            best.update({\"loss\": loss, \"row\": dfrow, \"yhat\": yhat})\n",
        "    else:\n",
        "        print(f\"[Warn] Optimization failed for {cat_choice}: {result.message}\")\n",
        "\n",
        "\n",
        "if best[\"row\"] is None:\n",
        "     raise RuntimeError(\"Optimization failed for all combinations.\")\n",
        "\n",
        "\n",
        "opt_recipe = best[\"row\"]\n",
        "opt_pred = pd.DataFrame([best[\"yhat\"]], columns=Y.columns) # Use Y.columns for full prediction columns\n",
        "report = pd.concat({\"recipe_opt\": opt_recipe.reset_index(drop=True), \"predicted_targets\": opt_pred[target_keys].reset_index(drop=True)}, axis=1) # Report only target columns\n",
        "\n",
        "\n",
        "print(\"\\n================ RESULTS ================\")\n",
        "if MODE == \"composition\":\n",
        "    print(\"Mode: COMPOSITION → PROPERTIES\")\n",
        "    print(\"\\nRecommended composition:\")\n",
        "    display_cols = COMPOSITION_COLS\n",
        "else:\n",
        "    print(\"Mode: LABEL FALLBACK (no composition provided)\")\n",
        "    print(\"\\nRecommended knobs parsed from label (not true chemistry):\")\n",
        "    display_cols = X.columns.tolist()\n",
        "\n",
        "print(opt_recipe[display_cols].to_string(index=False))\n",
        "print(\"\\nPredicted target properties:\")\n",
        "print(report.to_string(index=False))\n",
        "\n",
        "# Save files\n",
        "props_out = \"/content/_derived_properties_table.csv\"\n",
        "opt_out = \"/content/_optimal_recipe_and_predictions.csv\"\n",
        "props_df.to_csv(props_out, index=False)\n",
        "report.to_csv(opt_out, index=False)\n",
        "print(f\"\\nSaved:\\n  {props_out}\\n  {opt_out}\")\n",
        "\n",
        "# Helpful tip: if you get \"not enough rows\", print coverage per target:\n",
        "# print(props_df[target_keys].notna().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6j2_lZzq7Oj_",
        "outputId": "b79481bf-de1b-4f59-b004-288a7484ffc0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3718803818.py:103: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
            "  return float(np.trapz(f(xs), xs))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Warn] No composition table recognized. Falling back to ('mat_type','mat_level') from labels.\n",
            "=== Quick holdout ===\n",
            "           UTS_kPa  R2=-0.548  MAE=  13.855\n",
            "\n",
            "================ RESULTS ================\n",
            "Mode: LABEL FALLBACK (no composition provided)\n",
            "\n",
            "Recommended knobs parsed from label (not true chemistry):\n",
            "mat_type  mat_level\n",
            "     Cel        5.0\n",
            "\n",
            "Predicted target properties:\n",
            "recipe_opt           predicted_targets\n",
            "  mat_type mat_level           UTS_kPa\n",
            "       Cel       5.0         61.194722\n",
            "\n",
            "Saved:\n",
            "  /content/_derived_properties_table.csv\n",
            "  /content/_optimal_recipe_and_predictions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What you’ll see\n",
        "\n",
        "If you provided COMPOSITION_COLS and a composition table with label matching the stress–strain labels, you’ll get a recommended chemical composition (respecting a sum=100 constraint if you set COMPOSITION_TOTAL=100.0) that best hits your TARGETS.\n",
        "\n",
        "If you skip composition, you’ll get recommended coarse knobs (mat_type, mat_level), which is not a full chemistry but still runs.\n",
        "\n",
        "Common pitfalls (and quick fixes)\n",
        "\n",
        "Error: not enough rows → Start with TARGETS = {\"UTS_kPa\": <value>}; UTS is almost always available.\n",
        "\n",
        "Sum constraint → If your variables are wt%, keep COMPOSITION_TOTAL=100.0. If not percentages, set it to None.\n",
        "\n",
        "Column names → Make sure COMPOSITION_COLS exactly match your table’s numeric columns and that a label column matches the stress–strain label suffixes.\n",
        "\n",
        "If you share the names of your actual composition columns (e.g., AAm_wt, BIS_wt, APS_wt, TEMED_wt, Water_wt, NaCl_mM), I can pre-fill COMPOSITION_COLS (and the appropriate COMPOSITION_TOTAL) for you."
      ],
      "metadata": {
        "id": "L7RIDUa09MOW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) UTS only"
      ],
      "metadata": {
        "id": "r8vbEUwd-MA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# Single-cell: Composition design for a chosen target property (or set)\n",
        "# ============================\n",
        "!pip -q install numpy pandas scikit-learn scipy\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import Dict, Tuple, Optional, List\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "# ========== USER CONFIG ==========\n",
        "# 1) Stress–strain file (paired columns: Strain(%)_<label>, Stress(kPa)_<label>)\n",
        "DATA_PATH = \"/content/drive/MyDrive/AI Training/paam_hydrogel_stress_strain_data_v2.xlsx\"\n",
        "\n",
        "# 2) Composition source (choose ONE)\n",
        "COMPOSITION_PATH = \"\"                 # e.g., \"/content/composition_table.xlsx\" or \"/content/recipe_table.csv\"\n",
        "COMPOSITION_SHEET = \"\"                # e.g., \"composition\" if stored as a sheet inside DATA_PATH\n",
        "\n",
        "# 3) Composition columns (true chemistry knobs). Leave empty to fallback to ('mat_type','mat_level')\n",
        "COMPOSITION_COLS: List[str] = [\n",
        "    # \"monomer_wt%\", \"crosslinker_wt%\", \"initiator_wt%\", \"solvent_wt%\", \"salt_mM\"\n",
        "]\n",
        "\n",
        "# 4) If composition columns are wt% (or any total constraint), set sum=constant\n",
        "COMPOSITION_TOTAL = 100.0   # or None if not applicable\n",
        "\n",
        "# 5) >>>>> CHANGE THIS FOR EACH TARGET <<<<<\n",
        "TARGETS: Dict[str, float] = {\n",
        "    \"UTS_kPa\": 90.0,    # example default; replace per the presets below\n",
        "}\n",
        "# =================================\n",
        "\n",
        "# ======== Stress–strain utilities ========\n",
        "def find_pairs(df: pd.DataFrame) -> Tuple[Dict[str, str], Dict[str, str], list]:\n",
        "    strain_cols = [c for c in df.columns if c.lower().startswith(\"strain\")]\n",
        "    stress_cols = [c for c in df.columns if c.lower().startswith(\"stress\")]\n",
        "    def lab(c): return c.split(\"_\", 1)[1] if \"_\" in c else None\n",
        "    labels_strain = {lab(c): c for c in strain_cols if lab(c) is not None}\n",
        "    labels_stress = {lab(c): c for c in stress_cols if lab(c) is not None}\n",
        "    labels = sorted(set(labels_strain).intersection(labels_stress))\n",
        "    return labels_strain, labels_stress, labels\n",
        "\n",
        "def to_fraction(eps_raw: np.ndarray) -> np.ndarray:\n",
        "    return (eps_raw.astype(float)/100.0)/100.0\n",
        "\n",
        "def ensure_sorted(eps: np.ndarray, sig: np.ndarray):\n",
        "    idx = np.argsort(eps)\n",
        "    return eps[idx], sig[idx]\n",
        "\n",
        "def interp_curve(eps: np.ndarray, sig: np.ndarray):\n",
        "    x = np.asarray(eps, float); y = np.asarray(sig, float)\n",
        "    lo, hi = float(x.min()), float(x.max())\n",
        "    def f(xq):\n",
        "        xq = np.asarray(xq, float)\n",
        "        return np.interp(np.clip(xq, lo, hi), x, y)\n",
        "    return f, (lo, hi)\n",
        "\n",
        "def linear_fit_window(eps: np.ndarray, sig: np.ndarray, a: float, b: float):\n",
        "    if b <= a: return None\n",
        "    f, (lo, hi) = interp_curve(eps, sig)\n",
        "    a, b = max(lo, a), min(hi, b)\n",
        "    if b <= a: return None\n",
        "    xs = np.linspace(a, b, 20); ys = f(xs)\n",
        "    X = np.vstack([xs, np.ones_like(xs)]).T\n",
        "    slope, intercept = np.linalg.lstsq(X, ys, rcond=None)[0]\n",
        "    return float(slope), float(intercept)\n",
        "\n",
        "def secant_modulus(f, a: float, b: float):\n",
        "    if b <= a: return np.nan\n",
        "    return float((f(b) - f(a)) / (b - a))\n",
        "\n",
        "def yield_offset(eps: np.ndarray, sig: np.ndarray, E_init: Optional[float], offset: float = 0.002):\n",
        "    if E_init is None or not np.isfinite(E_init): return None, None\n",
        "    f, (lo, hi) = interp_curve(eps, sig)\n",
        "    xs = np.linspace(lo, hi, 400)\n",
        "    g = f(xs) - E_init*(xs - offset)\n",
        "    s = np.sign(g); idx = np.where(np.diff(s) != 0)[0]\n",
        "    if len(idx) == 0: return None, None\n",
        "    i = idx[0]; x0, x1 = xs[i], xs[i+1]; y0, y1 = g[i], g[i+1]\n",
        "    eps_y = x0 if (y1 - y0) == 0 else x0 - y0*(x1 - x0)/(y1 - y0)\n",
        "    return float(eps_y), float(f(eps_y))\n",
        "\n",
        "def integrate_toughness(eps: np.ndarray, sig: np.ndarray, up_to: Optional[float] = None) -> float:\n",
        "    f, (lo, hi) = interp_curve(eps, sig)\n",
        "    b = hi if up_to is None else max(lo, min(hi, up_to))\n",
        "    xs = np.linspace(lo, b, 400)\n",
        "    return float(np.trapz(f(xs), xs))\n",
        "\n",
        "def stress_at(f, p: float, lo: float, hi: float):\n",
        "    x = p/100.0\n",
        "    return float(f(x)) if lo <= x <= hi else np.nan\n",
        "\n",
        "def parse_label_recipe(label: str):\n",
        "    import re\n",
        "    m = re.match(r\"([A-Za-z]+)(\\d+)?\", label)\n",
        "    mat_type = m.group(1) if m else None\n",
        "    mat_level = float(m.group(2)) if (m and m.group(2)) else 0.0\n",
        "    return mat_type, mat_level\n",
        "\n",
        "def derive_properties_table(stress_strain_path: str) -> pd.DataFrame:\n",
        "    df = pd.read_excel(stress_strain_path)\n",
        "    labels_strain, labels_stress, labels = find_pairs(df)\n",
        "    rows = []\n",
        "    for lab in labels:\n",
        "        eps_raw = df[labels_strain[lab]].to_numpy(dtype=float)\n",
        "        sig_raw = df[labels_stress[lab]].to_numpy(dtype=float)\n",
        "        m = np.isfinite(eps_raw) & np.isfinite(sig_raw)\n",
        "        eps_raw, sig_raw = eps_raw[m], sig_raw[m]\n",
        "        if len(eps_raw) < 3: continue\n",
        "        eps = to_fraction(eps_raw)\n",
        "        eps, sig = ensure_sorted(eps, sig_raw)\n",
        "        f, (lo, hi) = interp_curve(eps, sig)\n",
        "        E0_5  = (linear_fit_window(eps, sig, 0.00, 0.05) or (np.nan, np.nan))[0]\n",
        "        E5_10 = secant_modulus(f, 0.05, 0.10) if hi >= 0.10 else np.nan\n",
        "        TanE10 = (linear_fit_window(eps, sig, 0.08, 0.12) or (np.nan, np.nan))[0] if hi >= 0.12 else np.nan\n",
        "        eps_y, sig_y = yield_offset(eps, sig, E0_5, offset=0.002)\n",
        "        resilience = integrate_toughness(eps, sig, up_to=eps_y) if eps_y is not None else (integrate_toughness(eps, sig, up_to=0.02) if hi >= 0.02 else np.nan)\n",
        "        uts = float(sig.max()); i_uts = int(sig.argmax()); strain_uts = float(eps[i_uts])\n",
        "        frac_strain = float(eps.max()); frac_stress = float(sig[-1])\n",
        "        toughness = integrate_toughness(eps, sig, None)\n",
        "        s5  = stress_at(f, 5, lo, hi); s10 = stress_at(f, 10, lo, hi)\n",
        "        s15 = stress_at(f, 15, lo, hi); s20 = stress_at(f, 20, lo, hi)\n",
        "        sec_0_15 = secant_modulus(f, 0.00, 0.15) if hi >= 0.15 else np.nan\n",
        "        mat_type, mat_level = parse_label_recipe(lab)\n",
        "        rows.append({\n",
        "            \"label\": lab, \"mat_type\": mat_type, \"mat_level\": mat_level,\n",
        "            \"E0_5_kPa\": E0_5, \"E5_10_kPa\": E5_10, \"TanE10_kPa\": TanE10,\n",
        "            \"Yield_strain_frac\": eps_y if eps_y is not None else np.nan,\n",
        "            \"Yield_stress_kPa\":  sig_y if sig_y is not None else np.nan,\n",
        "            \"Resilience_kJ_m3\":  resilience,\n",
        "            \"UTS_kPa\": uts, \"Strain_UTS_frac\": strain_uts,\n",
        "            \"Fracture_strain_frac\": frac_strain, \"Fracture_stress_kPa\": frac_stress,\n",
        "            \"Toughness_kJ_m3\": toughness,\n",
        "            \"Stress@5%_kPa\": s5, \"Stress@10%_kPa\": s10, \"Stress@15%_kPa\": s15, \"Stress@20%_kPa\": s20,\n",
        "            \"Secant_0_15_kPa\": sec_0_15\n",
        "        })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "props_df = derive_properties_table(DATA_PATH)\n",
        "if props_df.empty:\n",
        "    raise RuntimeError(\"No valid stress–strain pairs found. Check column names like Strain(%)_<label> and Stress(kPa)_<label>.\")\n",
        "\n",
        "def load_composition() -> pd.DataFrame:\n",
        "    comp_df = None\n",
        "    if COMPOSITION_PATH and Path(COMPOSITION_PATH).exists():\n",
        "        if COMPOSITION_PATH.lower().endswith(\".csv\"):\n",
        "            comp_df = pd.read_csv(COMPOSITION_PATH)\n",
        "        else:\n",
        "            comp_df = pd.read_excel(COMPOSITION_PATH)\n",
        "    elif COMPOSITION_SHEET:\n",
        "        comp_df = pd.read_excel(DATA_PATH, sheet_name=COMPOSITION_SHEET)\n",
        "    return comp_df\n",
        "\n",
        "comp_df = load_composition()\n",
        "\n",
        "# Build X (recipe features) and Y (targets)\n",
        "if comp_df is not None and len(COMPOSITION_COLS) > 0 and all(c in comp_df.columns for c in COMPOSITION_COLS) and \"label\" in comp_df.columns:\n",
        "    MODE = \"composition\"\n",
        "    df_model = props_df.merge(comp_df[[\"label\"] + COMPOSITION_COLS], on=\"label\", how=\"inner\")\n",
        "    XY = df_model[[\"label\"] + COMPOSITION_COLS + list(TARGETS.keys())]\n",
        "    XY = XY.dropna(subset=COMPOSITION_COLS + list(TARGETS.keys()))\n",
        "    X = XY[COMPOSITION_COLS].astype(float)\n",
        "    Y = XY[list(TARGETS.keys())].astype(float)\n",
        "else:\n",
        "    MODE = \"label_fallback\"\n",
        "    XY = props_df[[\"label\",\"mat_type\",\"mat_level\"] + list(TARGETS.keys())].dropna(subset=list(TARGETS.keys()))\n",
        "    X = XY[[\"mat_type\",\"mat_level\"]].copy()\n",
        "    Y = XY[list(TARGETS.keys())].astype(float)\n",
        "\n",
        "if len(X) < 2:\n",
        "    raise RuntimeError(\"Not enough rows to train. Ensure your chosen target has at least 2 valid samples.\")\n",
        "\n",
        "# Pipeline\n",
        "if MODE == \"composition\":\n",
        "    preprocess = ColumnTransformer([(\"num\", StandardScaler(), X.columns.tolist())])\n",
        "else:\n",
        "    preprocess = ColumnTransformer([\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), [\"mat_type\"]),\n",
        "        (\"num\", StandardScaler(), [\"mat_level\"]),\n",
        "    ])\n",
        "base = RandomForestRegressor(n_estimators=600, random_state=42, n_jobs=-1)\n",
        "reg = Pipeline([(\"prep\", preprocess), (\"rf\", MultiOutputRegressor(base))])\n",
        "\n",
        "ts = 0.33 if len(X) >= 6 else 0.0\n",
        "if ts>0:\n",
        "    X_tr, X_te, Y_tr, Y_te = train_test_split(X, Y, test_size=ts, random_state=42)\n",
        "else:\n",
        "    X_tr, Y_tr = X, Y\n",
        "    X_te, Y_te = X.iloc[:0], Y.iloc[:0]\n",
        "\n",
        "reg.fit(X_tr, Y_tr)\n",
        "if len(X_te)>0:\n",
        "    Y_hat = reg.predict(X_te)\n",
        "    print(\"=== Quick holdout ===\")\n",
        "    for i, col in enumerate(Y.columns):\n",
        "        print(f\"{col:>18}  R2={r2_score(Y_te.iloc[:, i], Y_hat[:, i]):6.3f}  MAE={mean_absolute_error(Y_te.iloc[:, i], Y_hat[:, i]):8.3f}\")\n",
        "else:\n",
        "    print(\"Trained on all rows (small dataset).\")\n",
        "\n",
        "# Forward design (SLSQP with optional sum constraint)\n",
        "tgt = np.array([TARGETS[k] for k in Y.columns], float)\n",
        "\n",
        "# Separate bounds for numeric and handle categoricals\n",
        "bounds = []\n",
        "cont_cols = [c for c in X.columns if np.issubdtype(X[c].dtype, np.number)]\n",
        "cat_cols = [c for c in X.columns if X[c].dtype == \"O\"]\n",
        "discrete_enums = {c: sorted(X[c].unique().tolist()) for c in cat_cols}\n",
        "\n",
        "for c in cont_cols:\n",
        "    lo, hi = float(X[c].min()), float(X[c].max())\n",
        "    span = hi - lo if hi > lo else 1.0\n",
        "    bounds.append((lo - 0.05*span, hi + 0.05*span))\n",
        "\n",
        "# Build a template row for prediction\n",
        "def build_row(cont_vec, cat_choice):\n",
        "    row = {}\n",
        "    j = 0\n",
        "    for col in X.columns:\n",
        "        if col in cat_cols:\n",
        "            row[col] = cat_choice[col]\n",
        "        else:\n",
        "            row[col] = float(cont_vec[j]); j += 1\n",
        "    return pd.DataFrame([row], columns=X.columns) # Ensure columns order matches X\n",
        "\n",
        "# Sum-to-constant constraint (if composition percentages)\n",
        "constraints = []\n",
        "if MODE == \"composition\" and COMPOSITION_TOTAL is not None:\n",
        "    def sum_eq(cont_vec, cont_cols=cont_cols, total=COMPOSITION_TOTAL):\n",
        "        # This assumes cont_cols are the composition components that sum\n",
        "        return float(np.sum(cont_vec) - total)\n",
        "    constraints.append({\"type\": \"eq\", \"fun\": sum_eq})\n",
        "\n",
        "# penalty for going outside historical range (soft corners)\n",
        "if cont_cols:\n",
        "    mins = X[cont_cols].min().values\n",
        "    maxs = X[cont_cols].max().values\n",
        "else:\n",
        "    mins = np.array([])\n",
        "    maxs = np.array([])\n",
        "\n",
        "\n",
        "def objective(cont_vec, cat_choice):\n",
        "    row = build_row(cont_vec, cat_choice)\n",
        "    pred = reg.predict(row)[0]\n",
        "    # Weighted MSE + MAPE on targets\n",
        "    var = np.var(Y_tr.values, axis=0) if len(Y_tr) else np.var(Y.values, axis=0)\n",
        "    var = var if var.size == pred.size else np.ones_like(pred)  # safeguard\n",
        "    w = 1.0 / np.where(var <= 1e-12, 1.0, var)\n",
        "    eps = 1e-8\n",
        "    # align only the target indices (Y order == target_keys order)\n",
        "    # our Y_tr columns equal target_keys in order already\n",
        "    y_pred_targets = pred[[Y.columns.get_loc(k) for k in target_keys]] # Ensure target columns are selected from prediction\n",
        "    mse = np.mean(w * (y_pred_targets - tgt)**2)\n",
        "    mape = np.mean(np.abs(y_pred_targets - tgt)/(np.abs(tgt)+eps))\n",
        "    base_loss = 0.5*mse + 0.5*mape\n",
        "\n",
        "    # Soft penalty if outside observed domain (only for continuous features)\n",
        "    penalty = 0.0\n",
        "    if cont_cols:\n",
        "        over_low = np.maximum(0.0, mins - cont_vec)\n",
        "        over_high = np.maximum(0.0, cont_vec - maxs)\n",
        "        penalty = 1e-3 * np.sum(over_low**2 + over_high**2)\n",
        "\n",
        "    return base_loss + penalty\n",
        "\n",
        "\n",
        "# Initial guess for continuous: median of continuous columns\n",
        "x0_cont = X[cont_cols].median().values if cont_cols else np.array([])\n",
        "\n",
        "# Enumerate categoricals; minimize continuous for each category combination\n",
        "from scipy.optimize import minimize\n",
        "best = {\"loss\": np.inf, \"row\": None, \"yhat\": None}\n",
        "\n",
        "cat_product = [{}]\n",
        "if cat_cols:\n",
        "    import itertools\n",
        "    cat_values = [discrete_enums[c] for c in cat_cols]\n",
        "    cat_product = [{c: v for c, v in zip(cat_cols, combo)} for combo in itertools.product(*cat_values)]\n",
        "\n",
        "\n",
        "for cat_choice in cat_product:\n",
        "    if not cont_cols:\n",
        "        # No continuous features — just evaluate categorical combo\n",
        "        dfrow = build_row(np.array([]), cat_choice)\n",
        "        loss, yhat = objective(np.array([]), cat_choice), reg.predict(dfrow)[0] # Evaluate loss with objective directly\n",
        "        if loss < best[\"loss\"]:\n",
        "            best.update({\"loss\": loss, \"row\": dfrow, \"yhat\": yhat})\n",
        "        continue\n",
        "\n",
        "    def _wrap(cont_vec):\n",
        "        return objective(cont_vec, cat_choice)\n",
        "\n",
        "    result = minimize(\n",
        "        _wrap, x0_cont,\n",
        "        method=\"SLSQP\",\n",
        "        bounds=bounds,\n",
        "        constraints=constraints,\n",
        "        options={\"maxiter\": 1000, \"ftol\": 1e-9, \"disp\": False}\n",
        "    )\n",
        "\n",
        "    if result.success:\n",
        "        loss = result.fun\n",
        "        dfrow = build_row(result.x, cat_choice)\n",
        "        yhat = reg.predict(dfrow)[0]\n",
        "        if loss < best[\"loss\"]:\n",
        "            best.update({\"loss\": loss, \"row\": dfrow, \"yhat\": yhat})\n",
        "    else:\n",
        "        print(f\"[Warn] Optimization failed for {cat_choice}: {result.message}\")\n",
        "\n",
        "\n",
        "if best[\"row\"] is None:\n",
        "     raise RuntimeError(\"Optimization failed for all combinations.\")\n",
        "\n",
        "\n",
        "opt_recipe = best[\"row\"]\n",
        "opt_pred = pd.DataFrame([best[\"yhat\"]], columns=Y.columns) # Use Y.columns for full prediction columns\n",
        "report = pd.concat({\"recipe_opt\": opt_recipe.reset_index(drop=True), \"predicted_targets\": opt_pred[target_keys].reset_index(drop=True)}, axis=1) # Report only target columns\n",
        "\n",
        "\n",
        "print(\"\\n================ RESULTS ================\")\n",
        "if MODE == \"composition\":\n",
        "    print(\"Mode: COMPOSITION → PROPERTIES\")\n",
        "    print(\"\\nRecommended composition:\")\n",
        "    display_cols = COMPOSITION_COLS\n",
        "else:\n",
        "    print(\"Mode: LABEL FALLBACK (no composition provided)\")\n",
        "    print(\"\\nRecommended knobs parsed from label (not true chemistry):\")\n",
        "    display_cols = X.columns.tolist()\n",
        "\n",
        "print(opt_recipe[display_cols].to_string(index=False))\n",
        "print(\"\\nPredicted target properties:\")\n",
        "print(report.to_string(index=False))\n",
        "\n",
        "# Save files\n",
        "props_out = \"/content/_derived_properties_table.csv\"\n",
        "opt_out = \"/content/_optimal_recipe_and_predictions.csv\"\n",
        "props_df.to_csv(props_out, index=False)\n",
        "report.to_csv(opt_out, index=False)\n",
        "print(f\"\\nSaved:\\n  {props_out}\\n  {opt_out}\")\n",
        "\n",
        "# Helpful tip: if you get \"not enough rows\", print coverage per target:\n",
        "# print(props_df[target_keys].notna().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yGmYXuy7OnH",
        "outputId": "4c0f0304-eb9d-4368-deec-86e569d19134"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3754016808.py:95: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
            "  return float(np.trapz(f(xs), xs))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Quick holdout ===\n",
            "           UTS_kPa  R2=-0.548  MAE=  13.855\n",
            "\n",
            "================ RESULTS ================\n",
            "Mode: LABEL FALLBACK (no composition provided)\n",
            "\n",
            "Recommended knobs parsed from label (not true chemistry):\n",
            "mat_type  mat_level\n",
            "     Cel        5.0\n",
            "\n",
            "Predicted target properties:\n",
            "recipe_opt           predicted_targets\n",
            "  mat_type mat_level           UTS_kPa\n",
            "       Cel       5.0         61.194722\n",
            "\n",
            "Saved:\n",
            "  /content/_derived_properties_table.csv\n",
            "  /content/_optimal_recipe_and_predictions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here’s a single, copy-paste Colab cell tailored to optimize Toughness only. It:\n",
        "\n",
        "Reads your stress–strain file from Google Drive (path you gave)\n",
        "\n",
        "Derives mechanical properties per curve\n",
        "\n",
        "Trains a recipe → Toughness predictor\n",
        "\n",
        "Designs a recipe/composition to hit your target Toughness_kJ_m3\n",
        "\n",
        "Works with either a true composition table (recommended) or a fallback using mat_type + mat_level parsed from labels\n",
        "\n",
        "How to use:\n",
        "\n",
        "Make sure your file exists at the path you gave.\n",
        "\n",
        "(Optional) If you have a composition table, fill COMPOSITION_PATH (or COMPOSITION_SHEET) and list its numeric columns in COMPOSITION_COLS (e.g., monomer %, crosslinker %, …). Set COMPOSITION_TOTAL=100.0 if they are wt%.\n",
        "\n",
        "Set your toughness target in TARGET_TOUGHNESS. Run the cel"
      ],
      "metadata": {
        "id": "WWks_umw_B1V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Toughness only"
      ],
      "metadata": {
        "id": "YzxBuDaS-JvP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# One-cell: Toughness-only composition design\n",
        "# ============================================\n",
        "!pip -q install numpy pandas scikit-learn scipy\n",
        "\n",
        "# --- Mount Google Drive (needed for the provided path) ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import Dict, Tuple, Optional, List\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "# ---------------- USER CONFIG ----------------\n",
        "# 1) Stress–strain file (paired columns: Strain(%)_<label>, Stress(kPa)_<label>)\n",
        "DATA_PATH = \"/content/drive/MyDrive/AI Training/paam_hydrogel_stress_strain_data_v2.xlsx\"\n",
        "\n",
        "# 2) Composition source (choose ONE: separate file OR sheet within DATA_PATH)\n",
        "COMPOSITION_PATH = \"\"                 # e.g., \"/content/drive/MyDrive/AI Training/composition_table.xlsx\" or \".csv\"\n",
        "COMPOSITION_SHEET = \"\"                # e.g., \"composition\" if stored as a sheet in DATA_PATH\n",
        "\n",
        "# 3) Composition columns (true chemistry knobs). Leave empty to fallback to ('mat_type','mat_level')\n",
        "COMPOSITION_COLS: List[str] = [\n",
        "    # Example: \"AAm_wt\", \"BIS_wt\", \"APS_wt\", \"TEMED_wt\", \"Water_wt\"\n",
        "]\n",
        "\n",
        "# 4) If composition cols are wt% (or any total constraint), set the target sum (e.g., 100.0). Else set None.\n",
        "COMPOSITION_TOTAL = 100.0   # or None\n",
        "\n",
        "# 5) Toughness target (kJ/m^3). Set your desired value here:\n",
        "TARGET_TOUGHNESS = 7.0\n",
        "# --------------------------------------------\n",
        "\n",
        "# ======== Stress–strain utilities ========\n",
        "def find_pairs(df: pd.DataFrame) -> Tuple[Dict[str, str], Dict[str, str], list]:\n",
        "    strain_cols = [c for c in df.columns if c.lower().startswith(\"strain\")]\n",
        "    stress_cols = [c for c in df.columns if c.lower().startswith(\"stress\")]\n",
        "    def lab(c): return c.split(\"_\", 1)[1] if \"_\" in c else None\n",
        "    labels_strain = {lab(c): c for c in strain_cols if lab(c) is not None}\n",
        "    labels_stress = {lab(c): c for c in stress_cols if lab(c) is not None}\n",
        "    labels = sorted(set(labels_strain).intersection(labels_stress))\n",
        "    return labels_strain, labels_stress, labels\n",
        "\n",
        "def to_fraction(eps_raw: np.ndarray) -> np.ndarray:\n",
        "    # Your data pattern looks like: [0, 500, 1000, ...] -> 0.0%, 5.0%, 10.0% -> 0.0, 0.05, 0.10 (fraction)\n",
        "    return (eps_raw.astype(float)/100.0)/100.0\n",
        "\n",
        "def ensure_sorted(eps: np.ndarray, sig: np.ndarray):\n",
        "    idx = np.argsort(eps)\n",
        "    return eps[idx], sig[idx]\n",
        "\n",
        "def interp_curve(eps: np.ndarray, sig: np.ndarray):\n",
        "    x = np.asarray(eps, float); y = np.asarray(sig, float)\n",
        "    lo, hi = float(x.min()), float(x.max())\n",
        "    def f(xq):\n",
        "        xq = np.asarray(xq, float)\n",
        "        return np.interp(np.clip(xq, lo, hi), x, y)\n",
        "    return f, (lo, hi)\n",
        "\n",
        "def linear_fit_window(eps: np.ndarray, sig: np.ndarray, a: float, b: float):\n",
        "    if b <= a: return None\n",
        "    f, (lo, hi) = interp_curve(eps, sig)\n",
        "    a, b = max(lo, a), min(hi, b)\n",
        "    if b <= a: return None\n",
        "    xs = np.linspace(a, b, 20); ys = f(xs)\n",
        "    X = np.vstack([xs, np.ones_like(xs)]).T\n",
        "    slope, intercept = np.linalg.lstsq(X, ys, rcond=None)[0]\n",
        "    return float(slope), float(intercept)\n",
        "\n",
        "def secant_modulus(f, a: float, b: float):\n",
        "    if b <= a: return np.nan\n",
        "    return float((f(b) - f(a)) / (b - a))\n",
        "\n",
        "def yield_offset(eps: np.ndarray, sig: np.ndarray, E_init: Optional[float], offset: float = 0.002):\n",
        "    if E_init is None or not np.isfinite(E_init): return None, None\n",
        "    f, (lo, hi) = interp_curve(eps, sig)\n",
        "    xs = np.linspace(lo, hi, 400)\n",
        "    g = f(xs) - E_init*(xs - offset)\n",
        "    s = np.sign(g); idx = np.where(np.diff(s) != 0)[0]\n",
        "    if len(idx) == 0: return None, None\n",
        "    i = idx[0]; x0, x1 = xs[i], xs[i+1]; y0, y1 = g[i], g[i+1]\n",
        "    eps_y = x0 if (y1 - y0) == 0 else x0 - y0*(x1 - x0)/(y1 - y0)\n",
        "    return float(eps_y), float(f(eps_y))\n",
        "\n",
        "def integrate_toughness(eps: np.ndarray, sig: np.ndarray, up_to: Optional[float] = None) -> float:\n",
        "    f, (lo, hi) = interp_curve(eps, sig)\n",
        "    b = hi if up_to is None else max(lo, min(hi, up_to))\n",
        "    xs = np.linspace(lo, b, 400)\n",
        "    return float(np.trapz(f(xs), xs))  # kJ/m^3 if stress in kPa and strain is fraction\n",
        "\n",
        "def stress_at(f, p: float, lo: float, hi: float):\n",
        "    x = p/100.0\n",
        "    return float(f(x)) if lo <= x <= hi else np.nan\n",
        "\n",
        "def parse_label_recipe(label: str):\n",
        "    import re\n",
        "    m = re.match(r\"([A-Za-z]+)(\\d+)?\", label)\n",
        "    mat_type = m.group(1) if m else None\n",
        "    mat_level = float(m.group(2)) if (m and m.group(2)) else 0.0\n",
        "    return mat_type, mat_level\n",
        "\n",
        "def derive_properties_table(stress_strain_path: str) -> pd.DataFrame:\n",
        "    df = pd.read_excel(stress_strain_path)\n",
        "    labels_strain, labels_stress, labels = find_pairs(df)\n",
        "    rows = []\n",
        "    for lab in labels:\n",
        "        eps_raw = df[labels_strain[lab]].to_numpy(dtype=float)\n",
        "        sig_raw = df[labels_stress[lab]].to_numpy(dtype=float)\n",
        "        m = np.isfinite(eps_raw) & np.isfinite(sig_raw)\n",
        "        eps_raw, sig_raw = eps_raw[m], sig_raw[m]\n",
        "        if len(eps_raw) < 3: continue\n",
        "        eps = to_fraction(eps_raw)\n",
        "        eps, sig = ensure_sorted(eps, sig_raw)\n",
        "        f, (lo, hi) = interp_curve(eps, sig)\n",
        "        E0_5  = (linear_fit_window(eps, sig, 0.00, 0.05) or (np.nan, np.nan))[0]\n",
        "        E5_10 = secant_modulus(f, 0.05, 0.10) if hi >= 0.10 else np.nan\n",
        "        TanE10 = (linear_fit_window(eps, sig, 0.08, 0.12) or (np.nan, np.nan))[0] if hi >= 0.12 else np.nan\n",
        "        eps_y, sig_y = yield_offset(eps, sig, E0_5, offset=0.002)\n",
        "        resilience = integrate_toughness(eps, sig, up_to=eps_y) if eps_y is not None else (integrate_toughness(eps, sig, up_to=0.02) if hi >= 0.02 else np.nan)\n",
        "        uts = float(sig.max()); i_uts = int(sig.argmax()); strain_uts = float(eps[i_uts])\n",
        "        frac_strain = float(eps.max()); frac_stress = float(sig[-1])\n",
        "        toughness = integrate_toughness(eps, sig, None)\n",
        "        s5  = stress_at(f, 5, lo, hi); s10 = stress_at(f, 10, lo, hi)\n",
        "        s15 = stress_at(f, 15, lo, hi); s20 = stress_at(f, 20, lo, hi)\n",
        "        sec_0_15 = secant_modulus(f, 0.00, 0.15) if hi >= 0.15 else np.nan\n",
        "        mat_type, mat_level = parse_label_recipe(lab)\n",
        "        rows.append({\n",
        "            \"label\": lab, \"mat_type\": mat_type, \"mat_level\": mat_level,\n",
        "            \"E0_5_kPa\": E0_5, \"E5_10_kPa\": E5_10, \"TanE10_kPa\": TanE10,\n",
        "            \"Yield_strain_frac\": eps_y if eps_y is not None else np.nan,\n",
        "            \"Yield_stress_kPa\":  sig_y if sig_y is not None else np.nan,\n",
        "            \"Resilience_kJ_m3\":  resilience,\n",
        "            \"UTS_kPa\": uts, \"Strain_UTS_frac\": strain_uts,\n",
        "            \"Fracture_strain_frac\": frac_strain, \"Fracture_stress_kPa\": frac_stress,\n",
        "            \"Toughness_kJ_m3\": toughness,\n",
        "            \"Stress@5%_kPa\": s5, \"Stress@10%_kPa\": s10, \"Stress@15%_kPa\": s15, \"Stress@20%_kPa\": s20,\n",
        "            \"Secant_0_15_kPa\": sec_0_15\n",
        "        })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# ---------- Derive properties ----------\n",
        "props_df = derive_properties_table(DATA_PATH)\n",
        "if props_df.empty:\n",
        "    raise RuntimeError(\"No valid stress–strain pairs found. Check column names like Strain(%)_<label> and Stress(kPa)_<label>.\")\n",
        "\n",
        "# ---------- Load composition (optional) ----------\n",
        "def load_composition() -> Optional[pd.DataFrame]:\n",
        "    comp_df = None\n",
        "    if COMPOSITION_PATH and Path(COMPOSITION_PATH).exists():\n",
        "        if COMPOSITION_PATH.lower().endswith(\".csv\"):\n",
        "            comp_df = pd.read_csv(COMPOSITION_PATH)\n",
        "        else:\n",
        "            comp_df = pd.read_excel(COMPOSITION_PATH)\n",
        "    elif COMPOSITION_SHEET:\n",
        "        comp_df = pd.read_excel(DATA_PATH, sheet_name=COMPOSITION_SHEET)\n",
        "    return comp_df\n",
        "\n",
        "comp_df = load_composition()\n",
        "\n",
        "# ---------- Build X (recipe) and Y (toughness) ----------\n",
        "TARGET_KEY = \"Toughness_kJ_m3\"\n",
        "TARGETS = {TARGET_KEY: TARGET_TOUGHNESS} # Ensure TARGETS dict is created\n",
        "\n",
        "if comp_df is not None and len(COMPOSITION_COLS) > 0 and all(c in comp_df.columns for c in COMPOSITION_COLS) and \"label\" in comp_df.columns:\n",
        "    MODE = \"composition\"\n",
        "    df_model = props_df.merge(comp_df[[\"label\"] + COMPOSITION_COLS], on=\"label\", how=\"inner\")\n",
        "    XY = df_model[[\"label\"] + COMPOSITION_COLS + [TARGET_KEY]].dropna(subset=COMPOSITION_COLS + [TARGET_KEY])\n",
        "    X = XY[COMPOSITION_COLS].astype(float)\n",
        "    Y = XY[[TARGET_KEY]].astype(float)\n",
        "else:\n",
        "    MODE = \"label_fallback\"\n",
        "    print(\"[Warn] No composition table recognized. Falling back to ('mat_type','mat_level') from labels.\")\n",
        "    XY = props_df[[\"label\",\"mat_type\",\"mat_level\", TARGET_KEY]].dropna(subset=[TARGET_KEY])\n",
        "    X = XY[[\"mat_type\",\"mat_level\"]].copy()\n",
        "    Y = XY[[TARGET_KEY]].astype(float)\n",
        "\n",
        "if len(X) < 2:\n",
        "    raise RuntimeError(\"Not enough rows to train for Toughness. Ensure at least 2 valid samples with non-NaN Toughness and recipe info.\")\n",
        "\n",
        "# ---------- Model pipeline ----------\n",
        "if MODE == \"composition\":\n",
        "    preprocess = ColumnTransformer([(\"num\", StandardScaler(), X.columns.tolist())])\n",
        "else:\n",
        "    preprocess = ColumnTransformer([\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), [\"mat_type\"]),\n",
        "        (\"num\", StandardScaler(), [\"mat_level\"]),\n",
        "    ])\n",
        "\n",
        "base = RandomForestRegressor(n_estimators=600, random_state=42, n_jobs=-1)\n",
        "reg = Pipeline([(\"prep\", preprocess), (\"rf\", MultiOutputRegressor(base))])\n",
        "\n",
        "ts = 0.33 if len(X) >= 6 else 0.0\n",
        "if ts > 0:\n",
        "    X_tr, X_te, Y_tr, Y_te = train_test_split(X, Y, test_size=ts, random_state=42)\n",
        "else:\n",
        "    X_tr, Y_tr = X, Y\n",
        "    X_te, Y_te = X.iloc[:0], Y.iloc[:0]\n",
        "\n",
        "reg.fit(X_tr, Y_tr)\n",
        "\n",
        "if len(X_te) > 0:\n",
        "    Y_hat = reg.predict(X_te)\n",
        "    r2 = r2_score(Y_te.iloc[:, 0], Y_hat[:, 0])\n",
        "    mae = mean_absolute_error(Y_te.iloc[:, 0], Y_hat[:, 0])\n",
        "    print(f\"[Holdout] Toughness  R2={r2:6.3f}  MAE={mae:8.3f}\")\n",
        "else:\n",
        "    print(\"Trained on all rows (small dataset).\")\n",
        "\n",
        "# ---------- Forward design for Toughness ----------\n",
        "tgt = np.array([TARGET_TOUGHNESS], float)  # single target\n",
        "\n",
        "# Separate bounds for numeric and handle categoricals\n",
        "bounds = []\n",
        "cont_cols = [c for c in X.columns if np.issubdtype(X[c].dtype, np.number)]\n",
        "cat_cols = [c for c in X.columns if X[c].dtype == \"O\"]\n",
        "discrete_enums = {c: sorted(X[c].unique().tolist()) for c in cat_cols}\n",
        "\n",
        "for c in cont_cols:\n",
        "    lo, hi = float(X[c].min()), float(X[c].max())\n",
        "    span = hi - lo if hi > lo else 1.0\n",
        "    bounds.append((lo - 0.05*span, hi + 0.05*span))\n",
        "\n",
        "# Build a template row for prediction\n",
        "def build_row(cont_vec, cat_choice):\n",
        "    row = {}\n",
        "    j = 0\n",
        "    for col in X.columns:\n",
        "        if col in cat_cols:\n",
        "            row[col] = cat_choice[col]\n",
        "        else:\n",
        "            row[col] = float(cont_vec[j]); j += 1\n",
        "    return pd.DataFrame([row], columns=X.columns) # Ensure columns order matches X\n",
        "\n",
        "# Sum-to-constant constraint (if composition percentages)\n",
        "constraints = []\n",
        "if MODE == \"composition\" and COMPOSITION_TOTAL is not None:\n",
        "    def sum_eq(cont_vec, cont_cols=cont_cols, total=COMPOSITION_TOTAL):\n",
        "        # This assumes cont_cols are the composition components that sum\n",
        "        return float(np.sum(cont_vec) - total)\n",
        "    constraints.append({\"type\": \"eq\", \"fun\": sum_eq})\n",
        "\n",
        "# penalty for going outside historical range (soft corners)\n",
        "if cont_cols:\n",
        "    mins = X[cont_cols].min().values\n",
        "    maxs = X[cont_cols].max().values\n",
        "else:\n",
        "    mins = np.array([])\n",
        "    maxs = np.array([])\n",
        "\n",
        "\n",
        "def objective(x, cat_choice): # Modified to accept cat_choice\n",
        "    row = build_row(x, cat_choice) # Use build_row with cat_choice\n",
        "    pred = reg.predict(row)[0]   # shape (1,)\n",
        "    # Weighted MSE + MAPE (weights from train variance, robust to scale)\n",
        "    var = np.var(Y_tr.values, axis=0) if len(Y_tr) else np.var(Y.values, axis=0)\n",
        "    w = 1.0 / np.where(var <= 1e-12, 1.0, var)\n",
        "    eps = 1e-8\n",
        "    # Use Y.columns directly to slice prediction\n",
        "    y_pred_targets = pred[[Y.columns.get_loc(k) for k in Y.columns]]\n",
        "    mse = np.mean(w * (y_pred_targets - tgt)**2)\n",
        "    mape = np.mean(np.abs(y_pred_targets - tgt) / (np.abs(tgt) + eps))\n",
        "    base = 0.5*mse + 0.5*mape\n",
        "    # Soft penalty outside observed domain\n",
        "    over_low = np.maximum(0.0, mins - x)\n",
        "    over_high = np.maximum(0.0, x - maxs)\n",
        "    return base + 1e-3 * np.sum(over_low**2 + over_high**2)\n",
        "\n",
        "# Start from median composition/knob values\n",
        "x0_cont = X[cont_cols].median().values if cont_cols else np.array([])\n",
        "\n",
        "# Enumerate categoricals; minimize continuous for each category combination\n",
        "from scipy.optimize import minimize\n",
        "best = {\"loss\": np.inf, \"row\": None, \"yhat\": None}\n",
        "\n",
        "cat_product = [{}]\n",
        "if cat_cols:\n",
        "    import itertools\n",
        "    cat_values = [discrete_enums[c] for c in cat_cols]\n",
        "    cat_product = [{c: v for c, v in zip(cat_cols, combo)} for combo in itertools.product(*cat_values)]\n",
        "\n",
        "for cat_choice in cat_product:\n",
        "    if not cont_cols:\n",
        "        # No continuous features — just evaluate categorical combo\n",
        "        dfrow = build_row(np.array([]), cat_choice)\n",
        "        # Evaluate loss with objective directly, passing empty array for continuous and the cat_choice\n",
        "        loss = objective(np.array([]), cat_choice)\n",
        "        yhat = reg.predict(dfrow)[0]\n",
        "        if loss < best[\"loss\"]:\n",
        "            best.update({\"loss\": loss, \"row\": dfrow, \"yhat\": yhat})\n",
        "        continue\n",
        "\n",
        "    def _wrap(x):\n",
        "        return objective(x, cat_choice) # Pass cat_choice to objective\n",
        "\n",
        "    result = minimize(\n",
        "        _wrap, x0_cont,\n",
        "        method=\"SLSQP\",\n",
        "        bounds=bounds,\n",
        "        constraints=constraints,\n",
        "        options={\"maxiter\": 1000, \"ftol\": 1e-9, \"disp\": False}\n",
        "    )\n",
        "\n",
        "    if result.success:\n",
        "        loss = result.fun\n",
        "        dfrow = build_row(result.x, cat_choice)\n",
        "        yhat = reg.predict(dfrow)[0]\n",
        "        if loss < best[\"loss\"]:\n",
        "            best.update({\"loss\": loss, \"row\": dfrow, \"yhat\": yhat})\n",
        "    else:\n",
        "        print(f\"[Warn] Optimization failed for {cat_choice}: {result.message}\")\n",
        "\n",
        "\n",
        "if best[\"row\"] is None:\n",
        "     raise RuntimeError(\"Optimization failed for all combinations.\")\n",
        "\n",
        "\n",
        "opt_recipe = best[\"row\"]\n",
        "opt_pred = pd.DataFrame([best[\"yhat\"]], columns=Y.columns) # Use Y.columns for full prediction columns\n",
        "\n",
        "print(\"\\n================ RESULTS (Toughness only) ================\")\n",
        "print(f\"Mode: {'COMPOSITION → PROPERTIES' if MODE=='composition' else 'LABEL FALLBACK (no composition provided)'}\")\n",
        "print(\"\\nRecommended recipe:\")\n",
        "display_cols = COMPOSITION_COLS if MODE == \"composition\" else X.columns.tolist() # Define display_cols here\n",
        "print(opt_recipe[display_cols].to_string(index=False))\n",
        "print(\"\\nPredicted Toughness_kJ_m3:\")\n",
        "print(opt_pred[[TARGET_KEY]].to_string(index=False)) # Print only the target key\n",
        "\n",
        "# Save artifacts next to your Drive file\n",
        "out_dir = Path(DATA_PATH).parent\n",
        "props_out = out_dir / \"_derived_properties_table.csv\"\n",
        "opt_out = out_dir / \"_optimal_recipe_Toughness.csv\"\n",
        "props_df.to_csv(props_out, index=False)\n",
        "pd.concat({\"recipe_opt\": opt_recipe.reset_index(drop=True),\n",
        "           \"predicted_Toughness\": opt_pred[[TARGET_KEY]].reset_index(drop=True)}, axis=1).to_csv(opt_out, index=False) # Save only the target key in the report\n",
        "print(f\"\\nSaved:\\n  {props_out}\\n  {opt_out}\")\n",
        "\n",
        "# If you hit \"Not enough rows\", check coverage:\n",
        "# print(props_df[[\"Toughness_kJ_m3\"]].notna().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tRpbb_C9Noc",
        "outputId": "d5ca9430-fd45-4cfa-fedd-4bb1f725b8e1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "[Warn] No composition table recognized. Falling back to ('mat_type','mat_level') from labels.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-505269262.py:98: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
            "  return float(np.trapz(f(xs), xs))  # kJ/m^3 if stress in kPa and strain is fraction\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Holdout] Toughness  R2=-0.320  MAE=   0.835\n",
            "\n",
            "================ RESULTS (Toughness only) ================\n",
            "Mode: LABEL FALLBACK (no composition provided)\n",
            "\n",
            "Recommended recipe:\n",
            "mat_type  mat_level\n",
            "     Cel        5.0\n",
            "\n",
            "Predicted Toughness_kJ_m3:\n",
            " Toughness_kJ_m3\n",
            "        4.537019\n",
            "\n",
            "Saved:\n",
            "  /content/drive/MyDrive/AI Training/_derived_properties_table.csv\n",
            "  /content/drive/MyDrive/AI Training/_optimal_recipe_Toughness.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Strain at UTS only"
      ],
      "metadata": {
        "id": "foJdf5Ho_ToM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================\n",
        "# One-cell: Strain at UTS only (design recipe/composition)\n",
        "# ===================================================\n",
        "!pip -q install numpy pandas scikit-learn scipy\n",
        "\n",
        "# --- Mount Google Drive for your path ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import Dict, Tuple, Optional, List\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "# ---------------- USER CONFIG ----------------\n",
        "# 1) Stress–strain file (paired columns: Strain(%)_<label>, Stress(kPa)_<label>)\n",
        "DATA_PATH = \"/content/drive/MyDrive/AI Training/paam_hydrogel_stress_strain_data_v2.xlsx\"\n",
        "\n",
        "# 2) Composition source (choose ONE): separate file OR a sheet inside DATA_PATH\n",
        "COMPOSITION_PATH = \"\"                 # e.g., \"/content/drive/MyDrive/AI Training/composition_table.xlsx\" or \".csv\"\n",
        "COMPOSITION_SHEET = \"\"                # e.g., \"composition\" if stored as a sheet in DATA_PATH\n",
        "\n",
        "# 3) Composition columns (true chemistry knobs). Leave empty to fallback to ('mat_type','mat_level').\n",
        "COMPOSITION_COLS: List[str] = [\n",
        "    # Example: \"AAm_wt\", \"BIS_wt\", \"APS_wt\", \"TEMED_wt\", \"Water_wt\"\n",
        "]\n",
        "\n",
        "# 4) If composition columns are wt% (or any total constraint), set sum target; else set None.\n",
        "COMPOSITION_TOTAL = 100.0   # or None if not applicable\n",
        "\n",
        "# 5) Target STRAIN AT UTS (fraction). Example: 0.18 = 18% strain.\n",
        "TARGET_STRAIN_UTS = 0.18\n",
        "# --------------------------------------------\n",
        "\n",
        "# ======== Stress–strain utilities ========\n",
        "def find_pairs(df: pd.DataFrame) -> Tuple[Dict[str, str], Dict[str, str], list]:\n",
        "    strain_cols = [c for c in df.columns if c.lower().startswith(\"strain\")]\n",
        "    stress_cols = [c for c in df.columns if c.lower().startswith(\"stress\")]\n",
        "    def lab(c): return c.split(\"_\", 1)[1] if \"_\" in c else None\n",
        "    labels_strain = {lab(c): c for c in strain_cols if lab(c) is not None}\n",
        "    labels_stress = {lab(c): c for c in stress_cols if lab(c) is not None}\n",
        "    labels = sorted(set(labels_strain).intersection(labels_stress))\n",
        "    return labels_strain, labels_stress, labels\n",
        "\n",
        "def to_fraction(eps_raw: np.ndarray) -> np.ndarray:\n",
        "    # Data pattern: 0, 500, 1000 -> 0.0%, 5.0%, 10.0% -> 0.0, 0.05, 0.10 (fraction)\n",
        "    return (eps_raw.astype(float)/100.0)/100.0\n",
        "\n",
        "def ensure_sorted(eps: np.ndarray, sig: np.ndarray):\n",
        "    idx = np.argsort(eps)\n",
        "    return eps[idx], sig[idx]\n",
        "\n",
        "def interp_curve(eps: np.ndarray, sig: np.ndarray):\n",
        "    x = np.asarray(eps, float); y = np.asarray(sig, float)\n",
        "    lo, hi = float(x.min()), float(x.max())\n",
        "    def f(xq):\n",
        "        xq = np.asarray(xq, float)\n",
        "        return np.interp(np.clip(xq, lo, hi), x, y)\n",
        "    return f, (lo, hi)\n",
        "\n",
        "def linear_fit_window(eps: np.ndarray, sig: np.ndarray, a: float, b: float):\n",
        "    if b <= a: return None\n",
        "    f, (lo, hi) = interp_curve(eps, sig)\n",
        "    a, b = max(lo, a), min(hi, b)\n",
        "    if b <= a: return None\n",
        "    xs = np.linspace(a, b, 20); ys = f(xs)\n",
        "    X = np.vstack([xs, np.ones_like(xs)]).T\n",
        "    slope, intercept = np.linalg.lstsq(X, ys, rcond=None)[0]\n",
        "    return float(slope), float(intercept)\n",
        "\n",
        "def secant_modulus(f, a: float, b: float):\n",
        "    if b <= a: return np.nan\n",
        "    return float((f(b) - f(a)) / (b - a))\n",
        "\n",
        "def yield_offset(eps: np.ndarray, sig: np.ndarray, E_init: Optional[float], offset: float = 0.002):\n",
        "    if E_init is None or not np.isfinite(E_init): return None, None\n",
        "    f, (lo, hi) = interp_curve(eps, sig)\n",
        "    xs = np.linspace(lo, hi, 400)\n",
        "    g = f(xs) - E_init*(xs - offset)\n",
        "    s = np.sign(g); idx = np.where(np.diff(s) != 0)[0]\n",
        "    if len(idx) == 0: return None, None\n",
        "    i = idx[0]; x0, x1 = xs[i], xs[i+1]; y0, y1 = g[i], g[i+1]\n",
        "    eps_y = x0 if (y1 - y0) == 0 else x0 - y0*(x1 - x0)/(y1 - y0)\n",
        "    return float(eps_y), float(f(eps_y))\n",
        "\n",
        "def integrate_toughness(eps: np.ndarray, sig: np.ndarray, up_to: Optional[float] = None) -> float:\n",
        "    f, (lo, hi) = interp_curve(eps, sig)\n",
        "    b = hi if up_to is None else max(lo, min(hi, up_to))\n",
        "    xs = np.linspace(lo, b, 400)\n",
        "    return float(np.trapz(f(xs), xs))\n",
        "\n",
        "def stress_at(f, p: float, lo: float, hi: float):\n",
        "    x = p/100.0\n",
        "    return float(f(x)) if lo <= x <= hi else np.nan\n",
        "\n",
        "def parse_label_recipe(label: str):\n",
        "    import re\n",
        "    m = re.match(r\"([A-Za-z]+)(\\d+)?\", label)\n",
        "    mat_type = m.group(1) if m else None\n",
        "    mat_level = float(m.group(2)) if (m and m.group(2)) else 0.0\n",
        "    return mat_type, mat_level\n",
        "\n",
        "def derive_properties_table(stress_strain_path: str) -> pd.DataFrame:\n",
        "    df = pd.read_excel(stress_strain_path)\n",
        "    labels_strain, labels_stress, labels = find_pairs(df)\n",
        "    rows = []\n",
        "    for lab in labels:\n",
        "        eps_raw = df[labels_strain[lab]].to_numpy(dtype=float)\n",
        "        sig_raw = df[labels_stress[lab]].to_numpy(dtype=float)\n",
        "        m = np.isfinite(eps_raw) & np.isfinite(sig_raw)\n",
        "        eps_raw, sig_raw = eps_raw[m], sig_raw[m]\n",
        "        if len(eps_raw) < 3: continue\n",
        "        eps = to_fraction(eps_raw)\n",
        "        eps, sig = ensure_sorted(eps, sig_raw)\n",
        "        f, (lo, hi) = interp_curve(eps, sig)\n",
        "\n",
        "        # Core properties\n",
        "        E0_5  = (linear_fit_window(eps, sig, 0.00, 0.05) or (np.nan, np.nan))[0]\n",
        "        E5_10 = secant_modulus(f, 0.05, 0.10) if hi >= 0.10 else np.nan\n",
        "        TanE10 = (linear_fit_window(eps, sig, 0.08, 0.12) or (np.nan, np.nan))[0] if hi >= 0.12 else np.nan\n",
        "        eps_y, sig_y = yield_offset(eps, sig, E0_5, offset=0.002)\n",
        "        resilience = integrate_toughness(eps, sig, up_to=eps_y) if eps_y is not None else (integrate_toughness(eps, sig, up_to=0.02) if hi >= 0.02 else np.nan)\n",
        "        uts = float(sig.max()); i_uts = int(sig.argmax()); strain_uts = float(eps[i_uts])\n",
        "        frac_strain = float(eps.max()); frac_stress = float(sig[-1])\n",
        "        toughness = integrate_toughness(eps, sig, None)\n",
        "        s5  = stress_at(f, 5, lo, hi); s10 = stress_at(f, 10, lo, hi)\n",
        "        s15 = stress_at(f, 15, lo, hi); s20 = stress_at(f, 20, lo, hi)\n",
        "        sec_0_15 = secant_modulus(f, 0.00, 0.15) if hi >= 0.15 else np.nan\n",
        "\n",
        "        mat_type, mat_level = parse_label_recipe(lab)\n",
        "        rows.append({\n",
        "            \"label\": lab, \"mat_type\": mat_type, \"mat_level\": mat_level,\n",
        "            \"E0_5_kPa\": E0_5, \"E5_10_kPa\": E5_10, \"TanE10_kPa\": TanE10,\n",
        "            \"Yield_strain_frac\": eps_y if eps_y is not None else np.nan,\n",
        "            \"Yield_stress_kPa\":  sig_y if sig_y is not None else np.nan,\n",
        "            \"Resilience_kJ_m3\":  resilience,\n",
        "            \"UTS_kPa\": uts, \"Strain_UTS_frac\": strain_uts,\n",
        "            \"Fracture_strain_frac\": frac_strain, \"Fracture_stress_kPa\": frac_stress,\n",
        "            \"Toughness_kJ_m3\": toughness,\n",
        "            \"Stress@5%_kPa\": s5, \"Stress@10%_kPa\": s10, \"Stress@15%_kPa\": s15, \"Stress@20%_kPa\": s20,\n",
        "            \"Secant_0_15_kPa\": sec_0_15\n",
        "        })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# ---------- Derive properties ----------\n",
        "props_df = derive_properties_table(DATA_PATH)\n",
        "if props_df.empty:\n",
        "    raise RuntimeError(\"No valid stress–strain pairs found. Check column names like Strain(%)_<label> and Stress(kPa)_<label>.\")\n",
        "\n",
        "# ---------- Load composition (optional) ----------\n",
        "def load_composition() -> Optional[pd.DataFrame]:\n",
        "    comp_df = None\n",
        "    if COMPOSITION_PATH and Path(COMPOSITION_PATH).exists():\n",
        "        if COMPOSITION_PATH.lower().endswith(\".csv\"):\n",
        "            comp_df = pd.read_csv(COMPOSITION_PATH)\n",
        "        else:\n",
        "            comp_df = pd.read_excel(COMPOSITION_PATH)\n",
        "    elif COMPOSITION_SHEET:\n",
        "        comp_df = pd.read_excel(DATA_PATH, sheet_name=COMPOSITION_SHEET)\n",
        "    return comp_df\n",
        "\n",
        "comp_df = load_composition()\n",
        "\n",
        "# ---------- Build X (recipe) and Y (strain at UTS) ----------\n",
        "TARGET_KEY = \"Strain_UTS_frac\"  # single target\n",
        "\n",
        "if comp_df is not None and len(COMPOSITION_COLS) > 0 and all(c in comp_df.columns for c in COMPOSITION_COLS) and \"label\" in comp_df.columns:\n",
        "    MODE = \"composition\"\n",
        "    df_model = props_df.merge(comp_df[[\"label\"] + COMPOSITION_COLS], on=\"label\", how=\"inner\")\n",
        "    XY = df_model[[\"label\"] + COMPOSITION_COLS + [TARGET_KEY]].dropna(subset=COMPOSITION_COLS + [TARGET_KEY])\n",
        "    X = XY[COMPOSITION_COLS].astype(float)\n",
        "    y = XY[TARGET_KEY].astype(float).values  # 1D vector\n",
        "else:\n",
        "    MODE = \"label_fallback\"\n",
        "    print(\"[Warn] No composition table recognized. Falling back to ('mat_type','mat_level') from labels.\")\n",
        "    XY = props_df[[\"label\",\"mat_type\",\"mat_level\", TARGET_KEY]].dropna(subset=[TARGET_KEY])\n",
        "    X = XY[[\"mat_type\",\"mat_level\"]].copy()\n",
        "    y = XY[TARGET_KEY].astype(float).values\n",
        "\n",
        "if len(X) < 2:\n",
        "    raise RuntimeError(\"Not enough rows to train for Strain_UTS_frac. Need at least 2 valid samples.\")\n",
        "\n",
        "# ---------- Model pipeline ----------\n",
        "if MODE == \"composition\":\n",
        "    preprocess = ColumnTransformer([(\"num\", StandardScaler(), X.columns.tolist())])\n",
        "else:\n",
        "    preprocess = ColumnTransformer([\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), [\"mat_type\"]),\n",
        "        (\"num\", StandardScaler(), [\"mat_level\"]),\n",
        "    ])\n",
        "\n",
        "reg = Pipeline([(\"prep\", preprocess),\n",
        "                (\"rf\", RandomForestRegressor(n_estimators=600, random_state=42, n_jobs=-1))])\n",
        "\n",
        "ts = 0.33 if len(X) >= 6 else 0.0\n",
        "if ts > 0:\n",
        "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=ts, random_state=42)\n",
        "else:\n",
        "    X_tr, y_tr = X, y\n",
        "    X_te, y_te = X.iloc[:0], np.array([])\n",
        "\n",
        "reg.fit(X_tr, y_tr)\n",
        "\n",
        "if len(X_te) > 0:\n",
        "    y_hat = reg.predict(X_te)\n",
        "    print(f\"[Holdout] Strain_UTS_frac  R2={r2_score(y_te, y_hat):6.3f}  MAE={mean_absolute_error(y_te, y_hat):8.4f}\")\n",
        "else:\n",
        "    print(\"Trained on all rows (small dataset).\")\n",
        "\n",
        "# ---------- Forward design for Strain_UTS_frac ----------\n",
        "tgt = float(TARGET_STRAIN_UTS)\n",
        "mins, maxs = X.min().values, X.max().values\n",
        "\n",
        "# Helper to evaluate loss for a candidate row\n",
        "def _loss_from_row(dfrow):\n",
        "    pred = float(reg.predict(dfrow).ravel()[0])\n",
        "    # Weighted MSE + MAPE (robust)\n",
        "    var = float(np.var(y_tr)) if len(y_tr) else float(np.var(y))\n",
        "    w = 1.0 if var <= 1e-12 else 1.0/var\n",
        "    eps = 1e-8\n",
        "    mse = w * (pred - tgt)**2\n",
        "    mape = abs(pred - tgt) / (abs(tgt) + eps)\n",
        "    base = 0.5*mse + 0.5*mape\n",
        "    return base, pred\n",
        "\n",
        "# ===== Case A: composition mode — continuous optimization over composition columns =====\n",
        "if MODE == \"composition\":\n",
        "    # Bounds with ±5% padding\n",
        "    bounds = []\n",
        "    for c in X.columns:\n",
        "        lo, hi = float(X[c].min()), float(X[c].max())\n",
        "        span = hi - lo if hi > lo else 1.0\n",
        "        bounds.append((lo - 0.05*span, hi + 0.05*span))\n",
        "\n",
        "    # Sum-to-constant constraint if set (e.g., wt% totals to 100)\n",
        "    constraints = []\n",
        "    if COMPOSITION_TOTAL is not None:\n",
        "        def sum_eq(x, total=COMPOSITION_TOTAL):\n",
        "            return float(np.sum(x) - total)\n",
        "        constraints.append({\"type\": \"eq\", \"fun\": sum_eq})\n",
        "\n",
        "    def objective(x):\n",
        "        row = pd.DataFrame([x], columns=X.columns)\n",
        "        base, _ = _loss_from_row(row)\n",
        "        # Soft penalty for going outside historical domain\n",
        "        over_low = np.maximum(0.0, mins - x)\n",
        "        over_high = np.maximum(0.0, x - maxs)\n",
        "        return base + 1e-3*np.sum(over_low**2 + over_high**2)\n",
        "\n",
        "    x0 = X.median().values\n",
        "    res = minimize(objective, x0, bounds=bounds, constraints=constraints, method=\"SLSQP\",\n",
        "                   options={\"maxiter\": 1000, \"ftol\": 1e-9, \"disp\": False})\n",
        "    x_opt = res.x\n",
        "    opt_row = pd.DataFrame([x_opt], columns=X.columns)\n",
        "    _, pred_val = _loss_from_row(opt_row)\n",
        "    mode_label = \"COMPOSITION → PROPERTIES\"\n",
        "\n",
        "# ===== Case B: label_fallback — enumerate mat_type (discrete) + optimize mat_level (continuous) =====\n",
        "else:\n",
        "    mat_types = sorted(X[\"mat_type\"].unique().tolist())\n",
        "    level_min, level_max = float(X[\"mat_level\"].min()), float(X[\"mat_level\"].max())\n",
        "    span = max(1e-9, level_max - level_min)\n",
        "    bounds = [(level_min - 0.05*span, level_max + 0.05*span)]\n",
        "\n",
        "    best = {\"loss\": np.inf, \"row\": None, \"pred\": None}\n",
        "\n",
        "    for mt in mat_types:\n",
        "        def objective(x):\n",
        "            row = pd.DataFrame([{\"mat_type\": mt, \"mat_level\": float(x[0])}])\n",
        "            base, _ = _loss_from_row(row)\n",
        "            # Soft penalty outside observed level range\n",
        "            over_low = max(0.0, level_min - x[0])\n",
        "            over_high = max(0.0, x[0] - level_max)\n",
        "            return base + 1e-3*(over_low**2 + over_high**2)\n",
        "\n",
        "        x0 = np.array([(level_min + level_max)/2.0])\n",
        "        res = minimize(objective, x0, bounds=bounds, method=\"SLSQP\",\n",
        "                       options={\"maxiter\": 500, \"ftol\": 1e-9, \"disp\": False})\n",
        "        row = pd.DataFrame([{\"mat_type\": mt, \"mat_level\": float(res.x[0])}])\n",
        "        loss, pred = _loss_from_row(row)\n",
        "        if loss < best[\"loss\"]:\n",
        "            best.update({\"loss\": loss, \"row\": row, \"pred\": pred})\n",
        "\n",
        "    opt_row = best[\"row\"]\n",
        "    pred_val = best[\"pred\"]\n",
        "    mode_label = \"LABEL FALLBACK (no composition provided)\"\n",
        "\n",
        "# ---------- Report & save ----------\n",
        "print(\"\\n================ RESULTS (Strain at UTS only) ================\")\n",
        "print(f\"Mode: {mode_label}\")\n",
        "print(\"\\nRecommended recipe (composition or knobs):\")\n",
        "print(opt_row.to_string(index=False))\n",
        "print(\"\\nPredicted Strain_UTS_frac:\")\n",
        "print(pd.DataFrame([pred_val], columns=[TARGET_KEY]).to_string(index=False))\n",
        "\n",
        "# Save artifacts next to your Drive file\n",
        "out_dir = Path(DATA_PATH).parent\n",
        "props_out = out_dir / \"_derived_properties_table.csv\"\n",
        "opt_out = out_dir / \"_optimal_recipe_StrainUTS.csv\"\n",
        "props_df.to_csv(props_out, index=False)\n",
        "pd.concat({\"recipe_opt\": opt_row.reset_index(drop=True),\n",
        "           \"predicted_Strain_UTS\": pd.DataFrame([pred_val], columns=[TARGET_KEY]).reset_index(drop=True)}, axis=1).to_csv(opt_out, index=False)\n",
        "print(f\"\\nSaved:\\n  {props_out}\\n  {opt_out}\")\n",
        "\n",
        "# If you get \"Not enough rows\", check coverage:\n",
        "# print(props_df[[TARGET_KEY]].notna().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwaoPQIT_Hiq",
        "outputId": "9304863a-94c4-44bc-d489-09e99dfc962b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-586796648.py:97: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
            "  return float(np.trapz(f(xs), xs))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Warn] No composition table recognized. Falling back to ('mat_type','mat_level') from labels.\n",
            "[Holdout] Strain_UTS_frac  R2= 0.065  MAE=  0.0071\n",
            "\n",
            "================ RESULTS (Strain at UTS only) ================\n",
            "Mode: LABEL FALLBACK (no composition provided)\n",
            "\n",
            "Recommended recipe (composition or knobs):\n",
            "mat_type  mat_level\n",
            "     Cel       10.0\n",
            "\n",
            "Predicted Strain_UTS_frac:\n",
            " Strain_UTS_frac\n",
            "        0.156046\n",
            "\n",
            "Saved:\n",
            "  /content/drive/MyDrive/AI Training/_derived_properties_table.csv\n",
            "  /content/drive/MyDrive/AI Training/_optimal_recipe_StrainUTS.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you have real composition fields (e.g., AAm_wt, BIS_wt, APS_wt, …), list them in COMPOSITION_COLS and keep COMPOSITION_TOTAL=100.0 if they are wt%. The output then becomes a true chemical recipe satisfying the sum constraint.\n",
        "\n",
        "Without composition, the code optimizes label-derived knobs (mat_type, mat_level) instead—useful for exploration but not a full chemistry prescription.\n",
        "\n",
        "Start with a realistic TARGET_STRAIN_UTS within your dataset’s observed range for best results; then explore beyond with caution."
      ],
      "metadata": {
        "id": "qOnTz_BoAsOT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Initial modulus (0–5%) only\n",
        "Here’s a single, copy-paste Colab cell to design a recipe for a target Initial Modulus (0–5%) (E0_5_kPa). It:\n",
        "\n",
        "reads your file from Google Drive (/content/drive/MyDrive/AI Training/paam_hydrogel_stress_strain_data_v2.xlsx),\n",
        "\n",
        "derives properties (including a robust calculation of E0_5_kPa),\n",
        "\n",
        "trains a model (recipe → E0_5_kPa), and\n",
        "\n",
        "finds a recipe/composition that hits your target.\n",
        "\n",
        "It supports either a true composition table (recommended) or a fallback using mat_type + mat_level parsed from labels.\n",
        "\n",
        "Set your target here: TARGET_E0_5_KPA = 550.0 (example).\n",
        "If you have an explicit composition table, fill COMPOSITION_PATH or COMPOSITION_SHEET and list numeric columns in COMPOSITION_COLS."
      ],
      "metadata": {
        "id": "dM0jRGSY_8pD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# One-cell: Initial Modulus (0–5%) only (E0_5_kPa)\n",
        "# Recipe/composition design to hit a target E0_5\n",
        "# =====================================================\n",
        "!pip -q install numpy pandas scikit-learn scipy\n",
        "\n",
        "# --- Mount Google Drive for your provided path ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import Dict, Tuple, Optional, List\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "# ---------------- USER CONFIG ----------------\n",
        "# 1) Stress–strain file (paired columns: Strain(%)_<label>, Stress(kPa)_<label>)\n",
        "DATA_PATH = \"/content/drive/MyDrive/AI Training/paam_hydrogel_stress_strain_data_v2.xlsx\"\n",
        "\n",
        "# 2) Composition source (choose ONE: separate file OR sheet within DATA_PATH)\n",
        "COMPOSITION_PATH = \"\"                 # e.g., \"/content/drive/MyDrive/AI Training/composition_table.xlsx\" or \".csv\"\n",
        "COMPOSITION_SHEET = \"\"                # e.g., \"composition\" if stored as a sheet in DATA_PATH\n",
        "\n",
        "# 3) Composition columns (true chemistry knobs). Leave empty to fallback to ('mat_type','mat_level').\n",
        "COMPOSITION_COLS: List[str] = [\n",
        "    # Example: \"AAm_wt\", \"BIS_wt\", \"APS_wt\", \"TEMED_wt\", \"Water_wt\"\n",
        "]\n",
        "\n",
        "# 4) If composition columns are wt% (or any total constraint), set sum target; else set None.\n",
        "COMPOSITION_TOTAL = 100.0   # or None if not applicable\n",
        "\n",
        "# 5) Target Initial Modulus (0–5%), in kPa:\n",
        "TARGET_E0_5_KPA = 550.0\n",
        "# --------------------------------------------\n",
        "\n",
        "# ======== Stress–strain utilities ========\n",
        "def find_pairs(df: pd.DataFrame) -> Tuple[Dict[str, str], Dict[str, str], list]:\n",
        "    strain_cols = [c for c in df.columns if c.lower().startswith(\"strain\")]\n",
        "    stress_cols = [c for c in df.columns if c.lower().startswith(\"stress\")]\n",
        "    def lab(c): return c.split(\"_\", 1)[1] if \"_\" in c else None\n",
        "    labels_strain = {lab(c): c for c in strain_cols if lab(c) is not None}\n",
        "    labels_stress = {lab(c): c for c in stress_cols if lab(c) is not None}\n",
        "    labels = sorted(set(labels_strain).intersection(labels_stress))\n",
        "    return labels_strain, labels_stress, labels\n",
        "\n",
        "def to_fraction(eps_raw: np.ndarray) -> np.ndarray:\n",
        "    # Typical pattern: 0, 500, 1000 → 0.0%, 5.0%, 10.0% → 0.0, 0.05, 0.10 (fraction)\n",
        "    return (eps_raw.astype(float)/100.0)/100.0\n",
        "\n",
        "def ensure_sorted(eps: np.ndarray, sig: np.ndarray):\n",
        "    idx = np.argsort(eps)\n",
        "    return eps[idx], sig[idx]\n",
        "\n",
        "def interp_curve(eps: np.ndarray, sig: np.ndarray):\n",
        "    x = np.asarray(eps, float); y = np.asarray(sig, float)\n",
        "    lo, hi = float(x.min()), float(x.max())\n",
        "    def f(xq):\n",
        "        xq = np.asarray(xq, float)\n",
        "        return np.interp(np.clip(xq, lo, hi), x, y)\n",
        "    return f, (lo, hi)\n",
        "\n",
        "def linear_fit_window(eps: np.ndarray, sig: np.ndarray, a: float, b: float):\n",
        "    \"\"\"\n",
        "    Linear fit of σ(ε) in [a,b] using a dense interpolation (20 pts).\n",
        "    Returns slope (kPa per strain-fraction) and intercept.\n",
        "    If the full [0, 0.05] window isn't available, we shrink to what's available (down to 1%).\n",
        "    \"\"\"\n",
        "    f, (lo, hi) = interp_curve(eps, sig)\n",
        "    a_eff = max(lo, a)\n",
        "    b_eff = min(hi, b)\n",
        "    if b_eff - a_eff < 0.01:  # need at least ~1% strain span for a stable fit\n",
        "        return None\n",
        "    xs = np.linspace(a_eff, b_eff, 20)\n",
        "    ys = f(xs)\n",
        "    X = np.vstack([xs, np.ones_like(xs)]).T\n",
        "    slope, intercept = np.linalg.lstsq(X, ys, rcond=None)[0]\n",
        "    return float(slope), float(intercept)\n",
        "\n",
        "def secant_modulus(f, a: float, b: float):\n",
        "    if b <= a: return np.nan\n",
        "    return float((f(b) - f(a)) / (b - a))\n",
        "\n",
        "def yield_offset(eps: np.ndarray, sig: np.ndarray, E_init: Optional[float], offset: float = 0.002):\n",
        "    if E_init is None or not np.isfinite(E_init): return None, None\n",
        "    f, (lo, hi) = interp_curve(eps, sig)\n",
        "    xs = np.linspace(lo, hi, 400)\n",
        "    g = f(xs) - E_init*(xs - offset)\n",
        "    s = np.sign(g); idx = np.where(np.diff(s) != 0)[0]\n",
        "    if len(idx) == 0: return None, None\n",
        "    i = idx[0]; x0, x1 = xs[i], xs[i+1]; y0, y1 = g[i], g[i+1]\n",
        "    eps_y = x0 if (y1 - y0) == 0 else x0 - y0*(x1 - x0)/(y1 - y0)\n",
        "    return float(eps_y), float(f(eps_y))\n",
        "\n",
        "def integrate_toughness(eps: np.ndarray, sig: np.ndarray, up_to: Optional[float] = None) -> float:\n",
        "    f, (lo, hi) = interp_curve(eps, sig)\n",
        "    b = hi if up_to is None else max(lo, min(hi, up_to))\n",
        "    xs = np.linspace(lo, b, 400)\n",
        "    return float(np.trapz(f(xs), xs))\n",
        "\n",
        "def stress_at(f, p: float, lo: float, hi: float):\n",
        "    x = p/100.0\n",
        "    return float(f(x)) if lo <= x <= hi else np.nan\n",
        "\n",
        "def parse_label_recipe(label: str):\n",
        "    import re\n",
        "    m = re.match(r\"([A-Za-z]+)(\\d+)?\", label)\n",
        "    mat_type = m.group(1) if m else None\n",
        "    mat_level = float(m.group(2)) if (m and m.group(2)) else 0.0\n",
        "    return mat_type, mat_level\n",
        "\n",
        "def derive_properties_table(stress_strain_path: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Build a tidy table with per-label properties.\n",
        "    Crucially, E0_5_kPa is computed by fitting σ(ε) on [0, min(0.05, ε_max)], with a minimum 0.01 window.\n",
        "    \"\"\"\n",
        "    df = pd.read_excel(stress_strain_path)\n",
        "    labels_strain, labels_stress, labels = find_pairs(df)\n",
        "    rows = []\n",
        "    for lab in labels:\n",
        "        eps_raw = df[labels_strain[lab]].to_numpy(dtype=float)\n",
        "        sig_raw = df[labels_stress[lab]].to_numpy(dtype=float)\n",
        "        m = np.isfinite(eps_raw) & np.isfinite(sig_raw)\n",
        "        eps_raw, sig_raw = eps_raw[m], sig_raw[m]\n",
        "        if len(eps_raw) < 3:\n",
        "            continue\n",
        "\n",
        "        eps = to_fraction(eps_raw)\n",
        "        eps, sig = ensure_sorted(eps, sig_raw)\n",
        "        f, (lo, hi) = interp_curve(eps, sig)\n",
        "\n",
        "        # --- Initial modulus: fit over [0, min(0.05, hi)]\n",
        "        fit = linear_fit_window(eps, sig, 0.00, min(0.05, hi))\n",
        "        E0_5 = fit[0] if fit is not None else np.nan\n",
        "\n",
        "        # (The rest are optional; computed for context but not used in training)\n",
        "        E5_10 = secant_modulus(f, 0.05, 0.10) if hi >= 0.10 else np.nan\n",
        "        TanE10 = (linear_fit_window(eps, sig, 0.08, 0.12) or (np.nan, np.nan))[0] if hi >= 0.12 else np.nan\n",
        "        eps_y, sig_y = yield_offset(eps, sig, E0_5, offset=0.002)\n",
        "        resilience = integrate_toughness(eps, sig, up_to=eps_y) if eps_y is not None else (integrate_toughness(eps, sig, up_to=0.02) if hi >= 0.02 else np.nan)\n",
        "        uts = float(sig.max()); i_uts = int(sig.argmax()); strain_uts = float(eps[i_uts])\n",
        "        frac_strain = float(eps.max()); frac_stress = float(sig[-1])\n",
        "        toughness = integrate_toughness(eps, sig, None)\n",
        "        s5  = stress_at(f, 5, lo, hi); s10 = stress_at(f, 10, lo, hi)\n",
        "        s15 = stress_at(f, 15, lo, hi); s20 = stress_at(f, 20, lo, hi)\n",
        "        sec_0_15 = secant_modulus(f, 0.00, 0.15) if hi >= 0.15 else np.nan\n",
        "\n",
        "        mat_type, mat_level = parse_label_recipe(lab)\n",
        "        rows.append({\n",
        "            \"label\": lab, \"mat_type\": mat_type, \"mat_level\": mat_level,\n",
        "            \"E0_5_kPa\": E0_5, \"E5_10_kPa\": E5_10, \"TanE10_kPa\": TanE10,\n",
        "            \"Yield_strain_frac\": eps_y if eps_y is not None else np.nan,\n",
        "            \"Yield_stress_kPa\":  sig_y if sig_y is not None else np.nan,\n",
        "            \"Resilience_kJ_m3\":  resilience,\n",
        "            \"UTS_kPa\": uts, \"Strain_UTS_frac\": strain_uts,\n",
        "            \"Fracture_strain_frac\": frac_strain, \"Fracture_stress_kPa\": frac_stress,\n",
        "            \"Toughness_kJ_m3\": toughness,\n",
        "            \"Stress@5%_kPa\": s5, \"Stress@10%_kPa\": s10, \"Stress@15%_kPa\": s15, \"Stress@20%_kPa\": s20,\n",
        "            \"Secant_0_15_kPa\": sec_0_15\n",
        "        })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# ---------- Derive properties ----------\n",
        "props_df = derive_properties_table(DATA_PATH)\n",
        "if props_df.empty:\n",
        "    raise RuntimeError(\"No valid stress–strain pairs found. Check column names like Strain(%)_<label> and Stress(kPa)_<label>.\")\n",
        "\n",
        "# ---------- Load composition (optional) ----------\n",
        "def load_composition() -> Optional[pd.DataFrame]:\n",
        "    comp_df = None\n",
        "    if COMPOSITION_PATH and Path(COMPOSITION_PATH).exists():\n",
        "        if COMPOSITION_PATH.lower().endswith(\".csv\"):\n",
        "            comp_df = pd.read_csv(COMPOSITION_PATH)\n",
        "        else:\n",
        "            comp_df = pd.read_excel(COMPOSITION_PATH)\n",
        "    elif COMPOSITION_SHEET:\n",
        "        comp_df = pd.read_excel(DATA_PATH, sheet_name=COMPOSITION_SHEET)\n",
        "    return comp_df\n",
        "\n",
        "comp_df = load_composition()\n",
        "\n",
        "# ---------- Build X (recipe) and y (E0_5_kPa) ----------\n",
        "TARGET_KEY = \"E0_5_kPa\"  # single target\n",
        "\n",
        "if comp_df is not None and len(COMPOSITION_COLS) > 0 and all(c in comp_df.columns for c in COMPOSITION_COLS) and \"label\" in comp_df.columns:\n",
        "    MODE = \"composition\"\n",
        "    df_model = props_df.merge(comp_df[[\"label\"] + COMPOSITION_COLS], on=\"label\", how=\"inner\")\n",
        "    XY = df_model[[\"label\"] + COMPOSITION_COLS + [TARGET_KEY]].dropna(subset=COMPOSITION_COLS + [TARGET_KEY])\n",
        "    X = XY[COMPOSITION_COLS].astype(float)\n",
        "    y = XY[TARGET_KEY].astype(float).values\n",
        "else:\n",
        "    MODE = \"label_fallback\"\n",
        "    print(\"[Warn] No composition table recognized. Falling back to ('mat_type','mat_level') from labels.\")\n",
        "    XY = props_df[[\"label\",\"mat_type\",\"mat_level\", TARGET_KEY]].dropna(subset=[TARGET_KEY])\n",
        "    X = XY[[\"mat_type\",\"mat_level\"]].copy()\n",
        "    y = XY[TARGET_KEY].astype(float).values\n",
        "\n",
        "if len(X) < 2:\n",
        "    raise RuntimeError(\"Not enough rows to train for E0_5_kPa. Need at least 2 valid samples.\")\n",
        "\n",
        "# ---------- Model pipeline ----------\n",
        "if MODE == \"composition\":\n",
        "    preprocess = ColumnTransformer([(\"num\", StandardScaler(), X.columns.tolist())])\n",
        "else:\n",
        "    preprocess = ColumnTransformer([\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), [\"mat_type\"]),\n",
        "        (\"num\", StandardScaler(), [\"mat_level\"]),\n",
        "    ])\n",
        "\n",
        "reg = Pipeline([\n",
        "    (\"prep\", preprocess),\n",
        "    (\"rf\", RandomForestRegressor(n_estimators=600, random_state=42, n_jobs=-1))\n",
        "])\n",
        "\n",
        "ts = 0.33 if len(X) >= 6 else 0.0\n",
        "if ts > 0:\n",
        "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=ts, random_state=42)\n",
        "else:\n",
        "    X_tr, y_tr = X, y\n",
        "    X_te, y_te = X.iloc[:0], np.array([])\n",
        "\n",
        "reg.fit(X_tr, y_tr)\n",
        "\n",
        "if len(X_te) > 0:\n",
        "    y_hat = reg.predict(X_te)\n",
        "    print(f\"[Holdout] E0_5_kPa  R2={r2_score(y_te, y_hat):6.3f}  MAE={mean_absolute_error(y_te, y_hat):8.3f}\")\n",
        "else:\n",
        "    print(\"Trained on all rows (small dataset).\")\n",
        "\n",
        "# ---------- Forward design for E0_5_kPa ----------\n",
        "tgt = float(TARGET_E0_5_KPA)\n",
        "mins, maxs = X.min().values, X.max().values\n",
        "\n",
        "def _loss_from_row(dfrow):\n",
        "    pred = float(reg.predict(dfrow).ravel()[0])\n",
        "    # Weighted MSE + MAPE (robust scaling)\n",
        "    var = float(np.var(y_tr)) if len(y_tr) else float(np.var(y))\n",
        "    w = 1.0 if var <= 1e-12 else 1.0/var\n",
        "    eps = 1e-8\n",
        "    mse = w * (pred - tgt)**2\n",
        "    mape = abs(pred - tgt) / (abs(tgt) + eps)\n",
        "    base = 0.5*mse + 0.5*mape\n",
        "    return base, pred\n",
        "\n",
        "# ===== Case A: composition mode — continuous optimization over composition columns =====\n",
        "if MODE == \"composition\":\n",
        "    # Bounds with ±5% padding of historical range\n",
        "    bounds = []\n",
        "    for c in X.columns:\n",
        "        lo, hi = float(X[c].min()), float(X[c].max())\n",
        "        span = hi - lo if hi > lo else 1.0\n",
        "        bounds.append((lo - 0.05*span, hi + 0.05*span))\n",
        "\n",
        "    # Sum-to-constant constraint if set (e.g., wt% totals to 100)\n",
        "    constraints = []\n",
        "    if COMPOSITION_TOTAL is not None:\n",
        "        def sum_eq(x, total=COMPOSITION_TOTAL):\n",
        "            return float(np.sum(x) - total)\n",
        "        constraints.append({\"type\": \"eq\", \"fun\": sum_eq})\n",
        "\n",
        "    def objective(x):\n",
        "        row = pd.DataFrame([x], columns=X.columns)\n",
        "        base, _ = _loss_from_row(row)\n",
        "        # Soft penalty outside observed domain\n",
        "        over_low = np.maximum(0.0, mins - x)\n",
        "        over_high = np.maximum(0.0, x - maxs)\n",
        "        return base + 1e-3*np.sum(over_low**2 + over_high**2)\n",
        "\n",
        "    x0 = X.median().values\n",
        "    res = minimize(objective, x0, bounds=bounds, constraints=constraints, method=\"SLSQP\",\n",
        "                   options={\"maxiter\": 1000, \"ftol\": 1e-9, \"disp\": False})\n",
        "    x_opt = res.x\n",
        "    opt_row = pd.DataFrame([x_opt], columns=X.columns)\n",
        "    _, pred_val = _loss_from_row(opt_row)\n",
        "    mode_label = \"COMPOSITION → PROPERTIES\"\n",
        "\n",
        "# ===== Case B: label_fallback — enumerate mat_type (discrete) + optimize mat_level (continuous) =====\n",
        "else:\n",
        "    mat_types = sorted(X[\"mat_type\"].unique().tolist())\n",
        "    level_min, level_max = float(X[\"mat_level\"].min()), float(X[\"mat_level\"].max())\n",
        "    span = max(1e-9, level_max - level_min)\n",
        "    bounds = [(level_min - 0.05*span, level_max + 0.05*span)]\n",
        "\n",
        "    best = {\"loss\": np.inf, \"row\": None, \"pred\": None}\n",
        "\n",
        "    for mt in mat_types:\n",
        "        def objective(x):\n",
        "            row = pd.DataFrame([{\"mat_type\": mt, \"mat_level\": float(x[0])}])\n",
        "            base, _ = _loss_from_row(row)\n",
        "            # Soft penalty outside observed level range\n",
        "            over_low = max(0.0, level_min - x[0])\n",
        "            over_high = max(0.0, x[0] - level_max)\n",
        "            return base + 1e-3*(over_low**2 + over_high**2)\n",
        "\n",
        "        x0 = np.array([(level_min + level_max)/2.0])\n",
        "        res = minimize(objective, x0, bounds=bounds, method=\"SLSQP\",\n",
        "                       options={\"maxiter\": 500, \"ftol\": 1e-9, \"disp\": False})\n",
        "        row = pd.DataFrame([{\"mat_type\": mt, \"mat_level\": float(res.x[0])}])\n",
        "        loss, pred = _loss_from_row(row)\n",
        "        if loss < best[\"loss\"]:\n",
        "            best.update({\"loss\": loss, \"row\": row, \"pred\": pred})\n",
        "\n",
        "    opt_row = best[\"row\"]\n",
        "    pred_val = best[\"pred\"]\n",
        "    mode_label = \"LABEL FALLBACK (no composition provided)\"\n",
        "\n",
        "# ---------- Report & save ----------\n",
        "print(\"\\n================ RESULTS (Initial Modulus 0–5%) ================\")\n",
        "print(f\"Mode: {mode_label}\")\n",
        "print(\"\\nRecommended recipe (composition or knobs):\")\n",
        "print(opt_row.to_string(index=False))\n",
        "print(\"\\nPredicted E0_5_kPa:\")\n",
        "print(pd.DataFrame([pred_val], columns=[TARGET_KEY]).to_string(index=False))\n",
        "\n",
        "# Save artifacts next to your Drive file\n",
        "out_dir = Path(DATA_PATH).parent\n",
        "props_out = out_dir / \"_derived_properties_table.csv\"\n",
        "opt_out = out_dir / \"_optimal_recipe_E0_5.csv\"\n",
        "props_df.to_csv(props_out, index=False)\n",
        "pd.concat({\"recipe_opt\": opt_row.reset_index(drop=True),\n",
        "           \"predicted_E0_5_kPa\": pd.DataFrame([pred_val], columns=[TARGET_KEY]).reset_index(drop=True)}, axis=1).to_csv(opt_out, index=False)\n",
        "print(f\"\\nSaved:\\n  {props_out}\\n  {opt_out}\")\n",
        "\n",
        "# If you get \"Not enough rows\", check coverage:\n",
        "# print(props_df[[TARGET_KEY]].notna().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64NhDCGf_Hlz",
        "outputId": "496b5902-c456-4d09-84fa-7c2cd35b9008"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "[Warn] No composition table recognized. Falling back to ('mat_type','mat_level') from labels.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1708404795.py:105: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
            "  return float(np.trapz(f(xs), xs))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Holdout] E0_5_kPa  R2=-0.655  MAE=  40.612\n",
            "\n",
            "================ RESULTS (Initial Modulus 0–5%) ================\n",
            "Mode: LABEL FALLBACK (no composition provided)\n",
            "\n",
            "Recommended recipe (composition or knobs):\n",
            "mat_type  mat_level\n",
            "     Cel       10.0\n",
            "\n",
            "Predicted E0_5_kPa:\n",
            "  E0_5_kPa\n",
            "384.896667\n",
            "\n",
            "Saved:\n",
            "  /content/drive/MyDrive/AI Training/_derived_properties_table.csv\n",
            "  /content/drive/MyDrive/AI Training/_optimal_recipe_E0_5.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes\n",
        "\n",
        "If you have real composition fields (e.g., AAm_wt, BIS_wt, APS_wt, …), list them in COMPOSITION_COLS and keep COMPOSITION_TOTAL=100.0 if they are wt%. Then the output becomes a true chemical composition satisfying the sum constraint.\n",
        "\n",
        "Without composition, the code optimizes label-derived knobs (mat_type, mat_level) instead—useful for exploration but not a full chemistry prescription.\n",
        "\n",
        "For best performance, choose a target E0_5_kPa within the observed range first; then explore beyond it."
      ],
      "metadata": {
        "id": "hnT3JKV3BVyi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) Stress at 10% strain only"
      ],
      "metadata": {
        "id": "w2qXt4RhAAtD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here’s a single, copy-paste Colab cell to design a recipe for a target stress at 10% strain (Stress@10%_kPa). It:\n",
        "\n",
        "reads your file from Google Drive (/content/drive/MyDrive/AI Training/paam_hydrogel_stress_strain_data_v2.xlsx),\n",
        "\n",
        "derives properties (including Stress@10%_kPa),\n",
        "\n",
        "trains a model (recipe → Stress@10%_kPa), and\n",
        "\n",
        "finds a recipe/composition that hits your target.\n",
        "\n",
        "It supports either a true composition table (recommended) or a fallback using mat_type + mat_level parsed from the stress–strain labels.\n",
        "\n",
        "Set your target here: TARGET_STRESS_10 = 60.0 (example, in kPa).\n",
        "If you have a composition table, fill COMPOSITION_PATH or COMPOSITION_SHEET and list numeric columns in COMPOSITION_COLS."
      ],
      "metadata": {
        "id": "HQ0nMWn7BX-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# One-cell: Stress at 10% strain only (Stress@10%_kPa)\n",
        "# Recipe/composition design to hit a target Stress@10%\n",
        "# =========================================================\n",
        "!pip -q install numpy pandas scikit-learn scipy\n",
        "\n",
        "# --- Mount Google Drive for your provided path ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import Dict, Tuple, Optional, List\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "# ---------------- USER CONFIG ----------------\n",
        "# 1) Stress–strain file (paired columns: Strain(%)_<label>, Stress(kPa)_<label>)\n",
        "DATA_PATH = \"/content/drive/MyDrive/AI Training/paam_hydrogel_stress_strain_data_v2.xlsx\"\n",
        "\n",
        "# 2) Composition source (choose ONE: separate file OR sheet within DATA_PATH)\n",
        "COMPOSITION_PATH = \"\"                 # e.g., \"/content/drive/MyDrive/AI Training/composition_table.xlsx\" or \".csv\"\n",
        "COMPOSITION_SHEET = \"\"                # e.g., \"composition\" if stored as a sheet in DATA_PATH\n",
        "\n",
        "# 3) Composition columns (true chemistry knobs). Leave empty to fallback to ('mat_type','mat_level').\n",
        "COMPOSITION_COLS: List[str] = [\n",
        "    # Example: \"AAm_wt\", \"BIS_wt\", \"APS_wt\", \"TEMED_wt\", \"Water_wt\"\n",
        "]\n",
        "\n",
        "# 4) If composition columns are wt% (or any total constraint), set sum target; else set None.\n",
        "COMPOSITION_TOTAL = 100.0   # or None if not applicable\n",
        "\n",
        "# 5) Target Stress at 10% strain (kPa):\n",
        "TARGET_STRESS_10 = 60.0\n",
        "# --------------------------------------------\n",
        "\n",
        "# ======== Stress–strain utilities ========\n",
        "def find_pairs(df: pd.DataFrame) -> Tuple[Dict[str, str], Dict[str, str], list]:\n",
        "    strain_cols = [c for c in df.columns if c.lower().startswith(\"strain\")]\n",
        "    stress_cols = [c for c in df.columns if c.lower().startswith(\"stress\")]\n",
        "    def lab(c): return c.split(\"_\", 1)[1] if \"_\" in c else None\n",
        "    labels_strain = {lab(c): c for c in strain_cols if lab(c) is not None}\n",
        "    labels_stress = {lab(c): c for c in stress_cols if lab(c) is not None}\n",
        "    labels = sorted(set(labels_strain).intersection(labels_stress))\n",
        "    return labels_strain, labels_stress, labels\n",
        "\n",
        "def to_fraction(eps_raw: np.ndarray) -> np.ndarray:\n",
        "    # Pattern: 0, 500, 1000 → 0.0%, 5.0%, 10.0% → 0.0, 0.05, 0.10 (fraction)\n",
        "    return (eps_raw.astype(float)/100.0)/100.0\n",
        "\n",
        "def ensure_sorted(eps: np.ndarray, sig: np.ndarray):\n",
        "    idx = np.argsort(eps)\n",
        "    return eps[idx], sig[idx]\n",
        "\n",
        "def interp_curve(eps: np.ndarray, sig: np.ndarray):\n",
        "    x = np.asarray(eps, float); y = np.asarray(sig, float)\n",
        "    lo, hi = float(x.min()), float(x.max())\n",
        "    def f(xq):\n",
        "        xq = np.asarray(xq, float)\n",
        "        return np.interp(np.clip(xq, lo, hi), x, y)\n",
        "    return f, (lo, hi)\n",
        "\n",
        "def linear_fit_window(eps: np.ndarray, sig: np.ndarray, a: float, b: float):\n",
        "    if b <= a: return None\n",
        "    f, (lo, hi) = interp_curve(eps, sig)\n",
        "    a, b = max(lo, a), min(hi, b)\n",
        "    if b <= a: return None\n",
        "    xs = np.linspace(a, b, 20); ys = f(xs)\n",
        "    X = np.vstack([xs, np.ones_like(xs)]).T\n",
        "    slope, intercept = np.linalg.lstsq(X, ys, rcond=None)[0]\n",
        "    return float(slope), float(intercept)\n",
        "\n",
        "def secant_modulus(f, a: float, b: float):\n",
        "    if b <= a: return np.nan\n",
        "    return float((f(b) - f(a)) / (b - a))\n",
        "\n",
        "def yield_offset(eps: np.ndarray, sig: np.ndarray, E_init: Optional[float], offset: float = 0.002):\n",
        "    if E_init is None or not np.isfinite(E_init): return None, None\n",
        "    f, (lo, hi) = interp_curve(eps, sig)\n",
        "    xs = np.linspace(lo, hi, 400)\n",
        "    g = f(xs) - E_init*(xs - offset)\n",
        "    s = np.sign(g); idx = np.where(np.diff(s) != 0)[0]\n",
        "    if len(idx) == 0: return None, None\n",
        "    i = idx[0]; x0, x1 = xs[i], xs[i+1]; y0, y1 = g[i], g[i+1]\n",
        "    eps_y = x0 if (y1 - y0) == 0 else x0 - y0*(x1 - x0)/(y1 - y0)\n",
        "    return float(eps_y), float(f(eps_y))\n",
        "\n",
        "def integrate_toughness(eps: np.ndarray, sig: np.ndarray, up_to: Optional[float] = None) -> float:\n",
        "    f, (lo, hi) = interp_curve(eps, sig)\n",
        "    b = hi if up_to is None else max(lo, min(hi, up_to))\n",
        "    xs = np.linspace(lo, b, 400)\n",
        "    return float(np.trapz(f(xs), xs))\n",
        "\n",
        "def stress_at(f, p: float, lo: float, hi: float):\n",
        "    x = p/100.0\n",
        "    return float(f(x)) if lo <= x <= hi else np.nan\n",
        "\n",
        "def parse_label_recipe(label: str):\n",
        "    import re\n",
        "    m = re.match(r\"([A-Za-z]+)(\\d+)?\", label)\n",
        "    mat_type = m.group(1) if m else None\n",
        "    mat_level = float(m.group(2)) if (m and m.group(2)) else 0.0\n",
        "    return mat_type, mat_level\n",
        "\n",
        "def derive_properties_table(stress_strain_path: str) -> pd.DataFrame:\n",
        "    df = pd.read_excel(stress_strain_path)\n",
        "    labels_strain, labels_stress, labels = find_pairs(df)\n",
        "    rows = []\n",
        "    for lab in labels:\n",
        "        eps_raw = df[labels_strain[lab]].to_numpy(dtype=float)\n",
        "        sig_raw = df[labels_stress[lab]].to_numpy(dtype=float)\n",
        "        m = np.isfinite(eps_raw) & np.isfinite(sig_raw)\n",
        "        eps_raw, sig_raw = eps_raw[m], sig_raw[m]\n",
        "        if len(eps_raw) < 3: continue\n",
        "        eps = to_fraction(eps_raw)\n",
        "        eps, sig = ensure_sorted(eps, sig_raw)\n",
        "        f, (lo, hi) = interp_curve(eps, sig)\n",
        "\n",
        "        E0_5  = (linear_fit_window(eps, sig, 0.00, 0.05) or (np.nan, np.nan))[0]\n",
        "        E5_10 = secant_modulus(f, 0.05, 0.10) if hi >= 0.10 else np.nan\n",
        "        TanE10 = (linear_fit_window(eps, sig, 0.08, 0.12) or (np.nan, np.nan))[0] if hi >= 0.12 else np.nan\n",
        "        eps_y, sig_y = yield_offset(eps, sig, E0_5, offset=0.002)\n",
        "        resilience = integrate_toughness(eps, sig, up_to=eps_y) if eps_y is not None else (integrate_toughness(eps, sig, up_to=0.02) if hi >= 0.02 else np.nan)\n",
        "        uts = float(sig.max()); i_uts = int(sig.argmax()); strain_uts = float(eps[i_uts])\n",
        "        frac_strain = float(eps.max()); frac_stress = float(sig[-1])\n",
        "        toughness = integrate_toughness(eps, sig, None)\n",
        "\n",
        "        s5  = stress_at(f, 5, lo, hi)\n",
        "        s10 = stress_at(f, 10, lo, hi)    # <-- Stress at 10% strain\n",
        "        s15 = stress_at(f, 15, lo, hi)\n",
        "        s20 = stress_at(f, 20, lo, hi)\n",
        "        sec_0_15 = secant_modulus(f, 0.00, 0.15) if hi >= 0.15 else np.nan\n",
        "\n",
        "        mat_type, mat_level = parse_label_recipe(lab)\n",
        "        rows.append({\n",
        "            \"label\": lab, \"mat_type\": mat_type, \"mat_level\": mat_level,\n",
        "            \"E0_5_kPa\": E0_5, \"E5_10_kPa\": E5_10, \"TanE10_kPa\": TanE10,\n",
        "            \"Yield_strain_frac\": eps_y if eps_y is not None else np.nan,\n",
        "            \"Yield_stress_kPa\":  sig_y if sig_y is not None else np.nan,\n",
        "            \"Resilience_kJ_m3\":  resilience,\n",
        "            \"UTS_kPa\": uts, \"Strain_UTS_frac\": strain_uts,\n",
        "            \"Fracture_strain_frac\": frac_strain, \"Fracture_stress_kPa\": frac_stress,\n",
        "            \"Toughness_kJ_m3\": toughness,\n",
        "            \"Stress@5%_kPa\": s5, \"Stress@10%_kPa\": s10, \"Stress@15%_kPa\": s15, \"Stress@20%_kPa\": s20,\n",
        "            \"Secant_0_15_kPa\": sec_0_15\n",
        "        })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# ---------- Derive properties ----------\n",
        "props_df = derive_properties_table(DATA_PATH)\n",
        "if props_df.empty:\n",
        "    raise RuntimeError(\"No valid stress–strain pairs found. Check column names like Strain(%)_<label> and Stress(kPa)_<label>.\")\n",
        "\n",
        "# ---------- Load composition (optional) ----------\n",
        "def load_composition() -> Optional[pd.DataFrame]:\n",
        "    comp_df = None\n",
        "    if COMPOSITION_PATH and Path(COMPOSITION_PATH).exists():\n",
        "        if COMPOSITION_PATH.lower().endswith(\".csv\"):\n",
        "            comp_df = pd.read_csv(COMPOSITION_PATH)\n",
        "        else:\n",
        "            comp_df = pd.read_excel(COMPOSITION_PATH)\n",
        "    elif COMPOSITION_SHEET:\n",
        "        comp_df = pd.read_excel(DATA_PATH, sheet_name=COMPOSITION_SHEET)\n",
        "    return comp_df\n",
        "\n",
        "comp_df = load_composition()\n",
        "\n",
        "# ---------- Build X (recipe) and y (Stress@10%_kPa) ----------\n",
        "TARGET_KEY = \"Stress@10%_kPa\"  # single target\n",
        "\n",
        "if TARGET_KEY not in props_df.columns:\n",
        "    raise RuntimeError(\"Stress@10%_kPa not computed — your curves might not reach 10% strain.\")\n",
        "\n",
        "if comp_df is not None and len(COMPOSITION_COLS) > 0 and all(c in comp_df.columns for c in COMPOSITION_COLS) and \"label\" in comp_df.columns:\n",
        "    MODE = \"composition\"\n",
        "    df_model = props_df.merge(comp_df[[\"label\"] + COMPOSITION_COLS], on=\"label\", how=\"inner\")\n",
        "    XY = df_model[[\"label\"] + COMPOSITION_COLS + [TARGET_KEY]].dropna(subset=COMPOSITION_COLS + [TARGET_KEY])\n",
        "    X = XY[COMPOSITION_COLS].astype(float)\n",
        "    y = XY[TARGET_KEY].astype(float).values\n",
        "else:\n",
        "    MODE = \"label_fallback\"\n",
        "    print(\"[Warn] No composition table recognized. Falling back to ('mat_type','mat_level') from labels.\")\n",
        "    XY = props_df[[\"label\",\"mat_type\",\"mat_level\", TARGET_KEY]].dropna(subset=[TARGET_KEY])\n",
        "    X = XY[[\"mat_type\",\"mat_level\"]].copy()\n",
        "    y = XY[TARGET_KEY].astype(float).values\n",
        "\n",
        "if len(X) < 2:\n",
        "    raise RuntimeError(\"Not enough rows to train for Stress@10%_kPa. Need at least 2 valid samples with this property.\")\n",
        "\n",
        "# ---------- Model pipeline ----------\n",
        "if MODE == \"composition\":\n",
        "    preprocess = ColumnTransformer([(\"num\", StandardScaler(), X.columns.tolist())])\n",
        "else:\n",
        "    preprocess = ColumnTransformer([\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), [\"mat_type\"]),\n",
        "        (\"num\", StandardScaler(), [\"mat_level\"]),\n",
        "    ])\n",
        "\n",
        "reg = Pipeline([\n",
        "    (\"prep\", preprocess),\n",
        "    (\"rf\", RandomForestRegressor(n_estimators=600, random_state=42, n_jobs=-1))\n",
        "])\n",
        "\n",
        "ts = 0.33 if len(X) >= 6 else 0.0\n",
        "if ts > 0:\n",
        "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=ts, random_state=42)\n",
        "else:\n",
        "    X_tr, y_tr = X, y\n",
        "    X_te, y_te = X.iloc[:0], np.array([])\n",
        "\n",
        "reg.fit(X_tr, y_tr)\n",
        "\n",
        "if len(X_te) > 0:\n",
        "    y_hat = reg.predict(X_te)\n",
        "    print(f\"[Holdout] Stress@10%_kPa  R2={r2_score(y_te, y_hat):6.3f}  MAE={mean_absolute_error(y_te, y_hat):8.3f}\")\n",
        "else:\n",
        "    print(\"Trained on all rows (small dataset).\")\n",
        "\n",
        "# ---------- Forward design for Stress@10%_kPa ----------\n",
        "tgt = float(TARGET_STRESS_10)\n",
        "mins, maxs = X.min().values, X.max().values\n",
        "\n",
        "def _loss_from_row(dfrow):\n",
        "    pred = float(reg.predict(dfrow).ravel()[0])\n",
        "    # Weighted MSE + MAPE (robust scaling)\n",
        "    var = float(np.var(y_tr)) if len(y_tr) else float(np.var(y))\n",
        "    w = 1.0 if var <= 1e-12 else 1.0/var\n",
        "    eps = 1e-8\n",
        "    mse = w * (pred - tgt)**2\n",
        "    mape = abs(pred - tgt) / (abs(tgt) + eps)\n",
        "    base = 0.5*mse + 0.5*mape\n",
        "    return base, pred\n",
        "\n",
        "# ===== Case A: composition mode — continuous optimization over composition columns =====\n",
        "if MODE == \"composition\":\n",
        "    # Bounds with ±5% padding of historical range\n",
        "    bounds = []\n",
        "    for c in X.columns:\n",
        "        lo, hi = float(X[c].min()), float(X[c].max())\n",
        "        span = hi - lo if hi > lo else 1.0\n",
        "        bounds.append((lo - 0.05*span, hi + 0.05*span))\n",
        "\n",
        "    # Sum-to-constant constraint if set (e.g., wt% totals to 100)\n",
        "    constraints = []\n",
        "    if COMPOSITION_TOTAL is not None:\n",
        "        def sum_eq(x, total=COMPOSITION_TOTAL):\n",
        "            return float(np.sum(x) - total)\n",
        "        constraints.append({\"type\": \"eq\", \"fun\": sum_eq})\n",
        "\n",
        "    def objective(x):\n",
        "        row = pd.DataFrame([x], columns=X.columns)\n",
        "        base, _ = _loss_from_row(row)\n",
        "        # Soft penalty outside observed domain\n",
        "        over_low = np.maximum(0.0, mins - x)\n",
        "        over_high = np.maximum(0.0, x - maxs)\n",
        "        return base + 1e-3*np.sum(over_low**2 + over_high**2)\n",
        "\n",
        "    x0 = X.median().values\n",
        "    res = minimize(objective, x0, bounds=bounds, constraints=constraints, method=\"SLSQP\",\n",
        "                   options={\"maxiter\": 1000, \"ftol\": 1e-9, \"disp\": False})\n",
        "    x_opt = res.x\n",
        "    opt_row = pd.DataFrame([x_opt], columns=X.columns)\n",
        "    _, pred_val = _loss_from_row(opt_row)\n",
        "    mode_label = \"COMPOSITION → PROPERTIES\"\n",
        "\n",
        "# ===== Case B: label_fallback — enumerate mat_type (discrete) + optimize mat_level (continuous) =====\n",
        "else:\n",
        "    mat_types = sorted(X[\"mat_type\"].unique().tolist())\n",
        "    level_min, level_max = float(X[\"mat_level\"].min()), float(X[\"mat_level\"].max())\n",
        "    span = max(1e-9, level_max - level_min)\n",
        "    bounds = [(level_min - 0.05*span, level_max + 0.05*span)]\n",
        "\n",
        "    best = {\"loss\": np.inf, \"row\": None, \"pred\": None}\n",
        "\n",
        "    for mt in mat_types:\n",
        "        def objective(x):\n",
        "            row = pd.DataFrame([{\"mat_type\": mt, \"mat_level\": float(x[0])}])\n",
        "            base, _ = _loss_from_row(row)\n",
        "            # Soft penalty outside observed level range\n",
        "            over_low = max(0.0, level_min - x[0])\n",
        "            over_high = max(0.0, x[0] - level_max)\n",
        "            return base + 1e-3*(over_low**2 + over_high**2)\n",
        "\n",
        "        x0 = np.array([(level_min + level_max)/2.0])\n",
        "        res = minimize(objective, x0, bounds=bounds, method=\"SLSQP\",\n",
        "                       options={\"maxiter\": 500, \"ftol\": 1e-9, \"disp\": False})\n",
        "        row = pd.DataFrame([{\"mat_type\": mt, \"mat_level\": float(res.x[0])}])\n",
        "        loss, pred = _loss_from_row(row)\n",
        "        if loss < best[\"loss\"]:\n",
        "            best.update({\"loss\": loss, \"row\": row, \"pred\": pred})\n",
        "\n",
        "    opt_row = best[\"row\"]\n",
        "    pred_val = best[\"pred\"]\n",
        "    mode_label = \"LABEL FALLBACK (no composition provided)\"\n",
        "\n",
        "# ---------- Report & save ----------\n",
        "print(\"\\n================ RESULTS (Stress at 10% strain) ================\")\n",
        "print(f\"Mode: {mode_label}\")\n",
        "print(\"\\nRecommended recipe (composition or knobs):\")\n",
        "print(opt_row.to_string(index=False))\n",
        "print(\"\\nPredicted Stress@10%_kPa:\")\n",
        "print(pd.DataFrame([pred_val], columns=[TARGET_KEY]).to_string(index=False))\n",
        "\n",
        "# Save artifacts next to your Drive file\n",
        "out_dir = Path(DATA_PATH).parent\n",
        "props_out = out_dir / \"_derived_properties_table.csv\"\n",
        "opt_out = out_dir / \"_optimal_recipe_Stress10.csv\"\n",
        "props_df.to_csv(props_out, index=False)\n",
        "pd.concat({\"recipe_opt\": opt_row.reset_index(drop=True),\n",
        "           \"predicted_Stress10\": pd.DataFrame([pred_val], columns=[TARGET_KEY]).reset_index(drop=True)}, axis=1).to_csv(opt_out, index=False)\n",
        "print(f\"\\nSaved:\\n  {props_out}\\n  {opt_out}\")\n",
        "\n",
        "# If you get \"Not enough rows\", your curves might not reach 10% strain.\n",
        "# You can check coverage with:\n",
        "# print(props_df[[TARGET_KEY]].notna().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMRno22H_Ho1",
        "outputId": "3390fc7b-b170-4567-ccb3-4b342800d60d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "[Warn] No composition table recognized. Falling back to ('mat_type','mat_level') from labels.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1753915685.py:98: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
            "  return float(np.trapz(f(xs), xs))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Holdout] Stress@10%_kPa  R2=-2.135  MAE=   4.558\n",
            "\n",
            "================ RESULTS (Stress at 10% strain) ================\n",
            "Mode: LABEL FALLBACK (no composition provided)\n",
            "\n",
            "Recommended recipe (composition or knobs):\n",
            "mat_type  mat_level\n",
            "     Cel       10.0\n",
            "\n",
            "Predicted Stress@10%_kPa:\n",
            " Stress@10%_kPa\n",
            "        35.2375\n",
            "\n",
            "Saved:\n",
            "  /content/drive/MyDrive/AI Training/_derived_properties_table.csv\n",
            "  /content/drive/MyDrive/AI Training/_optimal_recipe_Stress10.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes\n",
        "\n",
        "For true chemical output, provide your composition table and list its numeric columns in COMPOSITION_COLS. Keep COMPOSITION_TOTAL=100.0 if those are wt%.\n",
        "\n",
        "Without composition, the optimizer proposes label-derived knobs (mat_type, mat_level) instead—useful for exploration but not full chemistry.\n",
        "\n",
        "If you see “Not enough rows,” it likely means many curves don’t reach 10% strain; try targeting Stress@5%_kPa first to confirm the pipeline, or expand your data that covers 10%."
      ],
      "metadata": {
        "id": "nOyQDvqcByLj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EpqIRJonBXNQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6) Yield stress (0.2% offset) only\n",
        "Here’s a single, copy-paste Colab cell to design a recipe for a target Yield stress (0.2% offset) using your Drive file:\n",
        "\n",
        "reads /content/drive/MyDrive/AI Training/paam_hydrogel_stress_strain_data_v2.xlsx\n",
        "\n",
        "derives Yield_stress_kPa (and Yield_strain_frac) via 0.2% offset using an initial 0–5% modulus fit\n",
        "\n",
        "trains a model (recipe → Yield_stress_kPa)\n",
        "\n",
        "optimizes a composition (if you provide a composition table) or label-fallback knobs (mat_type, mat_level) to hit your target\n",
        "\n",
        "Set your target here: TARGET_YIELD_STRESS = 25.0 (kPa).\n",
        "If you have a composition table, fill COMPOSITION_PATH or COMPOSITION_SHEET and list numeric columns in COMPOSITION_COLS (e.g., wt%). Keep COMPOSITION_TOTAL=100.0 if those are percentages."
      ],
      "metadata": {
        "id": "A93PzoIDABmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# One-cell: Yield stress (0.2% offset) only — design recipe\n",
        "# ============================================================\n",
        "!pip -q install numpy pandas scikit-learn scipy\n",
        "\n",
        "# --- Mount Google Drive for your provided path ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import Dict, Tuple, Optional, List\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "# ---------------- USER CONFIG ----------------\n",
        "# 1) Stress–strain file (paired columns: Strain(%)_<label>, Stress(kPa)_<label>)\n",
        "DATA_PATH = \"/content/drive/MyDrive/AI Training/paam_hydrogel_stress_strain_data_v2.xlsx\"\n",
        "\n",
        "# 2) Composition source (choose ONE: separate file OR sheet within DATA_PATH)\n",
        "COMPOSITION_PATH = \"\"                 # e.g., \"/content/drive/MyDrive/AI Training/composition_table.xlsx\" or \".csv\"\n",
        "COMPOSITION_SHEET = \"\"                # e.g., \"composition\" if stored as a sheet in DATA_PATH\n",
        "\n",
        "# 3) Composition columns (true chemistry knobs). Leave empty to fallback to ('mat_type','mat_level').\n",
        "COMPOSITION_COLS: List[str] = [\n",
        "    # Example: \"AAm_wt\", \"BIS_wt\", \"APS_wt\", \"TEMED_wt\", \"Water_wt\"\n",
        "]\n",
        "\n",
        "# 4) If composition columns are wt% (or any total constraint), set sum target; else set None.\n",
        "COMPOSITION_TOTAL = 100.0   # or None if not applicable\n",
        "\n",
        "# 5) Target Yield stress (kPa):\n",
        "TARGET_YIELD_STRESS = 25.0\n",
        "# --------------------------------------------\n",
        "\n",
        "# ======== Stress–strain utilities ========\n",
        "def find_pairs(df: pd.DataFrame) -> Tuple[Dict[str, str], Dict[str, str], list]:\n",
        "    strain_cols = [c for c in df.columns if c.lower().startswith(\"strain\")]\n",
        "    stress_cols = [c for c in df.columns if c.lower().startswith(\"stress\")]\n",
        "    def lab(c): return c.split(\"_\", 1)[1] if \"_\" in c else None\n",
        "    labels_strain = {lab(c): c for c in strain_cols if lab(c) is not None}\n",
        "    labels_stress = {lab(c): c for c in stress_cols if lab(c) is not None}\n",
        "    labels = sorted(set(labels_strain).intersection(labels_stress))\n",
        "    return labels_strain, labels_stress, labels\n",
        "\n",
        "def to_fraction(eps_raw: np.ndarray) -> np.ndarray:\n",
        "    # Pattern: 0, 500, 1000 → 0.0%, 5.0%, 10.0% → 0.0, 0.05, 0.10 (fraction)\n",
        "    return (eps_raw.astype(float)/100.0)/100.0\n",
        "\n",
        "def ensure_sorted(eps: np.ndarray, sig: np.ndarray):\n",
        "    idx = np.argsort(eps)\n",
        "    return eps[idx], sig[idx]\n",
        "\n",
        "def interp_curve(eps: np.ndarray, sig: np.ndarray):\n",
        "    x = np.asarray(eps, float); y = np.asarray(sig, float)\n",
        "    lo, hi = float(x.min()), float(x.max())\n",
        "    def f(xq):\n",
        "        xq = np.asarray(xq, float)\n",
        "        return np.interp(np.clip(xq, lo, hi), x, y)\n",
        "    return f, (lo, hi)\n",
        "\n",
        "def linear_fit_window(eps: np.ndarray, sig: np.ndarray, a: float, b: float):\n",
        "    \"\"\"\n",
        "    Linear fit of σ(ε) in [a,b] using dense interpolation.\n",
        "    If [0,0.05] isn't fully available, shrink to what's available, with a minimum 0.01 span.\n",
        "    \"\"\"\n",
        "    f, (lo, hi) = interp_curve(eps, sig)\n",
        "    a_eff, b_eff = max(lo, a), min(hi, b)\n",
        "    if b_eff - a_eff < 0.01:\n",
        "        return None\n",
        "    xs = np.linspace(a_eff, b_eff, 20)\n",
        "    ys = f(xs)\n",
        "    X = np.vstack([xs, np.ones_like(xs)]).T\n",
        "    slope, intercept = np.linalg.lstsq(X, ys, rcond=None)[0]\n",
        "    return float(slope), float(intercept)\n",
        "\n",
        "def yield_offset(eps: np.ndarray, sig: np.ndarray, E_init: Optional[float], offset: float = 0.002):\n",
        "    \"\"\"\n",
        "    0.2% offset yield: intersection of σ(ε) with line E_init*(ε - offset).\n",
        "    Returns (yield_strain, yield_stress) or (None, None) if no intersection.\n",
        "    \"\"\"\n",
        "    if E_init is None or not np.isfinite(E_init):\n",
        "        return None, None\n",
        "    f, (lo, hi) = interp_curve(eps, sig)\n",
        "    xs = np.linspace(lo, hi, 600)\n",
        "    g = f(xs) - E_init*(xs - offset)\n",
        "    s = np.sign(g)\n",
        "    idx = np.where(np.diff(s) != 0)[0]\n",
        "    if len(idx) == 0:\n",
        "        return None, None\n",
        "    i = idx[0]; x0, x1 = xs[i], xs[i+1]; y0, y1 = g[i], g[i+1]\n",
        "    eps_y = x0 if (y1 - y0) == 0 else x0 - y0*(x1 - x0)/(y1 - y0)\n",
        "    return float(eps_y), float(f(eps_y))\n",
        "\n",
        "def integrate_toughness(eps: np.ndarray, sig: np.ndarray, up_to: Optional[float] = None) -> float:\n",
        "    f, (lo, hi) = interp_curve(eps, sig)\n",
        "    b = hi if up_to is None else max(lo, min(hi, up_to))\n",
        "    xs = np.linspace(lo, b, 400)\n",
        "    return float(np.trapz(f(xs), xs))\n",
        "\n",
        "def stress_at(f, p: float, lo: float, hi: float):\n",
        "    x = p/100.0\n",
        "    return float(f(x)) if lo <= x <= hi else np.nan\n",
        "\n",
        "def parse_label_recipe(label: str):\n",
        "    import re\n",
        "    m = re.match(r\"([A-Za-z]+)(\\d+)?\", label)\n",
        "    mat_type = m.group(1) if m else None\n",
        "    mat_level = float(m.group(2)) if (m and m.group(2)) else 0.0\n",
        "    return mat_type, mat_level\n",
        "\n",
        "def derive_properties_table(stress_strain_path: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Build a tidy table with per-label properties.\n",
        "    Crucially, E0_5_kPa is computed over [0, min(0.05, ε_max)], with a minimum 0.01 span.\n",
        "    Yield is computed via 0.2% offset using that E0_5_kPa.\n",
        "    \"\"\"\n",
        "    df = pd.read_excel(stress_strain_path)\n",
        "    labels_strain, labels_stress, labels = find_pairs(df)\n",
        "    rows = []\n",
        "    for lab in labels:\n",
        "        eps_raw = df[labels_strain[lab]].to_numpy(dtype=float)\n",
        "        sig_raw = df[labels_stress[lab]].to_numpy(dtype=float)\n",
        "        m = np.isfinite(eps_raw) & np.isfinite(sig_raw)\n",
        "        eps_raw, sig_raw = eps_raw[m], sig_raw[m]\n",
        "        if len(eps_raw) < 3:\n",
        "            continue\n",
        "\n",
        "        eps = to_fraction(eps_raw)\n",
        "        eps, sig = ensure_sorted(eps, sig_raw)\n",
        "        f, (lo, hi) = interp_curve(eps, sig)\n",
        "\n",
        "        # Initial modulus over [0, min(0.05, hi)] with min span 0.01\n",
        "        fit = linear_fit_window(eps, sig, 0.00, min(0.05, hi))\n",
        "        E0_5 = fit[0] if fit is not None else np.nan\n",
        "\n",
        "        # Yield via 0.2% offset\n",
        "        eps_y, sig_y = yield_offset(eps, sig, E0_5, offset=0.002)\n",
        "\n",
        "        # Extra properties (optional context)\n",
        "        E5_10 = (lambda f=f: (float((f(0.10)-f(0.05))/0.05) if hi>=0.10 else np.nan))()\n",
        "        TanE10 = (linear_fit_window(eps, sig, 0.08, 0.12) or (np.nan, np.nan))[0] if hi >= 0.12 else np.nan\n",
        "        resilience = integrate_toughness(eps, sig, up_to=eps_y) if eps_y is not None else (integrate_toughness(eps, sig, up_to=0.02) if hi >= 0.02 else np.nan)\n",
        "        uts = float(sig.max()); strain_uts = float(eps[int(sig.argmax())])\n",
        "        frac_strain = float(eps.max()); frac_stress = float(sig[-1])\n",
        "        toughness = integrate_toughness(eps, sig, None)\n",
        "        s5  = stress_at(f, 5, lo, hi); s10 = stress_at(f, 10, lo, hi)\n",
        "        s15 = stress_at(f, 15, lo, hi); s20 = stress_at(f, 20, lo, hi)\n",
        "        sec_0_15 = (lambda f=f: (float((f(0.15)-f(0.00))/0.15) if hi>=0.15 else np.nan))()\n",
        "\n",
        "\n",
        "        mat_type, mat_level = parse_label_recipe(lab)\n",
        "        rows.append({\n",
        "            \"label\": lab, \"mat_type\": mat_type, \"mat_level\": mat_level,\n",
        "            \"E0_5_kPa\": E0_5,\n",
        "            \"Yield_strain_frac\": eps_y if eps_y is not None else np.nan,\n",
        "            \"Yield_stress_kPa\":  sig_y if sig_y is not None else np.nan,\n",
        "            # Optional context fields (not used for training unless you want to)\n",
        "            \"E5_10_kPa\": E5_10, \"TanE10_kPa\": TanE10,\n",
        "            \"Resilience_kJ_m3\":  resilience,\n",
        "            \"UTS_kPa\": uts, \"Strain_UTS_frac\": strain_uts,\n",
        "            \"Fracture_strain_frac\": frac_strain, \"Fracture_stress_kPa\": frac_stress,\n",
        "            \"Toughness_kJ_m3\": toughness,\n",
        "            \"Stress@5%_kPa\": s5, \"Stress@10%_kPa\": s10, \"Stress@15%_kPa\": s15, \"Stress@20%_kPa\": s20,\n",
        "            \"Secant_0_15_kPa\": sec_0_15\n",
        "        })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# ---------- Derive properties ----------\n",
        "props_df = derive_properties_table(DATA_PATH)\n",
        "if props_df.empty:\n",
        "    raise RuntimeError(\"No valid stress–strain pairs found. Check column names like Strain(%)_<label> and Stress(kPa)_<label>.\")\n",
        "\n",
        "# ---------- Load composition (optional) ----------\n",
        "def load_composition() -> Optional[pd.DataFrame]:\n",
        "    comp_df = None\n",
        "    if COMPOSITION_PATH and Path(COMPOSITION_PATH).exists():\n",
        "        if COMPOSITION_PATH.lower().endswith(\".csv\"):\n",
        "            comp_df = pd.read_csv(COMPOSITION_PATH)\n",
        "        else:\n",
        "            comp_df = pd.read_excel(COMPOSITION_PATH)\n",
        "    elif COMPOSITION_SHEET:\n",
        "        comp_df = pd.read_excel(DATA_PATH, sheet_name=COMPOSITION_SHEET)\n",
        "    return comp_df\n",
        "\n",
        "comp_df = load_composition()\n",
        "\n",
        "# ---------- Build X (recipe) and y (Yield_stress_kPa) ----------\n",
        "TARGET_KEY = \"Yield_stress_kPa\"  # single target\n",
        "\n",
        "if TARGET_KEY not in props_df.columns:\n",
        "    raise RuntimeError(\"Yield_stress_kPa not computed — curves may not permit 0.2% offset yield (or initial modulus window too small).\")\n",
        "\n",
        "if comp_df is not None and len(COMPOSITION_COLS) > 0 and all(c in comp_df.columns for c in COMPOSITION_COLS) and \"label\" in comp_df.columns:\n",
        "    MODE = \"composition\"\n",
        "    df_model = props_df.merge(comp_df[[\"label\"] + COMPOSITION_COLS], on=\"label\", how=\"inner\")\n",
        "    XY = df_model[[\"label\"] + COMPOSITION_COLS + [TARGET_KEY]].dropna(subset=COMPOSITION_COLS + [TARGET_KEY])\n",
        "    X = XY[COMPOSITION_COLS].astype(float)\n",
        "    y = XY[TARGET_KEY].astype(float).values\n",
        "else:\n",
        "    MODE = \"label_fallback\"\n",
        "    print(\"[Warn] No composition table recognized. Falling back to ('mat_type','mat_level') from labels.\")\n",
        "    XY = props_df[[\"label\",\"mat_type\",\"mat_level\", TARGET_KEY]].dropna(subset=[TARGET_KEY])\n",
        "    X = XY[[\"mat_type\",\"mat_level\"]].copy()\n",
        "    y = XY[TARGET_KEY].astype(float).values\n",
        "\n",
        "if len(X) < 2:\n",
        "    raise RuntimeError(\"Not enough rows to train for Yield_stress_kPa. Need at least 2 valid samples with this property.\")\n",
        "\n",
        "# ---------- Model pipeline ----------\n",
        "if MODE == \"composition\":\n",
        "    preprocess = ColumnTransformer([(\"num\", StandardScaler(), X.columns.tolist())])\n",
        "else:\n",
        "    preprocess = ColumnTransformer([\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), [\"mat_type\"]),\n",
        "        (\"num\", StandardScaler(), [\"mat_level\"]),\n",
        "    ])\n",
        "\n",
        "reg = Pipeline([\n",
        "    (\"prep\", preprocess),\n",
        "    (\"rf\", RandomForestRegressor(n_estimators=600, random_state=42, n_jobs=-1))\n",
        "])\n",
        "\n",
        "ts = 0.33 if len(X) >= 6 else 0.0\n",
        "if ts > 0:\n",
        "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=ts, random_state=42)\n",
        "else:\n",
        "    X_tr, y_tr = X, y\n",
        "    X_te, y_te = X.iloc[:0], np.array([])\n",
        "\n",
        "reg.fit(X_tr, y_tr)\n",
        "\n",
        "if len(X_te) > 0:\n",
        "    y_hat = reg.predict(X_te)\n",
        "    print(f\"[Holdout] Yield_stress_kPa  R2={r2_score(y_te, y_hat):6.3f}  MAE={mean_absolute_error(y_te, y_hat):8.3f}\")\n",
        "else:\n",
        "    print(\"Trained on all rows (small dataset).\")\n",
        "\n",
        "# ---------- Forward design for Yield_stress_kPa ----------\n",
        "tgt = float(TARGET_YIELD_STRESS)\n",
        "# Ensure mins and maxs are correctly sliced for continuous columns\n",
        "if cont_cols: # Check if cont_cols is not empty\n",
        "  mins, maxs = X[cont_cols].min().values, X[cont_cols].max().values\n",
        "else:\n",
        "  mins, maxs = np.array([]), np.array([])\n",
        "\n",
        "\n",
        "def _loss_from_row(dfrow):\n",
        "    pred = float(reg.predict(dfrow).ravel()[0])\n",
        "    # Weighted MSE + MAPE (robust scaling)\n",
        "    var = float(np.var(y_tr)) if len(y_tr) else float(np.var(y))\n",
        "    w = 1.0 if var <= 1e-12 else 1.0/var\n",
        "    eps = 1e-8\n",
        "    mse = w * (pred - tgt)**2\n",
        "    mape = abs(pred - tgt) / (abs(tgt) + eps)\n",
        "    base = 0.5*mse + 0.5*mape\n",
        "    return base, pred\n",
        "\n",
        "# ===== Case A: composition mode — continuous optimization over composition columns =====\n",
        "if MODE == \"composition\":\n",
        "    # Bounds with ±5% padding of historical range\n",
        "    bounds = []\n",
        "    for c in X.columns:\n",
        "        lo, hi = float(X[c].min()), float(X[c].max())\n",
        "        span = hi - lo if hi > lo else 1.0\n",
        "        bounds.append((lo - 0.05*span, hi + 0.05*span))\n",
        "\n",
        "    # Sum-to-constant constraint if set (e.g., wt% totals to 100)\n",
        "    constraints = []\n",
        "    if COMPOSITION_TOTAL is not None:\n",
        "        def sum_eq(x, total=COMPOSITION_TOTAL):\n",
        "            return float(np.sum(x) - total)\n",
        "        constraints.append({\"type\": \"eq\", \"fun\": sum_eq})\n",
        "\n",
        "    def objective(x):\n",
        "        row = pd.DataFrame([x], columns=X.columns)\n",
        "        base, _ = _loss_from_row(row)\n",
        "        # Soft penalty outside observed domain\n",
        "        over_low = np.maximum(0.0, mins - x)\n",
        "        over_high = np.maximum(0.0, x - maxs)\n",
        "        return base + 1e-3*np.sum(over_low**2 + over_high**2)\n",
        "\n",
        "    x0 = X.median().values\n",
        "    res = minimize(objective, x0, bounds=bounds, constraints=constraints, method=\"SLSQP\",\n",
        "                   options={\"maxiter\": 1000, \"ftol\": 1e-9, \"disp\": False})\n",
        "    x_opt = res.x\n",
        "    opt_row = pd.DataFrame([x_opt], columns=X.columns)\n",
        "    _, pred_val = _loss_from_row(opt_row)\n",
        "    mode_label = \"COMPOSITION → PROPERTIES\"\n",
        "\n",
        "# ===== Case B: label_fallback — enumerate mat_type (discrete) + optimize mat_level (continuous) =====\n",
        "else:\n",
        "    mat_types = sorted(X[\"mat_type\"].unique().tolist())\n",
        "    level_min, level_max = float(X[\"mat_level\"].min()), float(X[\"mat_level\"].max())\n",
        "    span = max(1e-9, level_max - level_min)\n",
        "    bounds = [(level_min - 0.05*span, level_max + 0.05*span)]\n",
        "\n",
        "    best = {\"loss\": np.inf, \"row\": None, \"pred\": None}\n",
        "\n",
        "    for mt in mat_types:\n",
        "        def objective(x):\n",
        "            row = pd.DataFrame([{\"mat_type\": mt, \"mat_level\": float(x[0])}])\n",
        "            base, _ = _loss_from_row(row)\n",
        "            # Soft penalty outside observed level range\n",
        "            over_low = max(0.0, level_min - x[0])\n",
        "            over_high = max(0.0, x[0] - level_max)\n",
        "            return base + 1e-3*(over_low**2 + over_high**2)\n",
        "\n",
        "        x0 = np.array([(level_min + level_max)/2.0])\n",
        "        res = minimize(objective, x0, bounds=bounds, method=\"SLSQP\",\n",
        "                       options={\"maxiter\": 500, \"ftol\": 1e-9, \"disp\": False})\n",
        "        row = pd.DataFrame([{\"mat_type\": mt, \"mat_level\": float(res.x[0])}])\n",
        "        loss, pred = _loss_from_row(row)\n",
        "        if loss < best[\"loss\"]:\n",
        "            best.update({\"loss\": loss, \"row\": row, \"pred\": pred})\n",
        "\n",
        "    opt_row = best[\"row\"]\n",
        "    pred_val = best[\"pred\"]\n",
        "    mode_label = \"LABEL FALLBACK (no composition provided)\"\n",
        "\n",
        "# ---------- Report & save ----------\n",
        "print(\"\\n================ RESULTS (Yield stress 0.2% offset) ================\")\n",
        "print(f\"Mode: {mode_label}\")\n",
        "print(\"\\nRecommended recipe (composition or knobs):\")\n",
        "print(opt_row.to_string(index=False))\n",
        "print(\"\\nPredicted Yield_stress_kPa:\")\n",
        "print(pd.DataFrame([pred_val], columns=[TARGET_KEY]).to_string(index=False))\n",
        "\n",
        "# Save artifacts next to your Drive file\n",
        "out_dir = Path(DATA_PATH).parent\n",
        "props_out = out_dir / \"_derived_properties_table.csv\"\n",
        "opt_out = out_dir / \"_optimal_recipe_YieldStress.csv\"\n",
        "props_df.to_csv(props_out, index=False)\n",
        "pd.concat({\"recipe_opt\": opt_row.reset_index(drop=True),\n",
        "           \"predicted_Yield_stress\": pd.DataFrame([pred_val], columns=[TARGET_KEY]).reset_index(drop=True)}, axis=1).to_csv(opt_out, index=False)\n",
        "print(f\"\\nSaved:\\n  {props_out}\\n  {opt_out}\")\n",
        "\n",
        "# If you get \"Not enough rows\", it means few curves have a resolvable 0.2% yield.\n",
        "# Try: print(props_df[['E0_5_kPa','Yield_stress_kPa','Yield_strain_frac']].notna().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ra2Gf3pC_Hr8",
        "outputId": "d5c3b6b7-9e18-4879-b270-2109efd2c0b3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "[Warn] No composition table recognized. Falling back to ('mat_type','mat_level') from labels.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3797196544.py:105: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
            "  return float(np.trapz(f(xs), xs))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Holdout] Yield_stress_kPa  R2=-0.017  MAE=   4.404\n",
            "\n",
            "================ RESULTS (Yield stress 0.2% offset) ================\n",
            "Mode: LABEL FALLBACK (no composition provided)\n",
            "\n",
            "Recommended recipe (composition or knobs):\n",
            "mat_type  mat_level\n",
            "     Cel       10.0\n",
            "\n",
            "Predicted Yield_stress_kPa:\n",
            " Yield_stress_kPa\n",
            "        25.124281\n",
            "\n",
            "Saved:\n",
            "  /content/drive/MyDrive/AI Training/_derived_properties_table.csv\n",
            "  /content/drive/MyDrive/AI Training/_optimal_recipe_YieldStress.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want the output to be a true chemical composition, provide COMPOSITION_COLS and keep COMPOSITION_TOTAL=100.0 for wt%.\n",
        "\n",
        "If many curves don’t resolve a 0.2% offset yield, consider tightening your data near 0–2% strain (denser sampling), or temporarily target a proxy like Stress@5%_kPa to validate the pipeline."
      ],
      "metadata": {
        "id": "w6YrHKH1CFrJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7) Fracture strain only\n",
        "Here’s a single, copy-paste Colab cell to design a recipe for a target Fracture strain (Fracture_strain_frac). It:\n",
        "\n",
        "reads your Drive file,\n",
        "\n",
        "derives properties (including Fracture_strain_frac),\n",
        "\n",
        "trains a model (recipe → Fracture_strain_frac),\n",
        "\n",
        "optimizes either a true composition (if you provide a composition table) or the label-fallback knobs (mat_type, mat_level) to hit your target.\n",
        "\n",
        "Set your target here: TARGET_FRACTURE_STRAIN = 0.20 (example = 20% strain).\n",
        "If you have a composition table, fill COMPOSITION_PATH or COMPOSITION_SHEET and list numeric columns in COMPOSITION_COLS. Keep COMPOSITION_TOTAL=100.0 if those are wt%."
      ],
      "metadata": {
        "id": "sxak1PDQAD2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================================================\n",
        "# One-cell: Fracture strain only (design recipe/composition)\n",
        "# Target property: Fracture_strain_frac  (unitless fraction)\n",
        "# =======================================================\n",
        "!pip -q install numpy pandas scikit-learn scipy\n",
        "\n",
        "# --- Mount Google Drive for your provided path ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import Dict, Tuple, Optional, List\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "# ---------------- USER CONFIG ----------------\n",
        "# 1) Stress–strain file (paired columns: Strain(%)_<label>, Stress(kPa)_<label>)\n",
        "DATA_PATH = \"/content/drive/MyDrive/AI Training/paam_hydrogel_stress_strain_data_v2.xlsx\"\n",
        "\n",
        "# 2) Composition source (choose ONE: separate file OR sheet within DATA_PATH)\n",
        "COMPOSITION_PATH = \"\"                 # e.g., \"/content/drive/MyDrive/AI Training/composition_table.xlsx\" or \".csv\"\n",
        "COMPOSITION_SHEET = \"\"                # e.g., \"composition\" if stored as a sheet in DATA_PATH\n",
        "\n",
        "# 3) Composition columns (true chemistry knobs). Leave empty to fallback to ('mat_type','mat_level').\n",
        "COMPOSITION_COLS: List[str] = [\n",
        "    # Example: \"AAm_wt\", \"BIS_wt\", \"APS_wt\", \"TEMED_wt\", \"Water_wt\"\n",
        "]\n",
        "\n",
        "# 4) If composition columns are wt% (or any total constraint), set sum target; else set None.\n",
        "COMPOSITION_TOTAL = 100.0   # or None if not applicable\n",
        "\n",
        "# 5) Target Fracture strain (fraction). Example: 0.20 = 20% strain.\n",
        "TARGET_FRACTURE_STRAIN = 0.20\n",
        "# --------------------------------------------\n",
        "\n",
        "# ======== Stress–strain utilities ========\n",
        "def find_pairs(df: pd.DataFrame) -> Tuple[Dict[str, str], Dict[str, str], list]:\n",
        "    strain_cols = [c for c in df.columns if c.lower().startswith(\"strain\")]\n",
        "    stress_cols = [c for c in df.columns if c.lower().startswith(\"stress\")]\n",
        "    def lab(c): return c.split(\"_\", 1)[1] if \"_\" in c else None\n",
        "    labels_strain = {lab(c): c for c in strain_cols if lab(c) is not None}\n",
        "    labels_stress = {lab(c): c for c in stress_cols if lab(c) is not None}\n",
        "    labels = sorted(set(labels_strain).intersection(labels_stress))\n",
        "    return labels_strain, labels_stress, labels\n",
        "\n",
        "def to_fraction(eps_raw: np.ndarray) -> np.ndarray:\n",
        "    # Pattern: 0, 500, 1000 → 0.0%, 5.0%, 10.0% → 0.0, 0.05, 0.10 (fraction)\n",
        "    return (eps_raw.astype(float)/100.0)/100.0\n",
        "\n",
        "def ensure_sorted(eps: np.ndarray, sig: np.ndarray):\n",
        "    idx = np.argsort(eps)\n",
        "    return eps[idx], sig[idx]\n",
        "\n",
        "def interp_curve(eps: np.ndarray, sig: np.ndarray):\n",
        "    x = np.asarray(eps, float); y = np.asarray(sig, float)\n",
        "    lo, hi = float(x.min()), float(x.max())\n",
        "    def f(xq):\n",
        "        xq = np.asarray(xq, float)\n",
        "        return np.interp(np.clip(xq, lo, hi), x, y)\n",
        "    return f, (lo, hi)\n",
        "\n",
        "def linear_fit_window(eps: np.ndarray, sig: np.ndarray, a: float, b: float):\n",
        "    if b <= a: return None\n",
        "    f, (lo, hi) = interp_curve(eps, sig)\n",
        "    a, b = max(lo, a), min(hi, b)\n",
        "    if b <= a: return None\n",
        "    xs = np.linspace(a, b, 20); ys = f(xs)\n",
        "    X = np.vstack([xs, np.ones_like(xs)]).T\n",
        "    slope, intercept = np.linalg.lstsq(X, ys, rcond=None)[0]\n",
        "    return float(slope), float(intercept)\n",
        "\n",
        "def secant_modulus(f, a: float, b: float):\n",
        "    if b <= a: return np.nan\n",
        "    return float((f(b) - f(a)) / (b - a))\n",
        "\n",
        "def yield_offset(eps: np.ndarray, sig: np.ndarray, E_init: Optional[float], offset: float = 0.002):\n",
        "    if E_init is None or not np.isfinite(E_init): return None, None\n",
        "    f, (lo, hi) = interp_curve(eps, sig)\n",
        "    xs = np.linspace(lo, hi, 400)\n",
        "    g = f(xs) - E_init*(xs - offset)\n",
        "    s = np.sign(g); idx = np.where(np.diff(s) != 0)[0]\n",
        "    if len(idx) == 0: return None, None\n",
        "    i = idx[0]; x0, x1 = xs[i], xs[i+1]; y0, y1 = g[i], g[i+1]\n",
        "    eps_y = x0 if (y1 - y0) == 0 else x0 - y0*(x1 - x0)/(y1 - y0)\n",
        "    return float(eps_y), float(f(eps_y))\n",
        "\n",
        "def integrate_toughness(eps: np.ndarray, sig: np.ndarray, up_to: Optional[float] = None) -> float:\n",
        "    f, (lo, hi) = interp_curve(eps, sig)\n",
        "    b = hi if up_to is None else max(lo, min(hi, up_to))\n",
        "    xs = np.linspace(lo, b, 400)\n",
        "    return float(np.trapz(f(xs), xs))\n",
        "\n",
        "def stress_at(f, p: float, lo: float, hi: float):\n",
        "    x = p/100.0\n",
        "    return float(f(x)) if lo <= x <= hi else np.nan\n",
        "\n",
        "def parse_label_recipe(label: str):\n",
        "    import re\n",
        "    m = re.match(r\"([A-Za-z]+)(\\d+)?\", label)\n",
        "    mat_type = m.group(1) if m else None\n",
        "    mat_level = float(m.group(2)) if (m and m.group(2)) else 0.0\n",
        "    return mat_type, mat_level\n",
        "\n",
        "def derive_properties_table(stress_strain_path: str) -> pd.DataFrame:\n",
        "    df = pd.read_excel(stress_strain_path)\n",
        "    labels_strain, labels_stress, labels = find_pairs(df)\n",
        "    rows = []\n",
        "    for lab in labels:\n",
        "        eps_raw = df[labels_strain[lab]].to_numpy(dtype=float)\n",
        "        sig_raw = df[labels_stress[lab]].to_numpy(dtype=float)\n",
        "        m = np.isfinite(eps_raw) & np.isfinite(sig_raw)\n",
        "        eps_raw, sig_raw = eps_raw[m], sig_raw[m]\n",
        "        if len(eps_raw) < 3: continue\n",
        "        eps = to_fraction(eps_raw)\n",
        "        eps, sig = ensure_sorted(eps, sig_raw)\n",
        "        f, (lo, hi) = interp_curve(eps, sig)\n",
        "\n",
        "        # Initial modulus (for context; not used for training)\n",
        "        E0_5  = (linear_fit_window(eps, sig, 0.00, min(0.05, hi)) or (np.nan, np.nan))[0]\n",
        "        eps_y, sig_y = yield_offset(eps, sig, E0_5, offset=0.002)\n",
        "\n",
        "        # Key quantities\n",
        "        uts = float(sig.max()); i_uts = int(sig.argmax()); strain_uts = float(eps[i_uts])\n",
        "        frac_strain = float(eps.max())           # <-- Fracture strain (max recorded strain)\n",
        "        frac_stress = float(sig[-1])\n",
        "        toughness = integrate_toughness(eps, sig, None)\n",
        "\n",
        "        # Convenience probes\n",
        "        s5  = stress_at(f, 5, lo, hi); s10 = stress_at(f, 10, lo, hi)\n",
        "        s15 = stress_at(f, 15, lo, hi); s20 = stress_at(f, 20, lo, hi)\n",
        "        E5_10 = secant_modulus(f, 0.05, 0.10) if hi >= 0.10 else np.nan\n",
        "        TanE10 = (linear_fit_window(eps, sig, 0.08, 0.12) or (np.nan, np.nan))[0] if hi >= 0.12 else np.nan\n",
        "        sec_0_15 = secant_modulus(f, 0.00, 0.15) if hi >= 0.15 else np.nan\n",
        "        resilience = integrate_toughness(eps, sig, up_to=eps_y) if eps_y is not None else (integrate_toughness(eps, sig, up_to=0.02) if hi >= 0.02 else np.nan)\n",
        "\n",
        "        mat_type, mat_level = parse_label_recipe(lab)\n",
        "        rows.append({\n",
        "            \"label\": lab, \"mat_type\": mat_type, \"mat_level\": mat_level,\n",
        "            \"E0_5_kPa\": E0_5,\n",
        "            \"Yield_strain_frac\": eps_y if eps_y is not None else np.nan,\n",
        "            \"Yield_stress_kPa\":  sig_y if sig_y is not None else np.nan,\n",
        "            \"UTS_kPa\": uts, \"Strain_UTS_frac\": strain_uts,\n",
        "            \"Fracture_strain_frac\": frac_strain,   # <-- target column\n",
        "            \"Fracture_stress_kPa\": frac_stress,\n",
        "            \"Toughness_kJ_m3\": toughness,\n",
        "            \"Stress@5%_kPa\": s5, \"Stress@10%_kPa\": s10, \"Stress@15%_kPa\": s15, \"Stress@20%_kPa\": s20,\n",
        "            \"E5_10_kPa\": E5_10, \"TanE10_kPa\": TanE10, \"Secant_0_15_kPa\": sec_0_15,\n",
        "            \"Resilience_kJ_m3\": resilience\n",
        "        })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# ---------- Derive properties ----------\n",
        "props_df = derive_properties_table(DATA_PATH)\n",
        "if props_df.empty:\n",
        "    raise RuntimeError(\"No valid stress–strain pairs found. Check column names like Strain(%)_<label> and Stress(kPa)_<label>.\")\n",
        "\n",
        "# ---------- Load composition (optional) ----------\n",
        "def load_composition() -> Optional[pd.DataFrame]:\n",
        "    comp_df = None\n",
        "    if COMPOSITION_PATH and Path(COMPOSITION_PATH).exists():\n",
        "        if COMPOSITION_PATH.lower().endswith(\".csv\"):\n",
        "            comp_df = pd.read_csv(COMPOSITION_PATH)\n",
        "        else:\n",
        "            comp_df = pd.read_excel(COMPOSITION_PATH)\n",
        "    elif COMPOSITION_SHEET:\n",
        "        comp_df = pd.read_excel(DATA_PATH, sheet_name=COMPOSITION_SHEET)\n",
        "    return comp_df\n",
        "\n",
        "comp_df = load_composition()\n",
        "\n",
        "# ---------- Build X (recipe) and y (Fracture_strain_frac) ----------\n",
        "TARGET_KEY = \"Fracture_strain_frac\"  # single target\n",
        "\n",
        "if TARGET_KEY not in props_df.columns:\n",
        "    raise RuntimeError(\"Fracture_strain_frac not computed.\")\n",
        "\n",
        "if comp_df is not None and len(COMPOSITION_COLS) > 0 and all(c in comp_df.columns for c in COMPOSITION_COLS) and \"label\" in comp_df.columns:\n",
        "    MODE = \"composition\"\n",
        "    df_model = props_df.merge(comp_df[[\"label\"] + COMPOSITION_COLS], on=\"label\", how=\"inner\")\n",
        "    XY = df_model[[\"label\"] + COMPOSITION_COLS + [TARGET_KEY]].dropna(subset=COMPOSITION_COLS + [TARGET_KEY])\n",
        "    X = XY[COMPOSITION_COLS].astype(float)\n",
        "    y = XY[TARGET_KEY].astype(float).values\n",
        "else:\n",
        "    MODE = \"label_fallback\"\n",
        "    print(\"[Warn] No composition table recognized. Falling back to ('mat_type','mat_level') from labels.\")\n",
        "    XY = props_df[[\"label\",\"mat_type\",\"mat_level\", TARGET_KEY]].dropna(subset=[TARGET_KEY])\n",
        "    X = XY[[\"mat_type\",\"mat_level\"]].copy()\n",
        "    y = XY[TARGET_KEY].astype(float).values\n",
        "\n",
        "if len(X) < 2:\n",
        "    raise RuntimeError(\"Not enough rows to train for Fracture_strain_frac. Need at least 2 valid samples.\")\n",
        "\n",
        "# ---------- Model pipeline ----------\n",
        "if MODE == \"composition\":\n",
        "    preprocess = ColumnTransformer([(\"num\", StandardScaler(), X.columns.tolist())])\n",
        "else:\n",
        "    preprocess = ColumnTransformer([\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), [\"mat_type\"]),\n",
        "        (\"num\", StandardScaler(), [\"mat_level\"]),\n",
        "    ])\n",
        "\n",
        "reg = Pipeline([\n",
        "    (\"prep\", preprocess),\n",
        "    (\"rf\", RandomForestRegressor(n_estimators=600, random_state=42, n_jobs=-1))\n",
        "])\n",
        "\n",
        "ts = 0.33 if len(X) >= 6 else 0.0\n",
        "if ts > 0:\n",
        "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=ts, random_state=42)\n",
        "else:\n",
        "    X_tr, y_tr = X, y\n",
        "    X_te, y_te = X.iloc[:0], np.array([])\n",
        "\n",
        "reg.fit(X_tr, y_tr)\n",
        "\n",
        "if len(X_te) > 0:\n",
        "    y_hat = reg.predict(X_te)\n",
        "    print(f\"[Holdout] Fracture_strain_frac  R2={r2_score(y_te, y_hat):6.3f}  MAE={mean_absolute_error(y_te, y_hat):8.4f}\")\n",
        "else:\n",
        "    print(\"Trained on all rows (small dataset).\")\n",
        "\n",
        "# ---------- Forward design for Fracture_strain_frac ----------\n",
        "tgt = float(TARGET_FRACTURE_STRAIN)\n",
        "mins, maxs = X.min().values, X.max().values\n",
        "\n",
        "def _loss_from_row(dfrow):\n",
        "    pred = float(reg.predict(dfrow).ravel()[0])\n",
        "    # Weighted MSE + MAPE (robust scaling)\n",
        "    var = float(np.var(y_tr)) if len(y_tr) else float(np.var(y))\n",
        "    w = 1.0 if var <= 1e-12 else 1.0/var\n",
        "    eps = 1e-8\n",
        "    mse = w * (pred - tgt)**2\n",
        "    mape = abs(pred - tgt) / (abs(tgt) + eps)\n",
        "    base = 0.5*mse + 0.5*mape\n",
        "    return base, pred\n",
        "\n",
        "# ===== Case A: composition mode — continuous optimization over composition columns =====\n",
        "if MODE == \"composition\":\n",
        "    # Bounds with ±5% padding of historical range\n",
        "    bounds = []\n",
        "    for c in X.columns:\n",
        "        lo, hi = float(X[c].min()), float(X[c].max())\n",
        "        span = hi - lo if hi > lo else 1.0\n",
        "        bounds.append((lo - 0.05*span, hi + 0.05*span))\n",
        "\n",
        "    # Sum-to-constant constraint if set (e.g., wt% totals to 100)\n",
        "    constraints = []\n",
        "    if COMPOSITION_TOTAL is not None:\n",
        "        def sum_eq(x, total=COMPOSITION_TOTAL):\n",
        "            return float(np.sum(x) - total)\n",
        "        constraints.append({\"type\": \"eq\", \"fun\": sum_eq})\n",
        "\n",
        "    def objective(x):\n",
        "        row = pd.DataFrame([x], columns=X.columns)\n",
        "        base, _ = _loss_from_row(row)\n",
        "        # Soft penalty outside observed domain\n",
        "        over_low = np.maximum(0.0, mins - x)\n",
        "        over_high = np.maximum(0.0, x - maxs)\n",
        "        return base + 1e-3*np.sum(over_low**2 + over_high**2)\n",
        "\n",
        "    x0 = X.median().values\n",
        "    res = minimize(objective, x0, bounds=bounds, constraints=constraints, method=\"SLSQP\",\n",
        "                   options={\"maxiter\": 1000, \"ftol\": 1e-9, \"disp\": False})\n",
        "    x_opt = res.x\n",
        "    opt_row = pd.DataFrame([x_opt], columns=X.columns)\n",
        "    _, pred_val = _loss_from_row(opt_row)\n",
        "    mode_label = \"COMPOSITION → PROPERTIES\"\n",
        "\n",
        "# ===== Case B: label_fallback — enumerate mat_type (discrete) + optimize mat_level (continuous) =====\n",
        "else:\n",
        "    mat_types = sorted(X[\"mat_type\"].unique().tolist())\n",
        "    level_min, level_max = float(X[\"mat_level\"].min()), float(X[\"mat_level\"].max())\n",
        "    span = max(1e-9, level_max - level_min)\n",
        "    bounds = [(level_min - 0.05*span, level_max + 0.05*span)]\n",
        "\n",
        "    best = {\"loss\": np.inf, \"row\": None, \"pred\": None}\n",
        "\n",
        "    for mt in mat_types:\n",
        "        def objective(x):\n",
        "            row = pd.DataFrame([{\"mat_type\": mt, \"mat_level\": float(x[0])}])\n",
        "            base, _ = _loss_from_row(row)\n",
        "            # Soft penalty outside observed level range\n",
        "            over_low = max(0.0, level_min - x[0])\n",
        "            over_high = max(0.0, x[0] - level_max)\n",
        "            return base + 1e-3*(over_low**2 + over_high**2)\n",
        "\n",
        "        x0 = np.array([(level_min + level_max)/2.0])\n",
        "        res = minimize(objective, x0, bounds=bounds, method=\"SLSQP\",\n",
        "                       options={\"maxiter\": 500, \"ftol\": 1e-9, \"disp\": False})\n",
        "        row = pd.DataFrame([{\"mat_type\": mt, \"mat_level\": float(res.x[0])}])\n",
        "        loss, pred = _loss_from_row(row)\n",
        "        if loss < best[\"loss\"]:\n",
        "            best.update({\"loss\": loss, \"row\": row, \"pred\": pred})\n",
        "\n",
        "    opt_row = best[\"row\"]\n",
        "    pred_val = best[\"pred\"]\n",
        "    mode_label = \"LABEL FALLBACK (no composition provided)\"\n",
        "\n",
        "# ---------- Report & save ----------\n",
        "print(\"\\n================ RESULTS (Fracture strain) ================\")\n",
        "print(f\"Mode: {mode_label}\")\n",
        "print(\"\\nRecommended recipe (composition or knobs):\")\n",
        "print(opt_row.to_string(index=False))\n",
        "print(\"\\nPredicted Fracture_strain_frac:\")\n",
        "print(pd.DataFrame([pred_val], columns=[TARGET_KEY]).to_string(index=False))\n",
        "\n",
        "# Save artifacts next to your Drive file\n",
        "out_dir = Path(DATA_PATH).parent\n",
        "props_out = out_dir / \"_derived_properties_table.csv\"\n",
        "opt_out = out_dir / \"_optimal_recipe_FractureStrain.csv\"\n",
        "props_df.to_csv(props_out, index=False)\n",
        "pd.concat({\"recipe_opt\": opt_row.reset_index(drop=True),\n",
        "           \"predicted_Fracture_strain\": pd.DataFrame([pred_val], columns=[TARGET_KEY]).reset_index(drop=True)}, axis=1).to_csv(opt_out, index=False)\n",
        "print(f\"\\nSaved:\\n  {props_out}\\n  {opt_out}\")\n",
        "\n",
        "# If you get \"Not enough rows\", check coverage:\n",
        "# print(props_df[[TARGET_KEY]].notna().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHJ3zOqJ_Hu7",
        "outputId": "eda0b989-3162-4af7-c71c-dab1bcc5f373"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "[Warn] No composition table recognized. Falling back to ('mat_type','mat_level') from labels.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1000350996.py:98: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
            "  return float(np.trapz(f(xs), xs))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Holdout] Fracture_strain_frac  R2= 0.065  MAE=  0.0071\n",
            "\n",
            "================ RESULTS (Fracture strain) ================\n",
            "Mode: LABEL FALLBACK (no composition provided)\n",
            "\n",
            "Recommended recipe (composition or knobs):\n",
            "mat_type  mat_level\n",
            "     Cel       10.0\n",
            "\n",
            "Predicted Fracture_strain_frac:\n",
            " Fracture_strain_frac\n",
            "             0.156046\n",
            "\n",
            "Saved:\n",
            "  /content/drive/MyDrive/AI Training/_derived_properties_table.csv\n",
            "  /content/drive/MyDrive/AI Training/_optimal_recipe_FractureStrain.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "চলুন Figure 5(E)-র মতো 3D ডায়াগ্রাম বানাই—আপনার experimental data থেকে (stress–strain → derived properties) আর (থাকলে) composition টেবিল থেকে AM–MBA–APS 3D scatter। নিচের একটাই Colab সেল কপি–পেস্ট করলেই হবে। এতে—\n",
        "\n",
        "আপনার Excel ফাইল থেকে properties বের করে 3D property–property–property scatter দেয়\n",
        "\n",
        "যদি আলাদা composition টেবিল থাকে (AM, MBA, APS + gelation/class), তাহলে Figure 5(E)-স্টাইল 3D composition scatter দেয় (জেল হয়েছে/হয়নি—রঙে আলাদা)\n",
        "\n",
        "rbae109\n",
        "\n",
        "যে পেপারটির Figure 5(E) রেফারেন্স করা হয়েছে, সেখানে AM–MBA–APS তিন ফিচারের 3D স্ক্যাটার দেখানো হয়েছে জেলেশন ক্লাস দিয়ে কালার-কোড করে। এখানেও সেই ধারণাটা ফলো করছি।\n",
        "\n",
        "paper link: https://drive.google.com/file/d/1ZRInPfNQ5L0DPeB9vxKJLGCNR8gCI3pY/view"
      ],
      "metadata": {
        "id": "FQbHRJMjDDWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# Colab one-cell: 3D diagrams like Fig. 5(E)\n",
        "# - 3D Property scatter from stress–strain data\n",
        "# - (Optional) 3D Composition scatter: AM–MBA–APS with gelation class\n",
        "# ================================================\n",
        "!pip -q install numpy pandas plotly scikit-learn scipy\n",
        "\n",
        "# ---- Mount Google Drive (needed for your given path) ----\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import plotly.express as px\n",
        "from typing import Dict, Tuple, Optional, List\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# ---------------- USER CONFIG ----------------\n",
        "# Your stress–strain Excel file (paired columns: Strain(%)_<label>, Stress(kPa)_<label>)\n",
        "DATA_PATH = \"/content/drive/MyDrive/AI Training/paam_hydrogel_stress_strain_data_v2.xlsx\"\n",
        "\n",
        "# (Optional) Composition source:\n",
        "#   Option A: a separate file (.xlsx/.csv)\n",
        "COMPOSITION_PATH = \"\"   # e.g., \"/content/drive/MyDrive/AI Training/composition_table.xlsx\"\n",
        "#   Option B: a sheet inside DATA_PATH\n",
        "COMPOSITION_SHEET = \"\"  # e.g., \"composition\"\n",
        "\n",
        "# Columns we’ll look for to replicate Fig.5(E)-style AM–MBA–APS plot (case-insensitive match done automatically)\n",
        "LIKELY_AM_COLS  = [\"am\", \"aam\", \"acrylamide\", \"am_wt\", \"aam_wt\"]\n",
        "LIKELY_MBA_COLS = [\"mba\", \"bis\", \"n,n-methylenebisacrylamide\", \"bis_wt\", \"mba_wt\"]\n",
        "LIKELY_APS_COLS = [\"aps\", \"ammonium persulfate\", \"aps_wt\"]\n",
        "\n",
        "# Optional gelation/class column names we’ll search for\n",
        "LIKELY_CLASS_COLS = [\"gel_ok\", \"gelation\", \"class\", \"label_y\", \"is_gel\", \"formed\", \"status\"]\n",
        "\n",
        "# Default 3D property axes (you can change these names to any derived property columns below)\n",
        "PROPERTY_X = \"UTS_kPa\"\n",
        "PROPERTY_Y = \"Fracture_strain_frac\"   # unitless fraction\n",
        "PROPERTY_Z = \"Toughness_kJ_m3\"\n",
        "# --------------------------------------------\n",
        "\n",
        "# ======== Stress–strain utilities ========\n",
        "def find_pairs(df: pd.DataFrame) -> Tuple[Dict[str, str], Dict[str, str], list]:\n",
        "    strain_cols = [c for c in df.columns if c.lower().startswith(\"strain\")]\n",
        "    stress_cols = [c for c in df.columns if c.lower().startswith(\"stress\")]\n",
        "    def lab(c): return c.split(\"_\", 1)[1] if \"_\" in c else None\n",
        "    labels_strain = {lab(c): c for c in strain_cols if lab(c) is not None}\n",
        "    labels_stress = {lab(c): c for c in stress_cols if lab(c) is not None}\n",
        "    labels = sorted(set(labels_strain).intersection(labels_stress))\n",
        "    return labels_strain, labels_stress, labels\n",
        "\n",
        "def to_fraction(eps_raw: np.ndarray) -> np.ndarray:\n",
        "    # e.g., 0, 500, 1000 -> 0.0, 0.05, 0.10 (fraction)\n",
        "    return (eps_raw.astype(float) / 100.0) / 100.0\n",
        "\n",
        "def ensure_sorted(eps: np.ndarray, sig: np.ndarray):\n",
        "    idx = np.argsort(eps)\n",
        "    return eps[idx], sig[idx]\n",
        "\n",
        "def interp_curve(eps: np.ndarray, sig: np.ndarray):\n",
        "    x = np.asarray(eps, float); y = np.asarray(sig, float)\n",
        "    lo, hi = float(x.min()), float(x.max())\n",
        "    def f(xq):\n",
        "        xq = np.asarray(xq, float)\n",
        "        return np.interp(np.clip(xq, lo, hi), x, y)\n",
        "    return f, (lo, hi)\n",
        "\n",
        "def linear_fit_window(eps: np.ndarray, sig: np.ndarray, a: float, b: float):\n",
        "    f, (lo, hi) = interp_curve(eps, sig)\n",
        "    a_eff, b_eff = max(lo, a), min(hi, b)\n",
        "    if b_eff - a_eff < 0.01:  # need at least ~1% strain span\n",
        "        return None\n",
        "    xs = np.linspace(a_eff, b_eff, 20); ys = f(xs)\n",
        "    X = np.vstack([xs, np.ones_like(xs)]).T\n",
        "    slope, intercept = np.linalg.lstsq(X, ys, rcond=None)[0]\n",
        "    return float(slope), float(intercept)\n",
        "\n",
        "def yield_offset(eps: np.ndarray, sig: np.ndarray, E_init: Optional[float], offset: float = 0.002):\n",
        "    if E_init is None or not np.isfinite(E_init): return None, None\n",
        "    f, (lo, hi) = interp_curve(eps, sig)\n",
        "    xs = np.linspace(lo, hi, 600)\n",
        "    g = f(xs) - E_init*(xs - offset)\n",
        "    s = np.sign(g); idx = np.where(np.diff(s) != 0)[0]\n",
        "    if len(idx) == 0: return None, None\n",
        "    i = idx[0]; x0, x1 = xs[i], xs[i+1]; y0, y1 = g[i], g[i+1]\n",
        "    eps_y = x0 if (y1 - y0) == 0 else x0 - y0*(x1 - x0)/(y1 - y0)\n",
        "    return float(eps_y), float(f(eps_y))\n",
        "\n",
        "def integrate_toughness(eps: np.ndarray, sig: np.ndarray, up_to: Optional[float] = None) -> float:\n",
        "    f, (lo, hi) = interp_curve(eps, sig)\n",
        "    b = hi if up_to is None else max(lo, min(hi, up_to))\n",
        "    xs = np.linspace(lo, b, 400)\n",
        "    return float(np.trapz(f(xs), xs))  # stress(kPa) × strain(fraction) -> kJ/m^3 (since kPa = kJ/m^3)\n",
        "\n",
        "def stress_at(f, p: float, lo: float, hi: float):\n",
        "    x = p/100.0\n",
        "    return float(f(x)) if lo <= x <= hi else np.nan\n",
        "\n",
        "import re\n",
        "def parse_label_recipe(label: str):\n",
        "    m = re.match(r\"([A-Za-z]+)(\\d+)?\", label)\n",
        "    mat_type = m.group(1) if m else None\n",
        "    mat_level = float(m.group(2)) if (m and m.group(2)) else 0.0\n",
        "    return mat_type, mat_level\n",
        "\n",
        "def derive_properties_table(stress_strain_path: str) -> pd.DataFrame:\n",
        "    df = pd.read_excel(stress_strain_path)\n",
        "    labels_strain, labels_stress, labels = find_pairs(df)\n",
        "    rows = []\n",
        "    for lab in labels:\n",
        "        eps_raw = df[labels_strain[lab]].to_numpy(dtype=float)\n",
        "        sig_raw = df[labels_stress[lab]].to_numpy(dtype=float)\n",
        "        m = np.isfinite(eps_raw) & np.isfinite(sig_raw)\n",
        "        eps_raw, sig_raw = eps_raw[m], sig_raw[m]\n",
        "        if len(eps_raw) < 3:\n",
        "            continue\n",
        "        eps = to_fraction(eps_raw)\n",
        "        eps, sig = ensure_sorted(eps, sig_raw)\n",
        "        f, (lo, hi) = interp_curve(eps, sig)\n",
        "\n",
        "        # Initial modulus over [0, min(0.05, hi)] with min 0.01 span\n",
        "        fit = linear_fit_window(eps, sig, 0.00, min(0.05, hi))\n",
        "        E0_5 = fit[0] if fit is not None else np.nan\n",
        "\n",
        "        # Yield via 0.2% offset\n",
        "        eps_y, sig_y = yield_offset(eps, sig, E0_5, offset=0.002)\n",
        "\n",
        "        # Key properties\n",
        "        uts = float(sig.max()); i_uts = int(sig.argmax()); strain_uts = float(eps[i_uts])\n",
        "        frac_strain = float(eps.max()); frac_stress = float(sig[-1])\n",
        "        toughness = integrate_toughness(eps, sig, None)\n",
        "        s5  = stress_at(f, 5, lo, hi); s10 = stress_at(f, 10, lo, hi)\n",
        "        s15 = stress_at(f, 15, lo, hi); s20 = stress_at(f, 20, lo, hi)\n",
        "\n",
        "        mat_type, mat_level = parse_label_recipe(lab)\n",
        "        rows.append({\n",
        "            \"label\": lab, \"mat_type\": mat_type, \"mat_level\": mat_level,\n",
        "            \"E0_5_kPa\": E0_5,\n",
        "            \"Yield_strain_frac\": eps_y if eps_y is not None else np.nan,\n",
        "            \"Yield_stress_kPa\":  sig_y if sig_y is not None else np.nan,\n",
        "            \"UTS_kPa\": uts, \"Strain_UTS_frac\": strain_uts,\n",
        "            \"Fracture_strain_frac\": frac_strain, \"Fracture_stress_kPa\": frac_stress,\n",
        "            \"Toughness_kJ_m3\": toughness,\n",
        "            \"Stress@5%_kPa\": s5, \"Stress@10%_kPa\": s10, \"Stress@15%_kPa\": s15, \"Stress@20%_kPa\": s20\n",
        "        })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# ---------- Derive properties from your stress–strain file ----------\n",
        "props_df = derive_properties_table(DATA_PATH)\n",
        "if props_df.empty:\n",
        "    raise RuntimeError(\"No valid stress–strain pairs found. Check column names like Strain(%)_<label> and Stress(kPa)_<label>.\")\n",
        "\n",
        "display_cols = [\n",
        "    \"label\",\"mat_type\",\"mat_level\",\"UTS_kPa\",\"Strain_UTS_frac\",\"Fracture_strain_frac\",\n",
        "    \"Fracture_stress_kPa\",\"Toughness_kJ_m3\",\"E0_5_kPa\",\"Yield_stress_kPa\",\"Yield_strain_frac\",\n",
        "    \"Stress@5%_kPa\",\"Stress@10%_kPa\",\"Stress@15%_kPa\",\"Stress@20%_kPa\"\n",
        "]\n",
        "print(\"Derived property table (head):\")\n",
        "display(props_df[display_cols].head())\n",
        "\n",
        "# ---------- 3D Property scatter (choose axes above) ----------\n",
        "for col in [PROPERTY_X, PROPERTY_Y, PROPERTY_Z]:\n",
        "    if col not in props_df.columns:\n",
        "        raise RuntimeError(f\"Property axis '{col}' not found in derived table. Available columns: {list(props_df.columns)}\")\n",
        "\n",
        "fig_prop = px.scatter_3d(\n",
        "    props_df, x=PROPERTY_X, y=PROPERTY_Y, z=PROPERTY_Z,\n",
        "    color=\"mat_type\",\n",
        "    symbol=\"mat_type\",\n",
        "    size_max=10,\n",
        "    hover_data=[\"label\",\"mat_level\",\"E0_5_kPa\",\"Yield_stress_kPa\",\"Stress@10%_kPa\",\"Toughness_kJ_m3\"]\n",
        ")\n",
        "fig_prop.update_traces(marker=dict(size=6, opacity=0.8))\n",
        "fig_prop.update_layout(\n",
        "    title=f\"3D Property Space: {PROPERTY_X} vs {PROPERTY_Y} vs {PROPERTY_Z}\",\n",
        "    legend_title=\"mat_type\"\n",
        ")\n",
        "fig_prop.show()\n",
        "\n",
        "# ---------- Try to build Fig. 5(E)-style 3D Composition scatter ----------\n",
        "def load_composition_table() -> Optional[pd.DataFrame]:\n",
        "    comp_df = None\n",
        "    if COMPOSITION_PATH and Path(COMPOSITION_PATH).exists():\n",
        "        comp_df = pd.read_csv(COMPOSITION_PATH) if COMPOSITION_PATH.lower().endswith(\".csv\") else pd.read_excel(COMPOSITION_PATH)\n",
        "    elif COMPOSITION_SHEET:\n",
        "        comp_df = pd.read_excel(DATA_PATH, sheet_name=COMPOSITION_SHEET)\n",
        "    return comp_df\n",
        "\n",
        "def pick_first_match(cols, candidates):\n",
        "    cl = {c.lower(): c for c in cols}\n",
        "    for name in candidates:\n",
        "        if name in cl:\n",
        "            return cl[name]\n",
        "    # try startswith match\n",
        "    for name in candidates:\n",
        "        for lc, orig in cl.items():\n",
        "            if lc.startswith(name):\n",
        "                return orig\n",
        "    return None\n",
        "\n",
        "comp_df = load_composition_table()\n",
        "if comp_df is not None:\n",
        "    # normalize column names to lower for matching\n",
        "    lower_map = {c.lower(): c for c in comp_df.columns}\n",
        "    am_col  = pick_first_match(lower_map.keys(), LIKELY_AM_COLS)\n",
        "    mba_col = pick_first_match(lower_map.keys(), LIKELY_MBA_COLS)\n",
        "    aps_col = pick_first_match(lower_map.keys(), LIKELY_APS_COLS)\n",
        "    cls_col = pick_first_match(lower_map.keys(), LIKELY_CLASS_COLS)\n",
        "\n",
        "    # Merge with properties on 'label' if that exists in both\n",
        "    if \"label\" in comp_df.columns and \"label\" in props_df.columns:\n",
        "        merged = props_df.merge(comp_df, on=\"label\", how=\"inner\")\n",
        "    else:\n",
        "        merged = comp_df.copy()\n",
        "\n",
        "    if am_col and mba_col and aps_col:\n",
        "        plot_df = merged.copy()\n",
        "        # Make a friendly class for coloring if available\n",
        "        if cls_col and cls_col in plot_df.columns:\n",
        "            # Coerce to 0/1 if needed\n",
        "            v = plot_df[cls_col]\n",
        "            if v.dtype == bool:\n",
        "                cls = v.map({True:\"Gel formed\", False:\"Cutoff\"})\n",
        "            else:\n",
        "                # numeric or string—treat nonzero/yes-like as formed\n",
        "                cls = v.astype(str).str.lower().map(\n",
        "                    lambda s: \"Gel formed\" if s in [\"1\",\"true\",\"yes\",\"y\",\"ok\",\"formed\",\"gel\",\"good\"] else (\"Cutoff\" if s in [\"0\",\"false\",\"no\",\"n\",\"cutoff\",\"bad\",\"fail\"] else \"Gel formed\")\n",
        "                )\n",
        "            plot_df[\"_gel_class_\"] = cls\n",
        "            color_col = \"_gel_class_\"\n",
        "        else:\n",
        "            color_col = None  # no class info -> single color\n",
        "\n",
        "        fig_comp = px.scatter_3d(\n",
        "            plot_df, x=am_col, y=mba_col, z=aps_col,\n",
        "            color=color_col if color_col else None,\n",
        "            symbol=color_col if color_col else None,\n",
        "            hover_data=[\"label\"] if \"label\" in plot_df.columns else None\n",
        "        )\n",
        "        fig_comp.update_traces(marker=dict(size=5, opacity=0.85))\n",
        "        ttl = f\"3D Composition Space ({am_col} vs {mba_col} vs {aps_col})\"\n",
        "        if color_col:\n",
        "            ttl += \" — gelation class\"\n",
        "        fig_comp.update_layout(title=ttl)\n",
        "        fig_comp.show()\n",
        "    else:\n",
        "        print(\"⚠️ Composition table loaded, but AM/MBA/APS columns not found. \"\n",
        "              \"Set COMPOSITION_PATH/COMPOSITION_SHEET correctly and ensure columns like AM, MBA, APS exist.\")\n",
        "else:\n",
        "    print(\"ℹ️ No composition table provided. Skipping Fig.5(E)-style composition plot. \"\n",
        "          \"To enable, set COMPOSITION_PATH or COMPOSITION_SHEET and include AM, MBA, APS (+ optional gelation class).\")\n",
        "\n",
        "# ---------- (Optional) Normalized tri-property cube (like paper’s normalized targets) ----------\n",
        "# If you want a normalized 0–1 cube view for any 3 properties (easier to see “balanced” region):\n",
        "NORM_AXES = [PROPERTY_X, PROPERTY_Y, PROPERTY_Z]\n",
        "scaler = MinMaxScaler()\n",
        "norm_vals = scaler.fit_transform(props_df[NORM_AXES].values)\n",
        "norm_df = pd.DataFrame(norm_vals, columns=[f\"norm_{c}\" for c in NORM_AXES])\n",
        "norm_df = pd.concat([props_df[[\"label\",\"mat_type\",\"mat_level\"]].reset_index(drop=True), norm_df], axis=1)\n",
        "\n",
        "fig_norm = px.scatter_3d(\n",
        "    norm_df, x=f\"norm_{PROPERTY_X}\", y=f\"norm_{PROPERTY_Y}\", z=f\"norm_{PROPERTY_Z}\",\n",
        "    color=\"mat_type\",\n",
        "    hover_data=[\"label\",\"mat_level\"]\n",
        ")\n",
        "fig_norm.update_traces(marker=dict(size=6, opacity=0.8))\n",
        "fig_norm.update_layout(\n",
        "    title=f\"Normalized 3D Property Cube: {PROPERTY_X}, {PROPERTY_Y}, {PROPERTY_Z} (0–1)\"\n",
        ")\n",
        "fig_norm.show()\n",
        "\n",
        "print(\"\\nDone. Tip: Change PROPERTY_X/PROPERTY_Y/PROPERTY_Z to any derived columns to plot different 3D views.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gH72-1J0_Hxr",
        "outputId": "949c7557-0b0a-4e02-9c45-98a79bf19ba4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Derived property table (head):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-36696654.py:94: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
            "  return float(np.trapz(f(xs), xs))  # stress(kPa) × strain(fraction) -> kJ/m^3 (since kPa = kJ/m^3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     label mat_type  mat_level  UTS_kPa  Strain_UTS_frac  \\\n",
              "0  Cel10_e      Cel       10.0     85.0             0.17   \n",
              "1  Cel10_f      Cel       10.0     55.0             0.15   \n",
              "2   Cel1_e      Cel        1.0     90.0             0.18   \n",
              "3   Cel1_f      Cel        1.0     65.0             0.16   \n",
              "4  Cel20_e      Cel       20.0     95.0             0.15   \n",
              "\n",
              "   Fracture_strain_frac  Fracture_stress_kPa  Toughness_kJ_m3  E0_5_kPa  \\\n",
              "0                  0.17                 85.0         6.395003     440.0   \n",
              "1                  0.15                 55.0         4.225000     440.0   \n",
              "2                  0.18                 90.0         7.650005     500.0   \n",
              "3                  0.16                 65.0         4.425005     400.0   \n",
              "4                  0.15                 95.0         6.525000     560.0   \n",
              "\n",
              "   Yield_stress_kPa  Yield_strain_frac  Stress@5%_kPa  Stress@10%_kPa  \\\n",
              "0         30.800000           0.072000           22.0            42.0   \n",
              "1         23.271111           0.054889           22.0            35.0   \n",
              "2         29.000000           0.060000           25.0            45.0   \n",
              "3         21.200000           0.055000           20.0            32.0   \n",
              "4               NaN                NaN           28.0            55.0   \n",
              "\n",
              "   Stress@15%_kPa  Stress@20%_kPa  \n",
              "0            67.0             NaN  \n",
              "1            55.0             NaN  \n",
              "2            70.0             NaN  \n",
              "3            50.0             NaN  \n",
              "4            95.0             NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-625ec761-0cc2-4772-976f-21edd758f620\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>mat_type</th>\n",
              "      <th>mat_level</th>\n",
              "      <th>UTS_kPa</th>\n",
              "      <th>Strain_UTS_frac</th>\n",
              "      <th>Fracture_strain_frac</th>\n",
              "      <th>Fracture_stress_kPa</th>\n",
              "      <th>Toughness_kJ_m3</th>\n",
              "      <th>E0_5_kPa</th>\n",
              "      <th>Yield_stress_kPa</th>\n",
              "      <th>Yield_strain_frac</th>\n",
              "      <th>Stress@5%_kPa</th>\n",
              "      <th>Stress@10%_kPa</th>\n",
              "      <th>Stress@15%_kPa</th>\n",
              "      <th>Stress@20%_kPa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cel10_e</td>\n",
              "      <td>Cel</td>\n",
              "      <td>10.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>85.0</td>\n",
              "      <td>6.395003</td>\n",
              "      <td>440.0</td>\n",
              "      <td>30.800000</td>\n",
              "      <td>0.072000</td>\n",
              "      <td>22.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cel10_f</td>\n",
              "      <td>Cel</td>\n",
              "      <td>10.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>55.0</td>\n",
              "      <td>4.225000</td>\n",
              "      <td>440.0</td>\n",
              "      <td>23.271111</td>\n",
              "      <td>0.054889</td>\n",
              "      <td>22.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cel1_e</td>\n",
              "      <td>Cel</td>\n",
              "      <td>1.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.18</td>\n",
              "      <td>90.0</td>\n",
              "      <td>7.650005</td>\n",
              "      <td>500.0</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>0.060000</td>\n",
              "      <td>25.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cel1_f</td>\n",
              "      <td>Cel</td>\n",
              "      <td>1.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>65.0</td>\n",
              "      <td>4.425005</td>\n",
              "      <td>400.0</td>\n",
              "      <td>21.200000</td>\n",
              "      <td>0.055000</td>\n",
              "      <td>20.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Cel20_e</td>\n",
              "      <td>Cel</td>\n",
              "      <td>20.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>95.0</td>\n",
              "      <td>6.525000</td>\n",
              "      <td>560.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>28.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-625ec761-0cc2-4772-976f-21edd758f620')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-625ec761-0cc2-4772-976f-21edd758f620 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-625ec761-0cc2-4772-976f-21edd758f620');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-de4774cd-91c7-43ca-b578-fd77cba86746\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-de4774cd-91c7-43ca-b578-fd77cba86746')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-de4774cd-91c7-43ca-b578-fd77cba86746 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\\\nDone\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Cel10_f\",\n          \"Cel20_e\",\n          \"Cel1_e\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mat_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Cel\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mat_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.893034904268447,\n        \"min\": 1.0,\n        \"max\": 20.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          10.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"UTS_kPa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.175564037317667,\n        \"min\": 55.0,\n        \"max\": 95.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          55.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Strain_UTS_frac\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.013038404810405298,\n        \"min\": 0.15,\n        \"max\": 0.18,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fracture_strain_frac\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.013038404810405298,\n        \"min\": 0.15,\n        \"max\": 0.18,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fracture_stress_kPa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.175564037317667,\n        \"min\": 55.0,\n        \"max\": 95.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          55.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Toughness_kJ_m3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4717105642722887,\n        \"min\": 4.225,\n        \"max\": 7.650005087907739,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4.225\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"E0_5_kPa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 62.60990336999406,\n        \"min\": 400.00000000000006,\n        \"max\": 559.9999999999999,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          500.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Yield_stress_kPa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.564663523899626,\n        \"min\": 21.199999999999996,\n        \"max\": 30.799999999999997,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          23.271111111111114\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Yield_strain_frac\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.008046354898989591,\n        \"min\": 0.054888888888888904,\n        \"max\": 0.072,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.054888888888888904\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stress@5%_kPa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.1304951684997055,\n        \"min\": 20.0,\n        \"max\": 28.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          25.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stress@10%_kPa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.038805230781334,\n        \"min\": 32.0,\n        \"max\": 55.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          35.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stress@15%_kPa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.501428513124292,\n        \"min\": 50.0,\n        \"max\": 95.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          55.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stress@20%_kPa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"4ec7bc56-926f-44c3-9d6e-563dc9bed513\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4ec7bc56-926f-44c3-9d6e-563dc9bed513\")) {                    Plotly.newPlot(                        \"4ec7bc56-926f-44c3-9d6e-563dc9bed513\",                        [{\"customdata\":[[\"Cel10_e\",10.0,440.0,30.799999999999997,42.0],[\"Cel10_f\",10.0,440.0,23.271111111111114,35.0],[\"Cel1_e\",1.0,500.0,29.0,45.0],[\"Cel1_f\",1.0,400.00000000000006,21.199999999999996,32.0],[\"Cel20_e\",20.0,559.9999999999999,null,55.0],[\"Cel20_f\",20.0,500.0,26.499999999999996,40.0],[\"Cel5_e\",5.0,400.00000000000006,null,40.0],[\"Cel5_f\",5.0,360.0,19.439999999999998,30.0]],\"hovertemplate\":\"mat_type=Cel\\u003cbr\\u003eUTS_kPa=%{x}\\u003cbr\\u003eFracture_strain_frac=%{y}\\u003cbr\\u003eToughness_kJ_m3=%{z}\\u003cbr\\u003elabel=%{customdata[0]}\\u003cbr\\u003emat_level=%{customdata[1]}\\u003cbr\\u003eE0_5_kPa=%{customdata[2]}\\u003cbr\\u003eYield_stress_kPa=%{customdata[3]}\\u003cbr\\u003eStress@10%_kPa=%{customdata[4]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Cel\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\",\"opacity\":0.8,\"size\":6},\"mode\":\"markers\",\"name\":\"Cel\",\"scene\":\"scene\",\"showlegend\":true,\"x\":[85.0,55.0,90.0,65.0,95.0,60.0,75.0,45.0],\"y\":[0.17,0.15,0.18,0.16,0.15,0.15,0.16,0.15],\"z\":[6.39500306530738,4.225,7.650005087907739,4.425004868059874,6.5249999999999995,4.75,5.325004239923117,3.5249999999999995],\"type\":\"scatter3d\"},{\"customdata\":[[\"PAA_e\",0.0,400.00000000000006,22.399999999999984,35.0],[\"PAA_f\",0.0,299.99999999999994,18.900000000000034,28.0]],\"hovertemplate\":\"mat_type=PAA\\u003cbr\\u003eUTS_kPa=%{x}\\u003cbr\\u003eFracture_strain_frac=%{y}\\u003cbr\\u003eToughness_kJ_m3=%{z}\\u003cbr\\u003elabel=%{customdata[0]}\\u003cbr\\u003emat_level=%{customdata[1]}\\u003cbr\\u003eE0_5_kPa=%{customdata[2]}\\u003cbr\\u003eYield_stress_kPa=%{customdata[3]}\\u003cbr\\u003eStress@10%_kPa=%{customdata[4]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"PAA\",\"marker\":{\"color\":\"#EF553B\",\"symbol\":\"diamond\",\"opacity\":0.8,\"size\":6},\"mode\":\"markers\",\"name\":\"PAA\",\"scene\":\"scene\",\"showlegend\":true,\"x\":[50.0,40.0],\"y\":[0.15,0.15],\"z\":[3.9999999999999996,3.1499999999999995],\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"xaxis\":{\"title\":{\"text\":\"UTS_kPa\"}},\"yaxis\":{\"title\":{\"text\":\"Fracture_strain_frac\"}},\"zaxis\":{\"title\":{\"text\":\"Toughness_kJ_m3\"}}},\"legend\":{\"title\":{\"text\":\"mat_type\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"3D Property Space: UTS_kPa vs Fracture_strain_frac vs Toughness_kJ_m3\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('4ec7bc56-926f-44c3-9d6e-563dc9bed513');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ℹ️ No composition table provided. Skipping Fig.5(E)-style composition plot. To enable, set COMPOSITION_PATH or COMPOSITION_SHEET and include AM, MBA, APS (+ optional gelation class).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"2c3f5e69-18ca-47ee-a3ae-ac23af98fa98\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2c3f5e69-18ca-47ee-a3ae-ac23af98fa98\")) {                    Plotly.newPlot(                        \"2c3f5e69-18ca-47ee-a3ae-ac23af98fa98\",                        [{\"customdata\":[[\"Cel10_e\",10.0],[\"Cel10_f\",10.0],[\"Cel1_e\",1.0],[\"Cel1_f\",1.0],[\"Cel20_e\",20.0],[\"Cel20_f\",20.0],[\"Cel5_e\",5.0],[\"Cel5_f\",5.0]],\"hovertemplate\":\"mat_type=Cel\\u003cbr\\u003enorm_UTS_kPa=%{x}\\u003cbr\\u003enorm_Fracture_strain_frac=%{y}\\u003cbr\\u003enorm_Toughness_kJ_m3=%{z}\\u003cbr\\u003elabel=%{customdata[0]}\\u003cbr\\u003emat_level=%{customdata[1]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Cel\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\",\"opacity\":0.8,\"size\":6},\"mode\":\"markers\",\"name\":\"Cel\",\"scene\":\"scene\",\"showlegend\":true,\"x\":[0.8181818181818181,0.2727272727272727,0.909090909090909,0.45454545454545436,1.0,0.36363636363636354,0.6363636363636362,0.09090909090909083],\"y\":[0.6666666666666679,0.0,1.0,0.3333333333333339,0.0,0.0,0.3333333333333339,0.0],\"z\":[0.7211109769691687,0.23888861879038836,0.9999999999999999,0.2833340947738091,0.7499991520163355,0.355555153548485,0.4833337290590437,0.08333323911292612],\"type\":\"scatter3d\"},{\"customdata\":[[\"PAA_e\",0.0],[\"PAA_f\",0.0]],\"hovertemplate\":\"mat_type=PAA\\u003cbr\\u003enorm_UTS_kPa=%{x}\\u003cbr\\u003enorm_Fracture_strain_frac=%{y}\\u003cbr\\u003enorm_Toughness_kJ_m3=%{z}\\u003cbr\\u003elabel=%{customdata[0]}\\u003cbr\\u003emat_level=%{customdata[1]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"PAA\",\"marker\":{\"color\":\"#EF553B\",\"symbol\":\"circle\",\"opacity\":0.8,\"size\":6},\"mode\":\"markers\",\"name\":\"PAA\",\"scene\":\"scene\",\"showlegend\":true,\"x\":[0.18181818181818177,0.0],\"y\":[0.0,0.0],\"z\":[0.18888867532263265,0.0],\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"xaxis\":{\"title\":{\"text\":\"norm_UTS_kPa\"}},\"yaxis\":{\"title\":{\"text\":\"norm_Fracture_strain_frac\"}},\"zaxis\":{\"title\":{\"text\":\"norm_Toughness_kJ_m3\"}}},\"legend\":{\"title\":{\"text\":\"mat_type\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"Normalized 3D Property Cube: UTS_kPa, Fracture_strain_frac, Toughness_kJ_m3 (0–1)\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('2c3f5e69-18ca-47ee-a3ae-ac23af98fa98');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Done. Tip: Change PROPERTY_X/PROPERTY_Y/PROPERTY_Z to any derived columns to plot different 3D views.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ব্যবহার টিপস\n",
        "\n",
        "3D property প্লটের অক্ষ বদলাতে PROPERTY_X/Y/Z-এ অন্য property নাম দিন (যেমন E0_5_kPa, Yield_stress_kPa, Stress@10%_kPa ইত্যাদি)।\n",
        "\n",
        "Figure 5(E)-স্টাইল composition প্লট পেতে আলাদা composition টেবিলে AM, MBA, APS (এবং চাইলে gel_ok/gelation ক্লাস) রাখুন; COMPOSITION_PATH বা COMPOSITION_SHEET সেট করুন।\n",
        "\n",
        "চাইলে LIKELY_*_COLS তালিকায় নিজের কলাম নাম যোগ করে ম্যাচিং সহজ করুন।\n",
        "\n",
        "এই কোডটা কনসেপ্টually Figure 5(E)-এর 3D স্ক্যাটারের আদলেই বানানো—একদিকে composition 3D scatter (জেলেশন ক্লাস রঙে), আরেকদিকে আপনার dataset-এর multi-property 3D ভিউ—যেন skin sensor অ্যাপ্লিকেশনের দিকে properties jointly দেখা যায়।"
      ],
      "metadata": {
        "id": "c_T8yrWuExz4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "চলুন মিটিং-এ আলোচনা করা 3D ফিগারগুলো—Figure-5(E) টাইপ composition 3D, সাথে property–property–property 3D, আর Bayesian (GP) surrogate থেকে prediction & EI (Expected Improvement)—আপনার Excel ডেটা থেকেই বানাই। নিচের একটা মাত্র Colab সেল কপি-পেস্ট করলেই চলবে। (রেফারেন্স হিসেবে যে বোয়েলার-প্লেট কাজ পেপারে—Bayesian অপ্টিমাইজেশন/লো-ডেটাসেট ML—ব্যবহৃত, সেটিই ফলো করা হয়েছে।\n",
        "Paper link: https://drive.google.com/file/d/1PHsJty9wXimV0bX6MvlkcHj5SgdH33-2/view"
      ],
      "metadata": {
        "id": "DyAOBI3fFjwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================\n",
        "# One-cell Colab: 3D figures from your PAAm hydrogel dataset\n",
        "#  - Derive properties from stress–strain\n",
        "#  - 3D property scatter (property-property-property)\n",
        "#  - 3D composition scatter (AM–MBA–APS), if composition is available\n",
        "#  - GP surrogate over AM–MBA–APS for a chosen property + isosurfaces\n",
        "#  - Expected Improvement (EI) isosurface for Bayesian-style exploration\n",
        "# ==============================================================\n",
        "\n",
        "!pip -q install numpy pandas scipy scikit-learn plotly\n",
        "\n",
        "# ---- Mount Google Drive (for your given path) ----\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from typing import Dict, Tuple, Optional, List\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import Matern, WhiteKernel, ConstantKernel\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "import warnings\n",
        "\n",
        "# ---------------- USER CONFIG ----------------\n",
        "# Your stress–strain Excel file (paired columns: Strain(%)_<label>, Stress(kPa)_<label>)\n",
        "DATA_PATH = \"/content/drive/MyDrive/AI Training/paam_hydrogel_stress_strain_data_v2.xlsx\"\n",
        "\n",
        "# (Optional) Composition source (needed for AM–MBA–APS & GP):\n",
        "#   Option A: a separate file (.xlsx/.csv)\n",
        "COMPOSITION_PATH = \"\"   # e.g., \"/content/drive/MyDrive/AI Training/composition_table.xlsx\"\n",
        "#   Option B: a sheet inside DATA_PATH\n",
        "COMPOSITION_SHEET = \"\"  # e.g., \"composition\"\n",
        "\n",
        "# Property 3D axes (change if you want other properties)\n",
        "PROPERTY_X = \"UTS_kPa\"\n",
        "PROPERTY_Y = \"Fracture_strain_frac\"   # unitless fraction\n",
        "PROPERTY_Z = \"Toughness_kJ_m3\"\n",
        "\n",
        "# Surrogate (GP) target property over composition (AM, MBA, APS)\n",
        "SURROGATE_TARGET = \"UTS_kPa\"  # e.g., \"UTS_kPa\", \"Toughness_kJ_m3\", \"E0_5_kPa\", \"Stress@10%_kPa\", ...\n",
        "\n",
        "# For the GP/EI grid (bigger -> heavier). 16–20 works well.\n",
        "GRID_N = 18\n",
        "EI_XI = 0.01   # EI exploration parameter\n",
        "# --------------------------------------------\n",
        "\n",
        "# ================= Utility: stress–strain -> properties =================\n",
        "def find_pairs(df: pd.DataFrame) -> Tuple[Dict[str, str], Dict[str, str], list]:\n",
        "    strain_cols = [c for c in df.columns if c.lower().startswith(\"strain\")]\n",
        "    stress_cols = [c for c in df.columns if c.lower().startswith(\"stress\")]\n",
        "    def lab(c): return c.split(\"_\", 1)[1] if \"_\" in c else None\n",
        "    labels_strain = {lab(c): c for c in strain_cols if lab(c) is not None}\n",
        "    labels_stress = {lab(c): c for c in stress_cols if lab(c) is not None}\n",
        "    labels = sorted(set(labels_strain).intersection(labels_stress))\n",
        "    return labels_strain, labels_stress, labels\n",
        "\n",
        "def to_fraction(eps_raw: np.ndarray) -> np.ndarray:\n",
        "    # e.g., 0, 500, 1000 -> 0.0, 0.05, 0.10 (fraction)\n",
        "    return (eps_raw.astype(float) / 100.0) / 100.0\n",
        "\n",
        "def ensure_sorted(eps: np.ndarray, sig: np.ndarray):\n",
        "    idx = np.argsort(eps)\n",
        "    return eps[idx], sig[idx]\n",
        "\n",
        "def interp_curve(eps: np.ndarray, sig: np.ndarray):\n",
        "    x = np.asarray(eps, float); y = np.asarray(sig, float)\n",
        "    lo, hi = float(x.min()), float(x.max())\n",
        "    def f(xq):\n",
        "        xq = np.asarray(xq, float)\n",
        "        return np.interp(np.clip(xq, lo, hi), x, y)\n",
        "    return f, (lo, hi)\n",
        "\n",
        "def linear_fit_window(eps: np.ndarray, sig: np.ndarray, a: float, b: float):\n",
        "    f, (lo, hi) = interp_curve(eps, sig)\n",
        "    a_eff, b_eff = max(lo, a), min(hi, b)\n",
        "    if b_eff - a_eff < 0.01:  # need at least ~1% strain span\n",
        "        return None\n",
        "    xs = np.linspace(a_eff, b_eff, 20); ys = f(xs)\n",
        "    X = np.vstack([xs, np.ones_like(xs)]).T\n",
        "    slope, intercept = np.linalg.lstsq(X, ys, rcond=None)[0]\n",
        "    return float(slope), float(intercept)\n",
        "\n",
        "def yield_offset(eps: np.ndarray, sig: np.ndarray, E_init: Optional[float], offset: float = 0.002):\n",
        "    if E_init is None or not np.isfinite(E_init): return None, None\n",
        "    f, (lo, hi) = interp_curve(eps, sig)\n",
        "    xs = np.linspace(lo, hi, 600)\n",
        "    g = f(xs) - E_init*(xs - offset)\n",
        "    s = np.sign(g); idx = np.where(np.diff(s) != 0)[0]\n",
        "    if len(idx) == 0: return None, None\n",
        "    i = idx[0]; x0, x1 = xs[i], xs[i+1]; y0, y1 = g[i], g[i+1]\n",
        "    eps_y = x0 if (y1 - y0) == 0 else x0 - y0*(x1 - x0)/(y1 - y0)\n",
        "    return float(eps_y), float(f(eps_y))\n",
        "\n",
        "def integrate_toughness(eps: np.ndarray, sig: np.ndarray, up_to: Optional[float] = None) -> float:\n",
        "    f, (lo, hi) = interp_curve(eps, sig)\n",
        "    b = hi if up_to is None else max(lo, min(hi, up_to))\n",
        "    xs = np.linspace(lo, b, 400)\n",
        "    return float(np.trapz(f(xs), xs))  # kPa × strain -> kJ/m^3\n",
        "\n",
        "def stress_at(f, p: float, lo: float, hi: float):\n",
        "    x = p/100.0\n",
        "    return float(f(x)) if lo <= x <= hi else np.nan\n",
        "\n",
        "import re\n",
        "def parse_label_recipe(label: str):\n",
        "    m = re.match(r\"([A-Za-z]+)(\\d+)?\", label)\n",
        "    mat_type = m.group(1) if m else None\n",
        "    mat_level = float(m.group(2)) if (m and m.group(2)) else 0.0\n",
        "    return mat_type, mat_level\n",
        "\n",
        "def derive_properties_table(stress_strain_path: str) -> pd.DataFrame:\n",
        "    df = pd.read_excel(stress_strain_path)\n",
        "    labels_strain, labels_stress, labels = find_pairs(df)\n",
        "    rows = []\n",
        "    for lab in labels:\n",
        "        eps_raw = df[labels_strain[lab]].to_numpy(dtype=float)\n",
        "        sig_raw = df[labels_stress[lab]].to_numpy(dtype=float)\n",
        "        m = np.isfinite(eps_raw) & np.isfinite(sig_raw)\n",
        "        eps_raw, sig_raw = eps_raw[m], sig_raw[m]\n",
        "        if len(eps_raw) < 3:\n",
        "            continue\n",
        "        eps = to_fraction(eps_raw)\n",
        "        eps, sig = ensure_sorted(eps, sig_raw)\n",
        "        f, (lo, hi) = interp_curve(eps, sig)\n",
        "\n",
        "        # Initial modulus over [0, min(0.05, hi)] with min 0.01 span\n",
        "        fit = linear_fit_window(eps, sig, 0.00, min(0.05, hi))\n",
        "        E0_5 = fit[0] if fit is not None else np.nan\n",
        "\n",
        "        # Yield via 0.2% offset\n",
        "        eps_y, sig_y = yield_offset(eps, sig, E0_5, offset=0.002)\n",
        "\n",
        "        # Main properties\n",
        "        uts = float(sig.max()); i_uts = int(sig.argmax()); strain_uts = float(eps[i_uts])\n",
        "        frac_strain = float(eps.max()); frac_stress = float(sig[-1])\n",
        "        toughness = integrate_toughness(eps, sig, None)\n",
        "        s5  = stress_at(f, 5, lo, hi); s10 = stress_at(f, 10, lo, hi)\n",
        "        s15 = stress_at(f, 15, lo, hi); s20 = stress_at(f, 20, lo, hi)\n",
        "\n",
        "        mat_type, mat_level = parse_label_recipe(lab)\n",
        "        rows.append({\n",
        "            \"label\": lab, \"mat_type\": mat_type, \"mat_level\": mat_level,\n",
        "            \"E0_5_kPa\": E0_5,\n",
        "            \"Yield_strain_frac\": eps_y if eps_y is not None else np.nan,\n",
        "            \"Yield_stress_kPa\":  sig_y if sig_y is not None else np.nan,\n",
        "            \"UTS_kPa\": uts, \"Strain_UTS_frac\": strain_uts,\n",
        "            \"Fracture_strain_frac\": frac_strain, \"Fracture_stress_kPa\": frac_stress,\n",
        "            \"Toughness_kJ_m3\": toughness,\n",
        "            \"Stress@5%_kPa\": s5, \"Stress@10%_kPa\": s10, \"Stress@15%_kPa\": s15, \"Stress@20%_kPa\": s20\n",
        "        })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# ---------- Derive properties ----------\n",
        "props_df = derive_properties_table(DATA_PATH)\n",
        "if props_df.empty:\n",
        "    raise RuntimeError(\"No valid stress–strain pairs found. Check column names like Strain(%)_<label> and Stress(kPa)_<label>.\")\n",
        "\n",
        "print(\"Derived properties (head):\")\n",
        "display(props_df.head())\n",
        "\n",
        "# ================== Load composition (if available) ==================\n",
        "def load_composition() -> Optional[pd.DataFrame]:\n",
        "    comp_df = None\n",
        "    if COMPOSITION_PATH and Path(COMPOSITION_PATH).exists():\n",
        "        comp_df = pd.read_csv(COMPOSITION_PATH) if COMPOSITION_PATH.lower().endswith(\".csv\") else pd.read_excel(COMPOSITION_PATH)\n",
        "    elif COMPOSITION_SHEET:\n",
        "        comp_df = pd.read_excel(DATA_PATH, sheet_name=COMPOSITION_SHEET)\n",
        "    return comp_df\n",
        "\n",
        "comp_df = load_composition()\n",
        "\n",
        "LIKELY_AM_COLS  = [\"am\", \"aam\", \"acrylamide\", \"am_wt\", \"aam_wt\"]\n",
        "LIKELY_MBA_COLS = [\"mba\", \"bis\", \"n,n-methylenebisacrylamide\", \"bis_wt\", \"mba_wt\"]\n",
        "LIKELY_APS_COLS = [\"aps\", \"ammonium persulfate\", \"aps_wt\"]\n",
        "LIKELY_CLASS_COLS = [\"gel_ok\", \"gelation\", \"class\", \"is_gel\", \"formed\", \"status\"]\n",
        "\n",
        "def pick_first_match(cols, candidates):\n",
        "    cl = {c.lower(): c for c in cols}\n",
        "    # direct match\n",
        "    for name in candidates:\n",
        "        if name in cl:\n",
        "            return cl[name]\n",
        "    # startswith fuzzy\n",
        "    for name in candidates:\n",
        "        for lc, orig in cl.items():\n",
        "            if lc.startswith(name):\n",
        "                return orig\n",
        "    return None\n",
        "\n",
        "merged = None\n",
        "am_col = mba_col = aps_col = cls_col = None\n",
        "\n",
        "if comp_df is not None:\n",
        "    if \"label\" in comp_df.columns and \"label\" in props_df.columns:\n",
        "        merged = props_df.merge(comp_df, on=\"label\", how=\"inner\")\n",
        "    else:\n",
        "        # fallback: if no label, assume composition table aligns by row order with props_df (not recommended)\n",
        "        merged = pd.concat([props_df.reset_index(drop=True), comp_df.reset_index(drop=True)], axis=1)\n",
        "\n",
        "    lower_cols = [c.lower() for c in merged.columns]\n",
        "    col_map = {c.lower(): c for c in merged.columns}\n",
        "    am_col  = pick_first_match(col_map.keys(), LIKELY_AM_COLS)\n",
        "    mba_col = pick_first_match(col_map.keys(), LIKELY_MBA_COLS)\n",
        "    aps_col = pick_first_match(col_map.keys(), LIKELY_APS_COLS)\n",
        "    cls_col = pick_first_match(col_map.keys(), LIKELY_CLASS_COLS)\n",
        "\n",
        "# ================== 3D Property scatter ==================\n",
        "for col in [PROPERTY_X, PROPERTY_Y, PROPERTY_Z]:\n",
        "    if col not in props_df.columns:\n",
        "        raise RuntimeError(f\"Property axis '{col}' not found. Available: {list(props_df.columns)}\")\n",
        "\n",
        "fig_prop = px.scatter_3d(\n",
        "    props_df, x=PROPERTY_X, y=PROPERTY_Y, z=PROPERTY_Z,\n",
        "    color=\"mat_type\", symbol=\"mat_type\",\n",
        "    hover_data=[\"label\",\"mat_level\",\"E0_5_kPa\",\"Yield_stress_kPa\",\"Stress@10%_kPa\",\"Toughness_kJ_m3\"]\n",
        ")\n",
        "fig_prop.update_traces(marker=dict(size=6, opacity=0.85))\n",
        "fig_prop.update_layout(\n",
        "    title=f\"3D Property Space: {PROPERTY_X} vs {PROPERTY_Y} vs {PROPERTY_Z}\",\n",
        "    legend_title=\"mat_type\"\n",
        ")\n",
        "fig_prop.show()\n",
        "\n",
        "# ================== 3D Composition scatter (AM–MBA–APS) ==================\n",
        "if merged is not None and am_col and mba_col and aps_col:\n",
        "    # Decide size/color: use surrogate target if present\n",
        "    size_col = SURROGATE_TARGET if SURROGATE_TARGET in merged.columns else None\n",
        "    color_col = None\n",
        "    if cls_col and cls_col in merged.columns:\n",
        "        # Normalize class to readable text\n",
        "        v = merged[cls_col].astype(str).str.lower()\n",
        "        cls = v.map(lambda s: \"Gel formed\" if s in [\"1\",\"true\",\"yes\",\"y\",\"ok\",\"formed\",\"gel\",\"good\"] else (\"Cutoff\" if s in [\"0\",\"false\",\"no\",\"n\",\"cutoff\",\"bad\",\"fail\"] else \"Unknown\"))\n",
        "        merged[\"_gel_class_\"] = cls\n",
        "        color_col = \"_gel_class_\"\n",
        "\n",
        "    fig_comp = px.scatter_3d(\n",
        "        merged, x=am_col, y=mba_col, z=aps_col,\n",
        "        color=color_col if color_col else None,\n",
        "        symbol=color_col if color_col else None,\n",
        "        size=size_col if size_col else None,\n",
        "        hover_data=[\"label\"] if \"label\" in merged.columns else None\n",
        "    )\n",
        "    fig_comp.update_traces(marker=dict(size=5, opacity=0.9))\n",
        "    ttl = f\"3D Composition: {am_col} vs {mba_col} vs {aps_col}\"\n",
        "    if color_col:\n",
        "        ttl += \" — gelation class\"\n",
        "    if size_col:\n",
        "        ttl += f\" (size ~ {size_col})\"\n",
        "    fig_comp.update_layout(title=ttl)\n",
        "    fig_comp.show()\n",
        "else:\n",
        "    print(\"ℹ️ Composition 3D scatter skipped: AM/MBA/APS or composition table not found. Set COMPOSITION_PATH/COMPOSITION_SHEET and ensure columns exist.\")\n",
        "\n",
        "# ---------- (Optional) Normalized tri-property cube (like paper’s normalized targets) ----------\n",
        "# If you want a normalized 0–1 cube view for any 3 properties (easier to see “balanced” region):\n",
        "NORM_AXES = [PROPERTY_X, PROPERTY_Y, PROPERTY_Z]\n",
        "scaler = MinMaxScaler()\n",
        "norm_vals = scaler.fit_transform(props_df[NORM_AXES].values)\n",
        "norm_df = pd.DataFrame(norm_vals, columns=[f\"norm_{c}\" for c in NORM_AXES])\n",
        "norm_df = pd.concat([props_df[[\"label\",\"mat_type\",\"mat_level\"]].reset_index(drop=True), norm_df], axis=1)\n",
        "\n",
        "fig_norm = px.scatter_3d(\n",
        "    norm_df, x=f\"norm_{PROPERTY_X}\", y=f\"norm_{PROPERTY_Y}\", z=f\"norm_{PROPERTY_Z}\",\n",
        "    color=\"mat_type\",\n",
        "    hover_data=[\"label\",\"mat_level\"]\n",
        ")\n",
        "fig_norm.update_traces(marker=dict(size=6, opacity=0.8))\n",
        "fig_norm.update_layout(\n",
        "    title=f\"Normalized 3D Property Cube: {PROPERTY_X}, {PROPERTY_Y}, {PROPERTY_Z} (0–1)\"\n",
        ")\n",
        "fig_norm.show()\n",
        "\n",
        "# ================== GP surrogate over composition + Isosurface ==================\n",
        "def make_gp_isosurfaces(df: pd.DataFrame, x_col: str, y_col: str, z_col: str, y_target_col: str,\n",
        "                        grid_n:int=18, title_prefix:str=\"\"):\n",
        "    # drop NA\n",
        "    use = df[[x_col, y_col, z_col, y_target_col]].dropna()\n",
        "    if len(use) < 8:\n",
        "        print(\"⚠️ Not enough rows for GP (~>=8 recommended). Skipping GP/EI.\")\n",
        "        return\n",
        "\n",
        "    X = use[[x_col, y_col, z_col]].values.astype(float)\n",
        "    y = use[y_target_col].values.astype(float)\n",
        "\n",
        "    # Scale inputs to [0,1] for stable GP\n",
        "    xsc = MinMaxScaler()\n",
        "    Xn = xsc.fit_transform(X)\n",
        "\n",
        "    # Simple, robust kernel\n",
        "    kernel = ConstantKernel(1.0, (1e-2, 1e3)) * Matern(length_scale=np.ones(3), length_scale_bounds=(1e-2, 10.0), nu=2.5) + WhiteKernel(noise_level=1e-3, noise_level_bounds=(1e-6, 1e-1))\n",
        "    gp = GaussianProcessRegressor(kernel=kernel, normalize_y=True, n_restarts_optimizer=2, random_state=42)\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "        gp.fit(Xn, y)\n",
        "\n",
        "    # Build grid in normalized space\n",
        "    ax = np.linspace(0, 1, grid_n)\n",
        "    AY, BY, CY = np.meshgrid(ax, ax, ax, indexing=\"ij\")  # shape (n,n,n)\n",
        "    Xgrid = np.stack([AY.ravel(), BY.ravel(), CY.ravel()], axis=1)\n",
        "    mu, std = gp.predict(Xgrid, return_std=True)\n",
        "\n",
        "    # Expected Improvement (maximize y)\n",
        "    y_best = np.max(y)\n",
        "    eps = 1e-12\n",
        "    improv = mu - y_best - EI_XI\n",
        "    Z = improv / (std + eps)\n",
        "    from math import sqrt, pi, exp\n",
        "    # Normal pdf & cdf\n",
        "    pdf = 1.0/np.sqrt(2*np.pi) * np.exp(-0.5*Z**2)\n",
        "    from scipy.stats import norm\n",
        "    cdf = norm.cdf(Z)\n",
        "    EI = np.maximum(0.0, improv)*cdf + std*pdf\n",
        "\n",
        "    # Back-transform grid to original units for plotting axes\n",
        "    # sample a unit cube grid and inverse_transform\n",
        "    # Build arrays corresponding to the 3 axes (vector form)\n",
        "    def inv_axis(idx):\n",
        "        # unit cube points for a single axis across all combinations -> take unique\n",
        "        U = np.zeros((grid_n, 3))\n",
        "        U[:, idx] = ax\n",
        "        inv = xsc.inverse_transform(U)\n",
        "        return inv[:, idx]\n",
        "\n",
        "    gx = inv_axis(0); gy = inv_axis(1); gz = inv_axis(2)\n",
        "\n",
        "    # -------- Prediction isosurface --------\n",
        "    vol_mu = mu.reshape(grid_n, grid_n, grid_n)\n",
        "    # Choose a few iso levels: quartiles of mu\n",
        "    qs = np.quantile(mu[np.isfinite(mu)], [0.25, 0.5, 0.75])\n",
        "    fig_mu = go.Figure()\n",
        "    for q in qs:\n",
        "        fig_mu.add_trace(go.Isosurface(\n",
        "            x=np.repeat(gx, grid_n*grid_n),\n",
        "            y=np.tile(np.repeat(gy, grid_n), grid_n),\n",
        "            z=np.tile(gz, grid_n*grid_n),\n",
        "            value=mu,\n",
        "            isomin=q, isomax=q,\n",
        "            surface_count=1,\n",
        "            showscale=False,\n",
        "            opacity=0.15,\n",
        "            caps=dict(x_show=False, y_show=False, z_show=False),\n",
        "            name=f\"μ≈{q:.2f}\"\n",
        "        ))\n",
        "    # overlay observed points colored by y\n",
        "    fig_mu.add_trace(go.Scatter3d(\n",
        "        x=use[x_col], y=use[y_col], z=use[z_col],\n",
        "        mode='markers',\n",
        "        marker=dict(size=5, color=use[y_target_col], colorscale='Viridis', showscale=True, colorbar=dict(title=y_target_col)),\n",
        "        name='observed'\n",
        "    ))\n",
        "    fig_mu.update_layout(\n",
        "        title=f\"{title_prefix} GP μ (prediction) isosurfaces + observed points\",\n",
        "        scene=dict(xaxis_title=x_col, yaxis_title=y_col, zaxis_title=z_col)\n",
        "    )\n",
        "    fig_mu.show()\n",
        "\n",
        "    # -------- EI isosurface --------\n",
        "    vol_ei = EI.reshape(grid_n, grid_n, grid_n)\n",
        "    # High-EI cutoff at, say, top 10–20% EI\n",
        "    thr = np.quantile(EI[np.isfinite(EI)], 0.80)\n",
        "    fig_ei = go.Figure(go.Isosurface(\n",
        "        x=np.repeat(gx, grid_n*grid_n),\n",
        "        y=np.tile(np.repeat(gy, grid_n), grid_n),\n",
        "        z=np.tile(gz, grid_n*grid_n),\n",
        "        value=EI,\n",
        "        isomin=thr, isomax=EI.max(),\n",
        "        surface_count=2,\n",
        "        colorscale='Plasma',\n",
        "        opacity=0.35,\n",
        "        caps=dict(x_show=False, y_show=False, z_show=False),\n",
        "        colorbar=dict(title=\"EI\")\n",
        "    ))\n",
        "    fig_ei.add_trace(go.Scatter3d(\n",
        "        x=use[x_col], y=use[y_col], z=use[z_col],\n",
        "        mode='markers',\n",
        "        marker=dict(size=4, color='black'),\n",
        "        name='observed'\n",
        "    ))\n",
        "    fig_ei.update_layout(\n",
        "        title=f\"{title_prefix} Expected Improvement (EI) — high-EI region\",\n",
        "        scene=dict(xaxis_title=x_col, yaxis_title=y_col, zaxis_title=z_col)\n",
        "    )\n",
        "    fig_ei.show()\n",
        "\n",
        "# Run GP only if composition present\n",
        "if merged is not None and am_col and mba_col and aps_col:\n",
        "    if SURROGATE_TARGET in merged.columns:\n",
        "        make_gp_isosurfaces(merged, am_col, mba_col, aps_col, SURROGATE_TARGET, grid_n=GRID_N,\n",
        "                            title_prefix=f\"{SURROGATE_TARGET}: \")\n",
        "    else:\n",
        "        print(f\"ℹ️ Surrogate target '{SURROGATE_TARGET}' not found in merged table. Available: {list(merged.columns)}\")\n",
        "\n",
        "print(\"\\nDone. Tips:\")\n",
        "print(\"• PROPERTY_X/Y/Z বদলে যে কোন ৩টি derived property প্লট করুন।\")\n",
        "print(\"• COMPOSITION_PATH/COMPOSITION_SHEET দিন এবং AM/MBA/APS কলাম ঠিক থাকলে composition 3D ও GP/EI প্লট আসবে।\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3YyPH0KX9Nr8",
        "outputId": "98732664-25c5-49a8-ba34-570b7a8f9e2c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Derived properties (head):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3196232463.py:102: DeprecationWarning:\n",
            "\n",
            "`trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     label mat_type  mat_level  E0_5_kPa  Yield_strain_frac  Yield_stress_kPa  \\\n",
              "0  Cel10_e      Cel       10.0     440.0           0.072000         30.800000   \n",
              "1  Cel10_f      Cel       10.0     440.0           0.054889         23.271111   \n",
              "2   Cel1_e      Cel        1.0     500.0           0.060000         29.000000   \n",
              "3   Cel1_f      Cel        1.0     400.0           0.055000         21.200000   \n",
              "4  Cel20_e      Cel       20.0     560.0                NaN               NaN   \n",
              "\n",
              "   UTS_kPa  Strain_UTS_frac  Fracture_strain_frac  Fracture_stress_kPa  \\\n",
              "0     85.0             0.17                  0.17                 85.0   \n",
              "1     55.0             0.15                  0.15                 55.0   \n",
              "2     90.0             0.18                  0.18                 90.0   \n",
              "3     65.0             0.16                  0.16                 65.0   \n",
              "4     95.0             0.15                  0.15                 95.0   \n",
              "\n",
              "   Toughness_kJ_m3  Stress@5%_kPa  Stress@10%_kPa  Stress@15%_kPa  \\\n",
              "0         6.395003           22.0            42.0            67.0   \n",
              "1         4.225000           22.0            35.0            55.0   \n",
              "2         7.650005           25.0            45.0            70.0   \n",
              "3         4.425005           20.0            32.0            50.0   \n",
              "4         6.525000           28.0            55.0            95.0   \n",
              "\n",
              "   Stress@20%_kPa  \n",
              "0             NaN  \n",
              "1             NaN  \n",
              "2             NaN  \n",
              "3             NaN  \n",
              "4             NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eab9dd6c-3641-456d-91ca-d6433299f7fd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>mat_type</th>\n",
              "      <th>mat_level</th>\n",
              "      <th>E0_5_kPa</th>\n",
              "      <th>Yield_strain_frac</th>\n",
              "      <th>Yield_stress_kPa</th>\n",
              "      <th>UTS_kPa</th>\n",
              "      <th>Strain_UTS_frac</th>\n",
              "      <th>Fracture_strain_frac</th>\n",
              "      <th>Fracture_stress_kPa</th>\n",
              "      <th>Toughness_kJ_m3</th>\n",
              "      <th>Stress@5%_kPa</th>\n",
              "      <th>Stress@10%_kPa</th>\n",
              "      <th>Stress@15%_kPa</th>\n",
              "      <th>Stress@20%_kPa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cel10_e</td>\n",
              "      <td>Cel</td>\n",
              "      <td>10.0</td>\n",
              "      <td>440.0</td>\n",
              "      <td>0.072000</td>\n",
              "      <td>30.800000</td>\n",
              "      <td>85.0</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>85.0</td>\n",
              "      <td>6.395003</td>\n",
              "      <td>22.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cel10_f</td>\n",
              "      <td>Cel</td>\n",
              "      <td>10.0</td>\n",
              "      <td>440.0</td>\n",
              "      <td>0.054889</td>\n",
              "      <td>23.271111</td>\n",
              "      <td>55.0</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>55.0</td>\n",
              "      <td>4.225000</td>\n",
              "      <td>22.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cel1_e</td>\n",
              "      <td>Cel</td>\n",
              "      <td>1.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>0.060000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>90.0</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.18</td>\n",
              "      <td>90.0</td>\n",
              "      <td>7.650005</td>\n",
              "      <td>25.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cel1_f</td>\n",
              "      <td>Cel</td>\n",
              "      <td>1.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>0.055000</td>\n",
              "      <td>21.200000</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>65.0</td>\n",
              "      <td>4.425005</td>\n",
              "      <td>20.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Cel20_e</td>\n",
              "      <td>Cel</td>\n",
              "      <td>20.0</td>\n",
              "      <td>560.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>95.0</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>95.0</td>\n",
              "      <td>6.525000</td>\n",
              "      <td>28.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eab9dd6c-3641-456d-91ca-d6433299f7fd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eab9dd6c-3641-456d-91ca-d6433299f7fd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eab9dd6c-3641-456d-91ca-d6433299f7fd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-64205b21-00d2-4bcb-a205-3953c3b86cfe\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-64205b21-00d2-4bcb-a205-3953c3b86cfe')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-64205b21-00d2-4bcb-a205-3953c3b86cfe button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\u2022 COMPOSITION_PATH/COMPOSITION_SHEET \\u09a6\\u09bf\\u09a8 \\u098f\\u09ac\\u0982 AM/MBA/APS \\u0995\\u09b2\\u09be\\u09ae \\u09a0\\u09bf\\u0995 \\u09a5\\u09be\\u0995\\u09b2\\u09c7 composition 3D \\u0993 GP/EI \\u09aa\\u09cd\\u09b2\\u099f \\u0986\\u09b8\\u09ac\\u09c7\\u0964\\\")\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Cel10_f\",\n          \"Cel20_e\",\n          \"Cel1_e\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mat_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Cel\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mat_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.893034904268447,\n        \"min\": 1.0,\n        \"max\": 20.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          10.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"E0_5_kPa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 62.60990336999406,\n        \"min\": 400.00000000000006,\n        \"max\": 559.9999999999999,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          500.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Yield_strain_frac\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.008046354898989591,\n        \"min\": 0.054888888888888904,\n        \"max\": 0.072,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.054888888888888904\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Yield_stress_kPa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.564663523899626,\n        \"min\": 21.199999999999996,\n        \"max\": 30.799999999999997,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          23.271111111111114\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"UTS_kPa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.175564037317667,\n        \"min\": 55.0,\n        \"max\": 95.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          55.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Strain_UTS_frac\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.013038404810405298,\n        \"min\": 0.15,\n        \"max\": 0.18,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fracture_strain_frac\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.013038404810405298,\n        \"min\": 0.15,\n        \"max\": 0.18,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fracture_stress_kPa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.175564037317667,\n        \"min\": 55.0,\n        \"max\": 95.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          55.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Toughness_kJ_m3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4717105642722887,\n        \"min\": 4.225,\n        \"max\": 7.650005087907739,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4.225\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stress@5%_kPa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.1304951684997055,\n        \"min\": 20.0,\n        \"max\": 28.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          25.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stress@10%_kPa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.038805230781334,\n        \"min\": 32.0,\n        \"max\": 55.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          35.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stress@15%_kPa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.501428513124292,\n        \"min\": 50.0,\n        \"max\": 95.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          55.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stress@20%_kPa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"4ce808bf-4093-4509-bd34-5bead3b0df03\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4ce808bf-4093-4509-bd34-5bead3b0df03\")) {                    Plotly.newPlot(                        \"4ce808bf-4093-4509-bd34-5bead3b0df03\",                        [{\"customdata\":[[\"Cel10_e\",10.0,440.0,30.799999999999997,42.0],[\"Cel10_f\",10.0,440.0,23.271111111111114,35.0],[\"Cel1_e\",1.0,500.0,29.0,45.0],[\"Cel1_f\",1.0,400.00000000000006,21.199999999999996,32.0],[\"Cel20_e\",20.0,559.9999999999999,null,55.0],[\"Cel20_f\",20.0,500.0,26.499999999999996,40.0],[\"Cel5_e\",5.0,400.00000000000006,null,40.0],[\"Cel5_f\",5.0,360.0,19.439999999999998,30.0]],\"hovertemplate\":\"mat_type=Cel\\u003cbr\\u003eUTS_kPa=%{x}\\u003cbr\\u003eFracture_strain_frac=%{y}\\u003cbr\\u003eToughness_kJ_m3=%{z}\\u003cbr\\u003elabel=%{customdata[0]}\\u003cbr\\u003emat_level=%{customdata[1]}\\u003cbr\\u003eE0_5_kPa=%{customdata[2]}\\u003cbr\\u003eYield_stress_kPa=%{customdata[3]}\\u003cbr\\u003eStress@10%_kPa=%{customdata[4]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Cel\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\",\"opacity\":0.85,\"size\":6},\"mode\":\"markers\",\"name\":\"Cel\",\"scene\":\"scene\",\"showlegend\":true,\"x\":[85.0,55.0,90.0,65.0,95.0,60.0,75.0,45.0],\"y\":[0.17,0.15,0.18,0.16,0.15,0.15,0.16,0.15],\"z\":[6.39500306530738,4.225,7.650005087907739,4.425004868059874,6.5249999999999995,4.75,5.325004239923117,3.5249999999999995],\"type\":\"scatter3d\"},{\"customdata\":[[\"PAA_e\",0.0,400.00000000000006,22.399999999999984,35.0],[\"PAA_f\",0.0,299.99999999999994,18.900000000000034,28.0]],\"hovertemplate\":\"mat_type=PAA\\u003cbr\\u003eUTS_kPa=%{x}\\u003cbr\\u003eFracture_strain_frac=%{y}\\u003cbr\\u003eToughness_kJ_m3=%{z}\\u003cbr\\u003elabel=%{customdata[0]}\\u003cbr\\u003emat_level=%{customdata[1]}\\u003cbr\\u003eE0_5_kPa=%{customdata[2]}\\u003cbr\\u003eYield_stress_kPa=%{customdata[3]}\\u003cbr\\u003eStress@10%_kPa=%{customdata[4]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"PAA\",\"marker\":{\"color\":\"#EF553B\",\"symbol\":\"diamond\",\"opacity\":0.85,\"size\":6},\"mode\":\"markers\",\"name\":\"PAA\",\"scene\":\"scene\",\"showlegend\":true,\"x\":[50.0,40.0],\"y\":[0.15,0.15],\"z\":[3.9999999999999996,3.1499999999999995],\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"xaxis\":{\"title\":{\"text\":\"UTS_kPa\"}},\"yaxis\":{\"title\":{\"text\":\"Fracture_strain_frac\"}},\"zaxis\":{\"title\":{\"text\":\"Toughness_kJ_m3\"}}},\"legend\":{\"title\":{\"text\":\"mat_type\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"3D Property Space: UTS_kPa vs Fracture_strain_frac vs Toughness_kJ_m3\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('4ce808bf-4093-4509-bd34-5bead3b0df03');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ℹ️ Composition 3D scatter skipped: AM/MBA/APS or composition table not found. Set COMPOSITION_PATH/COMPOSITION_SHEET and ensure columns exist.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"2d5b1b50-497f-4782-b364-539f1e353964\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2d5b1b50-497f-4782-b364-539f1e353964\")) {                    Plotly.newPlot(                        \"2d5b1b50-497f-4782-b364-539f1e353964\",                        [{\"customdata\":[[\"Cel10_e\",10.0],[\"Cel10_f\",10.0],[\"Cel1_e\",1.0],[\"Cel1_f\",1.0],[\"Cel20_e\",20.0],[\"Cel20_f\",20.0],[\"Cel5_e\",5.0],[\"Cel5_f\",5.0]],\"hovertemplate\":\"mat_type=Cel\\u003cbr\\u003enorm_UTS_kPa=%{x}\\u003cbr\\u003enorm_Fracture_strain_frac=%{y}\\u003cbr\\u003enorm_Toughness_kJ_m3=%{z}\\u003cbr\\u003elabel=%{customdata[0]}\\u003cbr\\u003emat_level=%{customdata[1]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Cel\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\",\"opacity\":0.8,\"size\":6},\"mode\":\"markers\",\"name\":\"Cel\",\"scene\":\"scene\",\"showlegend\":true,\"x\":[0.8181818181818181,0.2727272727272727,0.909090909090909,0.45454545454545436,1.0,0.36363636363636354,0.6363636363636362,0.09090909090909083],\"y\":[0.6666666666666679,0.0,1.0,0.3333333333333339,0.0,0.0,0.3333333333333339,0.0],\"z\":[0.7211109769691687,0.23888861879038836,0.9999999999999999,0.2833340947738091,0.7499991520163355,0.355555153548485,0.4833337290590437,0.08333323911292612],\"type\":\"scatter3d\"},{\"customdata\":[[\"PAA_e\",0.0],[\"PAA_f\",0.0]],\"hovertemplate\":\"mat_type=PAA\\u003cbr\\u003enorm_UTS_kPa=%{x}\\u003cbr\\u003enorm_Fracture_strain_frac=%{y}\\u003cbr\\u003enorm_Toughness_kJ_m3=%{z}\\u003cbr\\u003elabel=%{customdata[0]}\\u003cbr\\u003emat_level=%{customdata[1]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"PAA\",\"marker\":{\"color\":\"#EF553B\",\"symbol\":\"circle\",\"opacity\":0.8,\"size\":6},\"mode\":\"markers\",\"name\":\"PAA\",\"scene\":\"scene\",\"showlegend\":true,\"x\":[0.18181818181818177,0.0],\"y\":[0.0,0.0],\"z\":[0.18888867532263265,0.0],\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"xaxis\":{\"title\":{\"text\":\"norm_UTS_kPa\"}},\"yaxis\":{\"title\":{\"text\":\"norm_Fracture_strain_frac\"}},\"zaxis\":{\"title\":{\"text\":\"norm_Toughness_kJ_m3\"}}},\"legend\":{\"title\":{\"text\":\"mat_type\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"Normalized 3D Property Cube: UTS_kPa, Fracture_strain_frac, Toughness_kJ_m3 (0–1)\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('2d5b1b50-497f-4782-b364-539f1e353964');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Done. Tips:\n",
            "• PROPERTY_X/Y/Z বদলে যে কোন ৩টি derived property প্লট করুন।\n",
            "• COMPOSITION_PATH/COMPOSITION_SHEET দিন এবং AM/MBA/APS কলাম ঠিক থাকলে composition 3D ও GP/EI প্লট আসবে।\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ব্যবহার টিপস\n",
        "\n",
        "Property 3D: PROPERTY_X/PROPERTY_Y/PROPERTY_Z–তে আপনাদের আগ্রহের ৩টি property (যেমন E0_5_kPa, Yield_stress_kPa, Stress@10%_kPa) বসিয়ে দিন।\n",
        "\n",
        "Composition 3D & GP/EI: composition টেবিল দিন (COMPOSITION_PATH বা COMPOSITION_SHEET), আর কলাম নাম AM/MBA/APS-এর সাথে ম্যাচ করলে 3D composition scatter, GP prediction isosurfaces, আর EI isosurface দেখাবে—পেপারে বর্ণিত BO-স্টাইল অনুসন্ধানের (exploration) ভিজুয়াল গাইড হিসেবে উপকারী।\n",
        "\n",
        "summerstudent2022_PAAmMachineLe…\n",
        "\n",
        "গ্রিড সাইজ/সময়: GRID_N বড় হলে isosurface আরও স্মুথ, তবে কম্পিউট ভারী হয়। 16–20 ভাল ব্যালান্স।\n",
        "\n",
        "Target change: SURROGATE_TARGET বদলে Toughness/UTS/অন্যান্য property’র জন্যও GP/EI প্লট করতে পারবেন।\n",
        "\n",
        "চাইলে আপনার composition ফাইল/কলাম নাম একবার বললে, এগুলো আমি প্রিসেট করে দেব, যাতে আর কিছু না বদলাতে হয়।"
      ],
      "metadata": {
        "id": "YpVoluASGQb1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YjJHKDXTEzDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q52Sp1vOEzHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XOBp7jStEzLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zkxqD5-NEzOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1UWY7dbIEzSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tc2DPjoY9Nvd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}