{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+85Z/EtDQ2h8x0poKG98n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alikaiser12/AI/blob/main/LangChain_Custom_Tool_Integration_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# Single-Cell Colab Demo (No pydantic error, fully working as of Oct 2024)\n",
        "# Uses modern package structure: langchain-core, langchain-community, and langchain\n",
        "# and imports FakeListLLM from langchain_core.language_models.fake.\n",
        "# ===============================================\n",
        "\n",
        "# 1) Install compatible versions\n",
        "!pip install -q -U \"pydantic>=2.7,<3\" \\\n",
        "                  \"langchain>=0.3.0,<0.4\" \\\n",
        "                  \"langchain-core>=0.3.0,<0.4\" \\\n",
        "                  \"langchain-community>=0.3.0,<0.4\"\n",
        "\n",
        "# 2) Imports (note the langchain_core paths)\n",
        "from langchain_core.tools import Tool\n",
        "from langchain_core.language_models.fake import FakeListLLM\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "\n",
        "# 3) Mock API function\n",
        "def query_order_status(order_id: str) -> str:\n",
        "    \"\"\"Return a fake order status for the given order_id.\"\"\"\n",
        "    return \"Shipped\" if order_id == \"123\" else \"In Process\"\n",
        "\n",
        "# 4) Create the custom tool via Tool (not StructuredTool)\n",
        "order_checker_tool = Tool(\n",
        "    name=\"OrderCheckerTool\",\n",
        "    func=query_order_status,\n",
        "    description=(\n",
        "        \"Check the status of an order by ID. \"\n",
        "        \"Use this tool when the user asks for an order status and provides the order_id.\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "# 5) Simulated LLM responses\n",
        "fake_responses = [\n",
        "    \"I'll check the first order via OrderCheckerTool.\\nAction: OrderCheckerTool\\nAction Input: 123\",\n",
        "    \"Got the first result. Now I'll check the second order.\\nAction: OrderCheckerTool\\nAction Input: 999\",\n",
        "    \"Final Answer: Order 123 is Shipped and Order 999 is In Process.\"\n",
        "]\n",
        "llm = FakeListLLM(responses=fake_responses)\n",
        "\n",
        "# 6) Initialize agent and run test query\n",
        "agent = initialize_agent(\n",
        "    tools=[order_checker_tool],\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "query = \"I have two order IDs: '123' and '999'. What is the status of each of these orders?\"\n",
        "print(\"User Query:\", query)\n",
        "result = agent.run(query)\n",
        "\n",
        "# 7) Final, client-facing confirmation\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Final Answer:\")\n",
        "print(result)\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4F96e6lyVjmA",
        "outputId": "5dd665e5-3c70-431e-d852-0c177ef9a2d4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User Query: I have two order IDs: '123' and '999'. What is the status of each of these orders?\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI'll check the first order via OrderCheckerTool.\n",
            "Action: OrderCheckerTool\n",
            "Action Input: 123\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mShipped\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mGot the first result. Now I'll check the second order.\n",
            "Action: OrderCheckerTool\n",
            "Action Input: 999\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mIn Process\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: Order 123 is Shipped and Order 999 is In Process.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "============================================================\n",
            "Final Answer:\n",
            "Order 123 is Shipped and Order 999 is In Process.\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2061919265.py:39: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 1.0. Use :meth:`~Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc.` instead.\n",
            "  agent = initialize_agent(\n",
            "/tmp/ipython-input-2061919265.py:48: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  result = agent.run(query)\n"
          ]
        }
      ]
    }
  ]
}