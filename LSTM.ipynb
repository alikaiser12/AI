{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOIWEYLgEAamNYBtWDQ9OIU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alikaiser12/AI/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting Next Word in a Sentence with LSTM"
      ],
      "metadata": {
        "id": "gdfpo-3C7rn9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In this example, we will train an LSTM model to predict the next word in a sentence. Let's take a simple dataset of sentences and train the LSTM model to predict the next word given the current sequence of words."
      ],
      "metadata": {
        "id": "HkHE9KfT7uF1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Import the Required Libraries\n",
        "We will use the Keras API with TensorFlow to build our LSTM model."
      ],
      "metadata": {
        "id": "Mwypi_4X7679"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hIhbnNkf7pam"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Numpy is used for numerical operations (arrays and matrices).\n",
        "\n",
        "TensorFlow and Keras are used to build and train the LSTM model.\n",
        "\n",
        "pad_sequences is used to ensure all input sequences have the same length.\n",
        "\n",
        "train_test_split will split the data into training and testing sets."
      ],
      "metadata": {
        "id": "9C-mhegB7rdt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Prepare the Dataset\n",
        "We will create a simple dataset of sentences, each consisting of words. Our task is to predict the next word in the sequence."
      ],
      "metadata": {
        "id": "k95esE1B7-gN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example sentences\n",
        "sentences = ['i love machine learning', 'i love deep learning', 'deep learning is amazing']\n",
        "\n",
        "# Create a dictionary of unique words (vocabulary)\n",
        "vocab = set(' '.join(sentences).split())  # Extract unique words\n",
        "word_to_index = {word: i+1 for i, word in enumerate(vocab)}  # Map words to integers\n",
        "index_to_word = {i: word for word, i in word_to_index.items()}  # Reverse mapping\n",
        "\n",
        "# Convert sentences into sequences of integers\n",
        "sequences = [[word_to_index[word] for word in sentence.split()] for sentence in sentences]\n",
        "\n",
        "# Prepare the input and output sequences for next word prediction\n",
        "X_list = []\n",
        "y_list = []\n",
        "for seq in sequences:\n",
        "    for i in range(1, len(seq)):\n",
        "        # Input is the sequence up to the current word\n",
        "        X_list.append(seq[:i])\n",
        "        # Output is the next word\n",
        "        y_list.append(seq[i])\n",
        "\n",
        "# Pad the input sequences and convert to numpy array\n",
        "X = pad_sequences(X_list, padding='pre')\n",
        "\n",
        "# Reshape X to (samples, timesteps, features). We have 1 feature per word.\n",
        "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "\n",
        "# Convert y to a numpy array\n",
        "y = np.array(y_list)"
      ],
      "metadata": {
        "id": "W1op3Ewk7vG1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vocabulary: We create a set of unique words from the sentences.\n",
        "\n",
        "Mapping Words to Integers: Each word is mapped to a unique integer, allowing the model to process the text.\n",
        "\n",
        "Input and Output Sequences: We create input sequences (X) and output sequences (y) where the output is the next word in the sequence.\n",
        "\n",
        "# Step 3: Padding the Sequences\n",
        "LSTM models require the input data to have the same length. We use padding to ensure all sequences are of equal length."
      ],
      "metadata": {
        "id": "RxPjMdcw7vs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell is no longer needed as padding is done in the previous cell."
      ],
      "metadata": {
        "id": "204o8ltg8pbN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "pad_sequences ensures that all sequences are padded to the same length. It adds zeros at the beginning of shorter sequences (pre-padding).\n",
        "\n",
        "# Step 4: Reshaping the Input Data\n",
        "Before feeding the data into the LSTM model, we need to reshape it into the format (samples, timesteps, features)."
      ],
      "metadata": {
        "id": "uM7loBh38qjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell is no longer needed as reshaping is done in the previous cell."
      ],
      "metadata": {
        "id": "w4Xhkx2q8pen"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshape: The LSTM expects data in the shape (samples, timesteps, features). In this case, we have 1 feature per word.\n",
        "\n",
        "# Step 5: Build the LSTM Model\n",
        "Now we can create the LSTM model using Keras. Here's a simple model with one LSTM layer and one Dense output layer."
      ],
      "metadata": {
        "id": "mJg34JPf8rJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Add an LSTM layer with 50 units (neurons) and the input shape of the sequence length and number of features\n",
        "model.add(LSTM(50, input_shape=(X.shape[1], 1), activation='relu'))\n",
        "\n",
        "# Add a Dense layer to predict the next word (the output of the LSTM)\n",
        "model.add(Dense(len(vocab), activation='softmax'))  # Number of words in the vocab as the output size\n",
        "\n",
        "# Compile the model with categorical crossentropy loss and Adam optimizer\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdXsojb08pyd",
        "outputId": "f3ea4a52-ecc1-41c0-fd54-bfe5c9ec8047"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM Layer: The LSTM layer processes sequential data. We specify the number of units (neurons) as 50 and the input shape as (sequence_length, 1) because each word is a single feature.\n",
        "\n",
        "Dense Layer: The Dense layer produces the output prediction, which is a probability distribution over the vocabulary.\n",
        "\n",
        "Compile: We use sparse_categorical_crossentropy loss for multi-class classification (predicting the next word) and Adam optimizer for training.\n",
        "\n",
        "# Step 6: Train the LSTM Model\n",
        "Now, let's train the LSTM model on our data."
      ],
      "metadata": {
        "id": "e_YpyLfU8r6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of X:\", X.shape)\n",
        "print(\"Shape of y:\", y.shape)\n",
        "\n",
        "# Increase batch size to potentially avoid low-level TensorFlow issues\n",
        "model.fit(X, y, epochs=100, batch_size=2) # Increased batch size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o5zjCaAH8p8d",
        "outputId": "838ef495-f85a-4679-ab33-2dd7853a47fb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X: (9, 3, 1)\n",
            "Shape of y: (9,)\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/tmp/ipython-input-6-736608511.py\", line 5, in <cell line: 0>\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 113, in one_step_on_data\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 60, in train_step\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/trainer.py\", line 383, in _compute_loss\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/trainer.py\", line 351, in compute_loss\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/compile_utils.py\", line 691, in __call__\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/compile_utils.py\", line 700, in call\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/losses/loss.py\", line 67, in __call__\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py\", line 33, in call\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py\", line 2246, in sparse_categorical_crossentropy\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py\", line 1963, in sparse_categorical_crossentropy\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/nn.py\", line 744, in sparse_categorical_crossentropy\n\nReceived a label value of 7 which is outside the valid range of [0, 7).  Label values: 2 7\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_multi_step_on_iterator_2094]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-6-736608511.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Increase batch size to potentially avoid low-level TensorFlow issues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Increased batch size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mkeras_symbolic_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeras_symbolic_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/tmp/ipython-input-6-736608511.py\", line 5, in <cell line: 0>\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 113, in one_step_on_data\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 60, in train_step\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/trainer.py\", line 383, in _compute_loss\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/trainer.py\", line 351, in compute_loss\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/compile_utils.py\", line 691, in __call__\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/compile_utils.py\", line 700, in call\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/losses/loss.py\", line 67, in __call__\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py\", line 33, in call\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py\", line 2246, in sparse_categorical_crossentropy\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py\", line 1963, in sparse_categorical_crossentropy\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/nn.py\", line 744, in sparse_categorical_crossentropy\n\nReceived a label value of 7 which is outside the valid range of [0, 7).  Label values: 2 7\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_multi_step_on_iterator_2094]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training: We use the fit() method to train the model. We train for 100 epochs with a batch size of 1 (since we have a small dataset).\n",
        "\n",
        "# Step 7: Predict the Next Word\n",
        "Once the model is trained, we can use it to predict the next word in a sentence."
      ],
      "metadata": {
        "id": "Fmo8E1MR8se9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentence = 'i love'\n",
        "test_sequence = [word_to_index[word] for word in test_sentence.split()]\n",
        "test_sequence = pad_sequences([test_sequence], padding='pre', maxlen=X.shape[1])\n",
        "test_sequence = test_sequence.reshape((test_sequence.shape[0], test_sequence.shape[1], 1))\n",
        "\n",
        "predicted_index = model.predict(test_sequence)\n",
        "predicted_word = index_to_word[np.argmax(predicted_index)]\n",
        "print(f\"The next word after '{test_sentence}' is: {predicted_word}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_soda7i48tDF",
        "outputId": "d7a368f9-e934-42b1-a740-1bc970ce8ec2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
            "The next word after 'i love' is: love\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction: We convert the test sentence into a sequence of integers, pad it, and reshape it to match the input format expected by the LSTM. We then use the model to predict the next word by selecting the word with the highest probability (argmax).\n",
        "\n",
        "# Detailed Explanation of the Code:\n",
        "Data Preprocessing: We convert sentences into sequences of integers. Each word is mapped to a unique integer.\n",
        "\n",
        "Padding: We pad the sequences to ensure that they all have the same length. This is necessary for RNNs and LSTMs.\n",
        "\n",
        "Reshaping: The LSTM expects data to have a specific shape: (samples, timesteps, features).\n",
        "\n",
        "Model Creation: We create an LSTM model with one LSTM layer and one Dense output layer. The LSTM layer learns patterns from the sequential data.\n",
        "\n",
        "Training: We train the model on our input and output data, allowing it to learn the relationships between the words.\n",
        "\n",
        "Prediction: Once trained, the model can predict the next word given an input sequence.\n",
        "\n",
        "# Summary:\n",
        "LSTMs are designed to handle sequential data and can remember long-term dependencies.\n",
        "\n",
        "In this example, we used an LSTM to predict the next word in a sentence.\n",
        "\n",
        "LSTMs are particularly useful for tasks like text generation, language translation, and speech recognition."
      ],
      "metadata": {
        "id": "nY-U21QP-PR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Example sentences\n",
        "sentences = ['i love machine learning', 'i love deep learning', 'deep learning is amazing']\n",
        "\n",
        "# Create a dictionary of unique words (vocabulary)\n",
        "vocab = sorted(list(set(' '.join(sentences).split()))) # Extract unique words and sort for consistent indexing\n",
        "word_to_index = {word: i for i, word in enumerate(vocab)}  # Map words to integers, starting from 0\n",
        "index_to_word = {i: word for word, i in word_to_index.items()}  # Reverse mapping\n",
        "\n",
        "# Convert sentences into sequences of integers\n",
        "sequences = [[word_to_index[word] for word in sentence.split()] for sentence in sentences]\n",
        "\n",
        "# Prepare the input and output sequences for next word prediction\n",
        "X_list = []\n",
        "y_list = []\n",
        "for seq in sequences:\n",
        "    for i in range(1, len(seq)):\n",
        "        # Input is the sequence up to the current word\n",
        "        X_list.append(seq[:i])\n",
        "        # Output is the next word\n",
        "        y_list.append(seq[i])\n",
        "\n",
        "# Pad the input sequences and convert to numpy array\n",
        "X = pad_sequences(X_list, padding='pre')\n",
        "\n",
        "# Reshape X to (samples, timesteps, features). We have 1 feature per word.\n",
        "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "\n",
        "# Convert y to a numpy array (output labels)\n",
        "y = np.array(y_list)\n",
        "\n",
        "# Print debug information\n",
        "print(\"Vocabulary:\", vocab)\n",
        "print(\"Word to index mapping:\", word_to_index)\n",
        "print(\"Unique values in y:\", np.unique(y))\n",
        "print(\"Shape of X:\", X.shape)\n",
        "print(\"Shape of y:\", y.shape)\n",
        "\n",
        "\n",
        "# Build the LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# Add an LSTM layer with 50 units (neurons) and the input shape of (sequence_length, 1)\n",
        "model.add(LSTM(50, input_shape=(X.shape[1], 1), activation='relu'))\n",
        "\n",
        "# Add a Dense layer to predict the next word (the output of the LSTM)\n",
        "model.add(Dense(len(vocab), activation='softmax'))  # Number of words in the vocab as the output size\n",
        "\n",
        "# Compile the model with sparse categorical crossentropy loss and Adam optimizer\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model on the data\n",
        "model.fit(X, y, epochs=100, batch_size=1)\n",
        "\n",
        "# Make a prediction for the next word after a given sentence\n",
        "test_sentence = 'i love'\n",
        "test_sequence = [word_to_index[word] for word in test_sentence.split()]\n",
        "test_sequence = pad_sequences([test_sequence], padding='pre', maxlen=X.shape[1])\n",
        "test_sequence = test_sequence.reshape((test_sequence.shape[0], test_sequence.shape[1], 1))\n",
        "\n",
        "predicted_index = model.predict(test_sequence)\n",
        "predicted_word = index_to_word[np.argmax(predicted_index)]\n",
        "print(f\"The next word after '{test_sentence}' is: {predicted_word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEn0bujW_CPs",
        "outputId": "881b9d6f-cf3f-4312-93bf-afca1a2e7293"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: ['amazing', 'deep', 'i', 'is', 'learning', 'love', 'machine']\n",
            "Word to index mapping: {'amazing': 0, 'deep': 1, 'i': 2, 'is': 3, 'learning': 4, 'love': 5, 'machine': 6}\n",
            "Unique values in y: [0 1 3 4 5 6]\n",
            "Shape of X: (9, 3, 1)\n",
            "Shape of y: (9,)\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1107 - loss: 1.9186    \n",
            "Epoch 2/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6320 - loss: 1.8891 \n",
            "Epoch 3/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3287 - loss: 1.8698     \n",
            "Epoch 4/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3019 - loss: 1.8956     \n",
            "Epoch 5/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2152 - loss: 1.9530     \n",
            "Epoch 6/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6320 - loss: 1.7733 \n",
            "Epoch 7/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1060 - loss: 1.9659     \n",
            "Epoch 8/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5987 - loss: 1.7132 \n",
            "Epoch 9/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3602 - loss: 1.7521     \n",
            "Epoch 10/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1676 - loss: 1.9213     \n",
            "Epoch 11/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3269 - loss: 1.7028     \n",
            "Epoch 12/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3269 - loss: 1.7910     \n",
            "Epoch 13/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2787 - loss: 1.7869     \n",
            "Epoch 14/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2894 - loss: 1.8120     \n",
            "Epoch 15/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3727 - loss: 1.7088     \n",
            "Epoch 16/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2620 - loss: 1.7091     \n",
            "Epoch 17/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2186 - loss: 1.7013     \n",
            "Epoch 18/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3144 - loss: 1.7222     \n",
            "Epoch 19/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5987 - loss: 1.4242 \n",
            "Epoch 20/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1676 - loss: 1.8155     \n",
            "Epoch 21/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4237 - loss: 1.5084     \n",
            "Epoch 22/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5102 - loss: 1.4363 \n",
            "Epoch 23/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3287 - loss: 1.7252    \n",
            "Epoch 24/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3602 - loss: 1.4124    \n",
            "Epoch 25/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2311 - loss: 1.6701     \n",
            "Epoch 26/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4287 - loss: 1.3304 \n",
            "Epoch 27/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3404 - loss: 1.4404     \n",
            "Epoch 28/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4537 - loss: 1.2277 \n",
            "Epoch 29/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2004 - loss: 1.6934    \n",
            "Epoch 30/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2777 - loss: 1.4454     \n",
            "Epoch 31/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1454 - loss: 1.5329\n",
            "Epoch 32/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2547 - loss: 1.3360     \n",
            "Epoch 33/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1930 - loss: 1.5009     \n",
            "Epoch 34/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5709 - loss: 1.1524 \n",
            "Epoch 35/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4676 - loss: 1.1811 \n",
            "Epoch 36/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6644 - loss: 0.9491 \n",
            "Epoch 37/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2500 - loss: 1.5496     \n",
            "Epoch 38/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2801 - loss: 1.4661     \n",
            "Epoch 39/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4000 - loss: 1.4976 \n",
            "Epoch 40/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3926 - loss: 1.2407     \n",
            "Epoch 41/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3973 - loss: 1.4211     \n",
            "Epoch 42/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6056 - loss: 1.1673 \n",
            "Epoch 43/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7324 - loss: 1.0545 \n",
            "Epoch 44/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6106 - loss: 1.1121 \n",
            "Epoch 45/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4283 - loss: 1.2442     \n",
            "Epoch 46/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7467 - loss: 0.9339 \n",
            "Epoch 47/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7000 - loss: 0.8836 \n",
            "Epoch 48/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2573 - loss: 1.3741     \n",
            "Epoch 49/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3333 - loss: 1.2569     \n",
            "Epoch 50/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5566 - loss: 1.1238     \n",
            "Epoch 51/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3666 - loss: 1.1964     \n",
            "Epoch 52/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3791 - loss: 1.1081     \n",
            "Epoch 53/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6834 - loss: 0.8884 \n",
            "Epoch 54/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5050 - loss: 0.9444     \n",
            "Epoch 55/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4783 - loss: 1.0559     \n",
            "Epoch 56/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5440 - loss: 1.1027 \n",
            "Epoch 57/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5473 - loss: 1.0111 \n",
            "Epoch 58/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5634 - loss: 0.8259     \n",
            "Epoch 59/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4806 - loss: 0.9918     \n",
            "Epoch 60/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4616 - loss: 0.8064     \n",
            "Epoch 61/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7667 - loss: 0.6548 \n",
            "Epoch 62/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6691 - loss: 0.9105 \n",
            "Epoch 63/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4874 - loss: 0.9930     \n",
            "Epoch 64/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3856 - loss: 1.0287     \n",
            "Epoch 65/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4408 - loss: 1.0233     \n",
            "Epoch 66/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5384 - loss: 0.7377 \n",
            "Epoch 67/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6344 - loss: 0.6901 \n",
            "Epoch 68/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6991 - loss: 0.7857 \n",
            "Epoch 69/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6223 - loss: 0.8317     \n",
            "Epoch 70/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7056 - loss: 0.7075 \n",
            "Epoch 71/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2967 - loss: 0.8892     \n",
            "Epoch 72/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3656 - loss: 0.9478     \n",
            "Epoch 73/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5634 - loss: 0.7973     \n",
            "Epoch 74/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3110 - loss: 0.8062     \n",
            "Epoch 75/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8014 - loss: 0.6480 \n",
            "Epoch 76/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6306 - loss: 0.6853 \n",
            "Epoch 77/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4874 - loss: 0.8233     \n",
            "Epoch 78/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8671 - loss: 0.6294 \n",
            "Epoch 79/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7667 - loss: 0.5969 \n",
            "Epoch 80/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6991 - loss: 0.5822 \n",
            "Epoch 81/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6348 - loss: 0.6680     \n",
            "Epoch 82/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4013 - loss: 0.7851     \n",
            "Epoch 83/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7838 - loss: 0.7746 \n",
            "Epoch 84/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6713 - loss: 0.7329     \n",
            "Epoch 85/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7181 - loss: 0.5860 \n",
            "Epoch 86/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8853 - loss: 0.5983 \n",
            "Epoch 87/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8653 - loss: 0.6862 \n",
            "Epoch 88/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8796 - loss: 0.5847 \n",
            "Epoch 89/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8921 - loss: 0.6040 \n",
            "Epoch 90/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8796 - loss: 0.6310 \n",
            "Epoch 91/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6913 - loss: 0.6121 \n",
            "Epoch 92/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7689 - loss: 0.5416 \n",
            "Epoch 93/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6056 - loss: 0.6565     \n",
            "Epoch 94/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8546 - loss: 0.4303 \n",
            "Epoch 95/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9431 - loss: 0.5311 \n",
            "Epoch 96/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9163 - loss: 0.6314 \n",
            "Epoch 97/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8264 - loss: 0.3704 \n",
            "Epoch 98/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8037 - loss: 0.6604 \n",
            "Epoch 99/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9163 - loss: 0.4293 \n",
            "Epoch 100/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9163 - loss: 0.4273 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step\n",
            "The next word after 'i love' is: deep\n"
          ]
        }
      ]
    }
  ]
}