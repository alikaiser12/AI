{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alikaiser12/AI/blob/main/traffic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Txz83rEy0tK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import re\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3Nte6-J0Csw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0mNQUC4z-D7",
        "outputId": "85b64bc9-4f6f-4012-98b7-1da920470695"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veJ8eJ5s0Myo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc8e5a4c-0268-476e-d346-4d048b10ea7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/Video/traffic-1.avi']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Define the folder path in Google Drive (adjust according to your folder structure)\n",
        "data_path = '/content/drive/MyDrive/Video'\n",
        "\n",
        "# List .jpg files in the folder\n",
        "Video_paths = [os.path.join(data_path, file) for file in os.listdir(data_path) if file.lower().endswith('.avi')]\n",
        "\n",
        "# Print the list of image paths\n",
        "print(Video_paths)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"yolov8n.pt\")  # Load a pretrained YOLOv8n model\n",
        "cap = cv2.VideoCapture(\"traffic-1.avi\")\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    results = model(frame)  # Detect objects\n",
        "    annotated_frame = results[0].plot()  # Draw bounding boxes\n",
        "    cv2.imshow(\"Annotated Video\", annotated_frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "cap.release()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQzNdCiabW5k",
        "outputId": "03d4bab7-c09d-4021-93d0-c4b516e6ce9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Using cached ultralytics-8.3.159-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Using cached ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.6.15)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Using cached ultralytics-8.3.159-py3-none-any.whl (1.0 MB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.159 ultralytics-thop-2.0.14\n",
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.25M/6.25M [00:00<00:00, 53.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoP4UMWCbW-L",
        "outputId": "2f651ac1-6312-4897-efec-451b6c9bd765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "# Create a folder to save extracted frames\n",
        "output_folder = \"frames\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Load the video file\n",
        "video_path = \"/content/drive/MyDrive/Video/traffic-1.avi\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Check if video opened successfully\n",
        "if not cap.isOpened():\n",
        "    print(\"Error: Could not open video.\")\n",
        "    exit()\n",
        "\n",
        "frame_number = 0\n",
        "\n",
        "# Loop through video frames\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break  # No more frames, end of video\n",
        "\n",
        "    # Optional: Do something with the frame (e.g., display, process, etc.)\n",
        "\n",
        "    # Save each frame as an image\n",
        "    frame_filename = os.path.join(output_folder, f\"frame_{frame_number:04d}.png\")\n",
        "    cv2.imwrite(frame_filename, frame)\n",
        "\n",
        "    frame_number += 1\n",
        "\n",
        "# Release the video capture object\n",
        "cap.release()\n",
        "print(f\"Done! Extracted {frame_number} frames to '{output_folder}' folder.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Im0CDSCcpQE",
        "outputId": "e939bcbd-6f91-469c-8653-32b798ffc41f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done! Extracted 53 frames to 'frames' folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MEBKzmVcpTz",
        "outputId": "d7267bcb-6f07-4bef-970f-f668bfad736e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 17496, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 17496 (delta 2), reused 0 (delta 0), pack-reused 17491 (from 3)\u001b[K\n",
            "Receiving objects: 100% (17496/17496), 16.56 MiB | 19.11 MiB/s, done.\n",
            "Resolving deltas: 100% (11997/11997), done.\n",
            "/content/yolov5\n",
            "Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (3.1.44)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (2.0.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=10.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (11.2.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (1.15.3)\n",
            "Collecting thop>=0.1.1 (from -r requirements.txt (line 14))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (4.67.1)\n",
            "Requirement already satisfied: ultralytics>=8.2.34 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (8.3.159)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 27)) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 28)) (0.13.2)\n",
            "Requirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 42)) (75.2.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.12)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.9.0.post0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2025.6.15)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics>=8.2.34->-r requirements.txt (line 18)) (9.0.0)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics>=8.2.34->-r requirements.txt (line 18)) (2.0.14)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (3.0.2)\n",
            "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: thop\n",
            "Successfully installed thop-0.1.1.post2209072238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --source /content/frames --weights yolov5s.pt --conf 0.4 --save-txt --save-conf --project ../output --name annotated_frames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4l9m8cScpXj",
        "outputId": "b117532d-2311-427a-f880-6abda5df41fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['yolov5s.pt'], source=/content/frames, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.4, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_format=0, save_csv=False, save_conf=True, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../output, name=annotated_frames, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ğŸš€ v7.0-421-g79c4c31d Python-3.11.13 torch-2.6.0+cu124 CPU\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 83.9MB/s]\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "image 1/53 /content/frames/frame_0000.png: 480x640 14 cars, 1 truck, 390.7ms\n",
            "image 2/53 /content/frames/frame_0001.png: 480x640 15 cars, 1 truck, 331.7ms\n",
            "image 3/53 /content/frames/frame_0002.png: 480x640 14 cars, 1 truck, 293.1ms\n",
            "image 4/53 /content/frames/frame_0003.png: 480x640 13 cars, 1 bus, 1 truck, 275.5ms\n",
            "image 5/53 /content/frames/frame_0004.png: 480x640 12 cars, 1 truck, 295.1ms\n",
            "image 6/53 /content/frames/frame_0005.png: 480x640 15 cars, 1 bus, 1 truck, 291.8ms\n",
            "image 7/53 /content/frames/frame_0006.png: 480x640 15 cars, 1 bus, 266.5ms\n",
            "image 8/53 /content/frames/frame_0007.png: 480x640 15 cars, 1 bus, 299.5ms\n",
            "image 9/53 /content/frames/frame_0008.png: 480x640 12 cars, 1 bus, 281.9ms\n",
            "image 10/53 /content/frames/frame_0009.png: 480x640 14 cars, 1 bus, 274.6ms\n",
            "image 11/53 /content/frames/frame_0010.png: 480x640 11 cars, 287.0ms\n",
            "image 12/53 /content/frames/frame_0011.png: 480x640 13 cars, 1 bus, 289.3ms\n",
            "image 13/53 /content/frames/frame_0012.png: 480x640 13 cars, 1 bus, 1 truck, 282.8ms\n",
            "image 14/53 /content/frames/frame_0013.png: 480x640 12 cars, 1 truck, 278.0ms\n",
            "image 15/53 /content/frames/frame_0014.png: 480x640 12 cars, 340.2ms\n",
            "image 16/53 /content/frames/frame_0015.png: 480x640 13 cars, 1 bus, 280.5ms\n",
            "image 17/53 /content/frames/frame_0016.png: 480x640 12 cars, 1 bus, 274.0ms\n",
            "image 18/53 /content/frames/frame_0017.png: 480x640 12 cars, 2 buss, 315.9ms\n",
            "image 19/53 /content/frames/frame_0018.png: 480x640 14 cars, 276.1ms\n",
            "image 20/53 /content/frames/frame_0019.png: 480x640 10 cars, 2 buss, 280.4ms\n",
            "image 21/53 /content/frames/frame_0020.png: 480x640 13 cars, 1 bus, 1 truck, 282.6ms\n",
            "image 22/53 /content/frames/frame_0021.png: 480x640 11 cars, 1 bus, 1 truck, 301.4ms\n",
            "image 23/53 /content/frames/frame_0022.png: 480x640 12 cars, 1 bus, 294.5ms\n",
            "image 24/53 /content/frames/frame_0023.png: 480x640 13 cars, 1 bus, 488.4ms\n",
            "image 25/53 /content/frames/frame_0024.png: 480x640 15 cars, 1 truck, 614.9ms\n",
            "image 26/53 /content/frames/frame_0025.png: 480x640 10 cars, 1 bus, 1574.3ms\n",
            "image 27/53 /content/frames/frame_0026.png: 480x640 12 cars, 1446.8ms\n",
            "image 28/53 /content/frames/frame_0027.png: 480x640 14 cars, 2 buss, 714.6ms\n",
            "image 29/53 /content/frames/frame_0028.png: 480x640 16 cars, 1 bus, 570.5ms\n",
            "image 30/53 /content/frames/frame_0029.png: 480x640 17 cars, 1 bus, 582.0ms\n",
            "image 31/53 /content/frames/frame_0030.png: 480x640 13 cars, 1 bus, 1 truck, 667.3ms\n",
            "image 32/53 /content/frames/frame_0031.png: 480x640 16 cars, 1 truck, 576.1ms\n",
            "image 33/53 /content/frames/frame_0032.png: 480x640 16 cars, 504.0ms\n",
            "image 34/53 /content/frames/frame_0033.png: 480x640 15 cars, 1 bus, 280.1ms\n",
            "image 35/53 /content/frames/frame_0034.png: 480x640 15 cars, 1 bus, 280.9ms\n",
            "image 36/53 /content/frames/frame_0035.png: 480x640 12 cars, 1 bus, 1 truck, 304.7ms\n",
            "image 37/53 /content/frames/frame_0036.png: 480x640 12 cars, 1 bus, 1 truck, 278.4ms\n",
            "image 38/53 /content/frames/frame_0037.png: 480x640 14 cars, 1 bus, 284.6ms\n",
            "image 39/53 /content/frames/frame_0038.png: 480x640 12 cars, 1 bus, 295.2ms\n",
            "image 40/53 /content/frames/frame_0039.png: 480x640 14 cars, 1 bus, 272.3ms\n",
            "image 41/53 /content/frames/frame_0040.png: 480x640 11 cars, 1 bus, 278.7ms\n",
            "image 42/53 /content/frames/frame_0041.png: 480x640 9 cars, 1 bus, 272.7ms\n",
            "image 43/53 /content/frames/frame_0042.png: 480x640 10 cars, 1 bus, 1 truck, 301.2ms\n",
            "image 44/53 /content/frames/frame_0043.png: 480x640 10 cars, 1 bus, 273.2ms\n",
            "image 45/53 /content/frames/frame_0044.png: 480x640 11 cars, 1 truck, 282.5ms\n",
            "image 46/53 /content/frames/frame_0045.png: 480x640 11 cars, 1 bus, 2 trucks, 299.7ms\n",
            "image 47/53 /content/frames/frame_0046.png: 480x640 10 cars, 2 trucks, 281.7ms\n",
            "image 48/53 /content/frames/frame_0047.png: 480x640 13 cars, 281.4ms\n",
            "image 49/53 /content/frames/frame_0048.png: 480x640 11 cars, 1 truck, 290.2ms\n",
            "image 50/53 /content/frames/frame_0049.png: 480x640 11 cars, 1 truck, 292.7ms\n",
            "image 51/53 /content/frames/frame_0050.png: 480x640 13 cars, 280.6ms\n",
            "image 52/53 /content/frames/frame_0051.png: 480x640 13 cars, 279.8ms\n",
            "image 53/53 /content/frames/frame_0052.png: 480x640 11 cars, 304.4ms\n",
            "Speed: 1.0ms pre-process, 381.8ms inference, 4.6ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m../output/annotated_frames\u001b[0m\n",
            "53 labels saved to ../output/annotated_frames/labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "image_folder = \"/content/output/annotated_frames\"  # Changed to include the subfolder\n",
        "output_video = \"annotated_video.mp4\"\n",
        "fps = 30  # Set your original video's FPS\n",
        "\n",
        "# Check if the folder exists\n",
        "if not os.path.exists(image_folder):\n",
        "    print(f\"Error: Folder '{image_folder}' not found. Make sure you have run the object detection and annotation step.\")\n",
        "    exit()\n",
        "\n",
        "# Get all files with .png extension\n",
        "images = sorted([img for img in os.listdir(image_folder) if img.endswith(\".png\")])\n",
        "\n",
        "if not images:\n",
        "    print(f\"Error: No image files found in '{image_folder}'.\")\n",
        "    exit()\n",
        "\n",
        "frame_path = os.path.join(image_folder, images[0])\n",
        "frame = cv2.imread(frame_path)\n",
        "height, width, layers = frame.shape\n",
        "\n",
        "video = cv2.VideoWriter(output_video, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "\n",
        "for image_name in images:\n",
        "    image = cv2.imread(os.path.join(image_folder, image_name))\n",
        "    video.write(image)\n",
        "\n",
        "video.release()\n",
        "print(\"âœ… Annotated video saved as:\", output_video)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4rRskysc31M",
        "outputId": "40d3d365-59b3-4074-8436-6ef6d37bab36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Annotated video saved as: annotated_video.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('annotated_video.mp4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "9PQmYXq5c35j",
        "outputId": "43689223-617a-4f29-ba83-ce93d1e87307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_533feda4-8094-46b6-95a9-ad8bd3f9c2a0\", \"annotated_video.mp4\", 912758)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample Detailed Code: Vehicle Tracking + Counting + Speed Estimation"
      ],
      "metadata": {
        "id": "qxBiFes_fGS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install filterpy\n",
        "!git clone https://github.com/abewley/sort.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNKgsP7zc39r",
        "outputId": "7cc00758-7114-40ea-ec45-eef78d60c5fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting filterpy\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/178.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m122.9/178.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from filterpy) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from filterpy) (1.15.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from filterpy) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->filterpy) (1.17.0)\n",
            "Building wheels for collected packages: filterpy\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110460 sha256=315b5eb2cfdd884bd79799bfd60073fd19cf3cf57bb2b82539754a0a8a68bffb\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/dc/3c/e12983eac132d00f82a20c6cbe7b42ce6e96190ef8fa2d15e1\n",
            "Successfully built filterpy\n",
            "Installing collected packages: filterpy\n",
            "Successfully installed filterpy-1.4.5\n",
            "Cloning into 'sort'...\n",
            "remote: Enumerating objects: 208, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 208 (delta 2), reused 1 (delta 1), pack-reused 203 (from 2)\u001b[K\n",
            "Receiving objects: 100% (208/208), 1.21 MiB | 4.29 MiB/s, done.\n",
            "Resolving deltas: 100% (74/74), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "model = YOLO('yolov8n.pt')  # Change to your trained or custom model if any\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fs_5kS4Fc4Bc",
        "outputId": "ec6085e1-e3a5-44eb-ee3d-21c2e84bf7e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.25M/6.25M [00:00<00:00, 52.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('./sort')\n",
        "\n",
        "# Modify sort.py to use a non-interactive backend\n",
        "sort_file_path = './sort/sort.py'\n",
        "with open(sort_file_path, 'r') as f:\n",
        "    sort_file_content = f.read()\n",
        "\n",
        "# Replace 'TkAgg' with 'Agg'\n",
        "modified_sort_file_content = sort_file_content.replace(\"matplotlib.use('TkAgg')\", \"matplotlib.use('Agg')\")\n",
        "\n",
        "with open(sort_file_path, 'w') as f:\n",
        "    f.write(modified_sort_file_content)\n",
        "\n",
        "from sort import Sort\n",
        "import matplotlib\n",
        "matplotlib.use('Agg') # Use a non-interactive backend\n",
        "\n",
        "tracker = Sort()  # Kalman filter + Hungarian tracking"
      ],
      "metadata": {
        "id": "DP8Tui7Dc4Ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dQG78caJc4XL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a94f2790d41c4b0bb90d9836cfb1bc30",
            "2013989b27bf474fa248b2fe1e769a2b",
            "9d8322d6af5d40fab5e674b09f3eca46",
            "b62563dac000461a973d2b6bb989ca94",
            "820a511b684b4ab795fd330f6b13269a",
            "ea1d795b10e84d85ba00b2eac695c9b5",
            "a90aa6a91f8e4b7a92abcb422221b6f2",
            "ede24ab710b24874931a96012bb30b65",
            "c3f5e25841f34bf78eda2ec0df6d7eaf",
            "909ccdd03f1f4ce5b4bd0d10185e3f3e",
            "560c75fd19034e649f653bb7179ec91d"
          ]
        },
        "id": "157cd9ab",
        "outputId": "5847d069-85ab-4c32-8550-e715f5d0972f"
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "results_list = []\n",
        "\n",
        "# Loop through each frame image\n",
        "image_folder = \"/content/frames\"  # Folder containing extracted frames\n",
        "image_files = sorted([f for f in os.listdir(image_folder) if f.endswith('.png')])\n",
        "\n",
        "for image_file in tqdm(image_files):\n",
        "    image_path = os.path.join(image_folder, image_file)\n",
        "    frame = cv2.imread(image_path)\n",
        "\n",
        "    # Perform object detection using YOLOv8 model\n",
        "    results = model(frame)\n",
        "\n",
        "    # Extract bounding boxes and confidence scores\n",
        "    # YOLOv8 results are in different formats depending on the version and task\n",
        "    # This is a common way to get bounding boxes, adjust if necessary\n",
        "    if results and results[0].boxes:\n",
        "        detections = results[0].boxes.data.cpu().numpy() # xyxy format, includes conf and class\n",
        "        # Filter detections by class if needed (e.g., filter only for cars)\n",
        "        # detections = detections[detections[:, 5] == 2] # assuming class 2 is car\n",
        "\n",
        "        # Convert detections to the format expected by SORT (xmin, ymin, xmax, ymax, score)\n",
        "        if detections.shape[0] > 0:\n",
        "          detections_for_sort = detections[:, :5]\n",
        "        else:\n",
        "          detections_for_sort = np.empty((0, 5))\n",
        "\n",
        "        # Update the tracker with the current frame's detections\n",
        "        track_bbs_ids = tracker.update(detections_for_sort)\n",
        "\n",
        "        # Store results\n",
        "        results_list.append({'frame_id': image_file, 'tracks': track_bbs_ids.tolist()})\n",
        "    else:\n",
        "         results_list.append({'frame_id': image_file, 'tracks': []})\n",
        "\n",
        "\n",
        "print(\"Object detection and tracking complete.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/53 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a94f2790d41c4b0bb90d9836cfb1bc30"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 14 cars, 2 buss, 1 truck, 316.9ms\n",
            "Speed: 15.4ms preprocess, 316.9ms inference, 5.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 18 cars, 1 truck, 300.3ms\n",
            "Speed: 4.3ms preprocess, 300.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 16 cars, 1 truck, 253.2ms\n",
            "Speed: 5.8ms preprocess, 253.2ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 16 cars, 1 truck, 265.2ms\n",
            "Speed: 3.7ms preprocess, 265.2ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 13 cars, 1 truck, 257.6ms\n",
            "Speed: 5.7ms preprocess, 257.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 13 cars, 1 truck, 272.3ms\n",
            "Speed: 3.9ms preprocess, 272.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 16 cars, 2 buss, 1 truck, 270.1ms\n",
            "Speed: 8.8ms preprocess, 270.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 16 cars, 2 buss, 250.7ms\n",
            "Speed: 3.7ms preprocess, 250.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 14 cars, 1 bus, 1 truck, 279.1ms\n",
            "Speed: 3.7ms preprocess, 279.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 13 cars, 1 bus, 244.3ms\n",
            "Speed: 3.8ms preprocess, 244.3ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 15 cars, 1 bus, 263.5ms\n",
            "Speed: 4.7ms preprocess, 263.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 15 cars, 2 buss, 267.0ms\n",
            "Speed: 3.8ms preprocess, 267.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 18 cars, 1 bus, 232.5ms\n",
            "Speed: 4.8ms preprocess, 232.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 16 cars, 1 bus, 156.7ms\n",
            "Speed: 3.6ms preprocess, 156.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 13 cars, 1 bus, 1 truck, 176.2ms\n",
            "Speed: 4.0ms preprocess, 176.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 10 cars, 1 bus, 158.6ms\n",
            "Speed: 3.6ms preprocess, 158.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 14 cars, 1 bus, 161.5ms\n",
            "Speed: 2.8ms preprocess, 161.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 11 cars, 1 bus, 1 truck, 179.7ms\n",
            "Speed: 3.4ms preprocess, 179.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 12 cars, 1 bus, 163.3ms\n",
            "Speed: 4.0ms preprocess, 163.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 16 cars, 1 bus, 175.6ms\n",
            "Speed: 4.0ms preprocess, 175.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 14 cars, 161.8ms\n",
            "Speed: 3.1ms preprocess, 161.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 14 cars, 1 bus, 1 truck, 155.5ms\n",
            "Speed: 3.5ms preprocess, 155.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 13 cars, 1 truck, 154.9ms\n",
            "Speed: 3.6ms preprocess, 154.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 19 cars, 1 truck, 171.7ms\n",
            "Speed: 3.8ms preprocess, 171.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 17 cars, 1 truck, 175.3ms\n",
            "Speed: 3.5ms preprocess, 175.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 17 cars, 1 bus, 1 truck, 154.1ms\n",
            "Speed: 3.6ms preprocess, 154.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 16 cars, 1 bus, 1 truck, 159.6ms\n",
            "Speed: 3.0ms preprocess, 159.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 14 cars, 1 truck, 160.5ms\n",
            "Speed: 4.6ms preprocess, 160.5ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 16 cars, 1 truck, 175.1ms\n",
            "Speed: 3.6ms preprocess, 175.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 17 cars, 1 bus, 1 truck, 167.6ms\n",
            "Speed: 3.6ms preprocess, 167.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 17 cars, 1 bus, 1 truck, 159.5ms\n",
            "Speed: 4.0ms preprocess, 159.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 13 cars, 1 bus, 1 truck, 154.8ms\n",
            "Speed: 3.2ms preprocess, 154.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 17 cars, 1 truck, 153.7ms\n",
            "Speed: 3.6ms preprocess, 153.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 18 cars, 1 bus, 164.1ms\n",
            "Speed: 4.3ms preprocess, 164.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 18 cars, 1 bus, 1 truck, 175.0ms\n",
            "Speed: 3.7ms preprocess, 175.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 14 cars, 1 bus, 2 trucks, 166.3ms\n",
            "Speed: 3.8ms preprocess, 166.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 13 cars, 1 bus, 2 trucks, 184.1ms\n",
            "Speed: 2.9ms preprocess, 184.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 13 cars, 2 buss, 1 truck, 159.6ms\n",
            "Speed: 3.7ms preprocess, 159.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 14 cars, 2 buss, 1 truck, 166.4ms\n",
            "Speed: 3.6ms preprocess, 166.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 14 cars, 1 bus, 168.6ms\n",
            "Speed: 3.8ms preprocess, 168.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 12 cars, 1 bus, 1 truck, 186.8ms\n",
            "Speed: 3.4ms preprocess, 186.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 15 cars, 1 bus, 1 truck, 159.8ms\n",
            "Speed: 4.2ms preprocess, 159.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 15 cars, 1 bus, 2 trucks, 158.1ms\n",
            "Speed: 3.8ms preprocess, 158.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 14 cars, 1 bus, 2 trucks, 154.7ms\n",
            "Speed: 3.2ms preprocess, 154.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 14 cars, 1 bus, 2 trucks, 158.2ms\n",
            "Speed: 3.8ms preprocess, 158.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 11 cars, 1 bus, 2 trucks, 164.8ms\n",
            "Speed: 3.3ms preprocess, 164.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 12 cars, 1 bus, 2 trucks, 162.8ms\n",
            "Speed: 3.5ms preprocess, 162.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 12 cars, 1 bus, 2 trucks, 161.4ms\n",
            "Speed: 3.8ms preprocess, 161.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 9 cars, 1 bus, 2 trucks, 158.9ms\n",
            "Speed: 3.0ms preprocess, 158.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 11 cars, 1 bus, 2 trucks, 162.7ms\n",
            "Speed: 3.8ms preprocess, 162.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 12 cars, 2 trucks, 177.0ms\n",
            "Speed: 3.7ms preprocess, 177.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 17 cars, 1 bus, 192.7ms\n",
            "Speed: 3.7ms preprocess, 192.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 14 cars, 1 bus, 2 trucks, 155.2ms\n",
            "Speed: 3.6ms preprocess, 155.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Object detection and tracking complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c58c7cb2",
        "outputId": "8e1e41e5-260d-41a6-d07f-4a2801dd6721"
      },
      "source": [
        "# Placeholder for speed calculation and visualization\n",
        "# You would add your speed calculation logic here based on the 'results_list'\n",
        "# For visualization, you would iterate through the frames again,\n",
        "# use the 'results_list' to get the bounding boxes and track IDs for each frame,\n",
        "# and draw them on the frames using OpenCV. You can also add speed display.\n",
        "\n",
        "print(\"Next steps: Calculate speeds and visualize the results.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Next steps: Calculate speeds and visualize the results.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "97e0f58283ad419b8e8030bbf89a3b9d",
            "4582d720b99a4395a177a3c3c712b191",
            "33c04499ce174fc39421873ef6e3e83f",
            "b6d3f37476264ac993484d4ad8a1bdd1",
            "6e1cdba2422044cf8f1e643b67ef4d2d",
            "19441a5c28824ad2b542053592c424a2",
            "da6f4b784da9405e9465328e2325408b",
            "5b5e94542dcd4ebeb6378c4076e906d3",
            "9044b43b7a47470aa3cbb8461d6178b4",
            "7f11c7a8feb040a58fa2ce55e518c12d",
            "8d235152e2fc477c9fd0be504d9c212c"
          ]
        },
        "id": "dc21ce51",
        "outputId": "fd4d93f9-d5f3-49e6-e1dd-bfeaa7b95c6f"
      },
      "source": [
        "# Speed calculation logic (example: based on change in bounding box position)\n",
        "# You'll likely need to define a reference point or line in your video\n",
        "# and calibrate distance per pixel to calculate real-world speed.\n",
        "# This is a simplified example.\n",
        "\n",
        "speeds = {} # Dictionary to store speeds for each tracked object ID\n",
        "log = [] # Initialize the log list for tracking data\n",
        "\n",
        "# Assuming a simple scenario where speed is proportional to the change in the bounding box's y-coordinate\n",
        "# You would need to adjust this based on your specific video and needs.\n",
        "# Define a conversion factor from pixels per frame to speed units (e.g., mph, km/h)\n",
        "# This requires knowing the real-world distance represented by a certain number of pixels\n",
        "# and the frame rate of the video.\n",
        "\n",
        "# Example conversion factor (you need to determine this based on your scene)\n",
        "# Let's assume 10 pixels per frame corresponds to 1 unit of speed.\n",
        "# You would need to calibrate this more accurately.\n",
        "pixels_per_frame_to_speed = 1 # Adjust this based on your calibration\n",
        "\n",
        "for frame_index, frame_result in enumerate(results_list): # Added enumerate to get frame_index\n",
        "    frame_id = frame_result['frame_id']\n",
        "    tracks = frame_result['tracks']\n",
        "    frame_count = frame_index + 1 # Use frame_index to get frame number\n",
        "\n",
        "    for track in tracks:\n",
        "        # track is [xmin, ymin, xmax, ymax, track_id]\n",
        "        xmin, ymin, xmax, ymax, track_id = track\n",
        "        center_x = (xmin + xmax) / 2 # Calculate center_x\n",
        "        center_y = (ymin + ymax) / 2\n",
        "\n",
        "        # Append data to log\n",
        "        log.append({\n",
        "            'frame': frame_count,\n",
        "            'track_id': int(track_id), # Convert track_id to integer\n",
        "            'bbox': [xmin, ymin, xmax, ymax],\n",
        "            'cx': center_x,\n",
        "            'cy': center_y,\n",
        "        })\n",
        "\n",
        "\n",
        "        if track_id not in speeds:\n",
        "            speeds[track_id] = {'positions': [(frame_id, center_y)], 'calculated_speed': 0}\n",
        "        else:\n",
        "            speeds[track_id]['positions'].append((frame_id, center_y))\n",
        "\n",
        "            # Simple speed calculation based on the last two positions\n",
        "            if len(speeds[track_id]['positions']) >= 2:\n",
        "                (prev_frame_id, prev_center_y) = speeds[track_id]['positions'][-2]\n",
        "                (current_frame_id, current_center_y) = speeds[track_id]['positions'][-1]\n",
        "\n",
        "                # Calculate vertical movement\n",
        "                delta_y = current_center_y - prev_center_y\n",
        "\n",
        "                # Calculate speed (simplified)\n",
        "                # You'll need to account for the time between frames (using FPS)\n",
        "                # and your pixel-to-real-world distance calibration\n",
        "                speed = abs(delta_y) * pixels_per_frame_to_speed # Simplified calculation\n",
        "\n",
        "                speeds[track_id]['calculated_speed'] = speed\n",
        "\n",
        "# Now, let's visualize the results on the frames\n",
        "output_annotated_folder = \"annotated_video_with_speed\"\n",
        "os.makedirs(output_annotated_folder, exist_ok=True)\n",
        "\n",
        "image_folder = \"/content/frames\"  # Folder containing original extracted frames\n",
        "image_files = sorted([f for f in os.listdir(image_folder) if f.endswith('.png')])\n",
        "\n",
        "for frame_result in tqdm(results_list):\n",
        "    frame_id = frame_result['frame_id']\n",
        "    tracks = frame_result['tracks']\n",
        "    image_path = os.path.join(image_folder, frame_id)\n",
        "    frame = cv2.imread(image_path)\n",
        "\n",
        "    for track in tracks:\n",
        "        xmin, ymin, xmax, ymax, track_id = track\n",
        "        xmin, ymin, xmax, ymax = int(xmin), int(ymin), int(xmax), int(ymax) # Convert to integers\n",
        "\n",
        "        # Draw bounding box\n",
        "        cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2) # Green bounding box\n",
        "\n",
        "        # Display track ID and speed (if available)\n",
        "        display_text = f\"ID: {int(track_id)}\"\n",
        "        if track_id in speeds:\n",
        "            display_text += f\" Speed: {speeds[track_id]['calculated_speed']:.2f}\" # Display calculated speed\n",
        "\n",
        "        cv2.putText(frame, display_text, (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    # Save the annotated frame\n",
        "    annotated_frame_path = os.path.join(output_annotated_folder, frame_id)\n",
        "    cv2.imwrite(annotated_frame_path, frame)\n",
        "\n",
        "print(f\"Annotated frames saved to '{output_annotated_folder}'\")\n",
        "\n",
        "# Create a video from the annotated frames\n",
        "output_video_with_speed = \"annotated_video_with_speed.mp4\"\n",
        "fps = 30  # Set your original video's FPS\n",
        "\n",
        "images = sorted([img for img in os.listdir(output_annotated_folder) if img.endswith(\".png\")])\n",
        "if images:\n",
        "    frame_path = os.path.join(output_annotated_folder, images[0])\n",
        "    frame = cv2.imread(frame_path)\n",
        "    height, width, layers = frame.shape\n",
        "\n",
        "    video = cv2.VideoWriter(output_video_with_speed, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "\n",
        "    for image_name in images:\n",
        "        image = cv2.imread(os.path.join(output_annotated_folder, image_name))\n",
        "        video.write(image)\n",
        "\n",
        "    video.release()\n",
        "    print(\"âœ… Annotated video with speed saved as:\", output_video_with_speed)\n",
        "else:\n",
        "    print(\"No annotated frames found to create video.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/53 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97e0f58283ad419b8e8030bbf89a3b9d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Annotated frames saved to 'annotated_video_with_speed'\n",
            "âœ… Annotated video with speed saved as: annotated_video_with_speed.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "40346a2a",
        "outputId": "a296c5d9-10e6-4000-d4c1-724140affaee"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('annotated_video_with_speed.mp4')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_133f8b8f-c17d-4693-b28d-ac7464991eb2\", \"annotated_video_with_speed.mp4\", 772356)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "traffic-1.avi"
      ],
      "metadata": {
        "id": "lw6VOO23gOKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load the video file - use the correct path\n",
        "video_path = \"/content/drive/MyDrive/Video/traffic-1.avi\" # Corrected video path\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Check if video opened successfully\n",
        "if not cap.isOpened():\n",
        "    print(\"Error: Could not open video.\")\n",
        "    # Consider adding a more robust error handling or exiting\n",
        "    # exit() # Exit might stop the kernel, consider raising an exception or returning\n",
        "\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS)) # Get FPS from the video\n",
        "\n",
        "# Define output video path\n",
        "output_video_path = \"output_tracked.mp4\" # Changed extension to mp4 for better compatibility\n",
        "out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height)) # Use mp4v codec\n",
        "\n",
        "counted_ids = set()\n",
        "# Define a crossing line - adjust coordinates based on your video frame\n",
        "# Example: a horizontal line across the middle of the frame\n",
        "crossing_line_y = frame_height // 2\n",
        "crossing_line = [(0, crossing_line_y), (frame_width, crossing_line_y)]  # horizontal line\n",
        "\n",
        "vehicle_count = 0\n",
        "\n",
        "# Loop through video frames\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break  # No more frames, end of video\n",
        "\n",
        "    # Perform object detection using the loaded YOLOv8 model\n",
        "    # Ensure 'model' is loaded and accessible in this scope\n",
        "    try:\n",
        "      results = model(frame)[0]\n",
        "    except NameError:\n",
        "      print(\"Error: YOLO model 'model' not found. Make sure the cell loading the model has been executed.\")\n",
        "      break # Exit the loop if model is not found\n",
        "\n",
        "    detections = []\n",
        "\n",
        "    # Process detection results\n",
        "    for r in results.boxes:\n",
        "        cls = int(r.cls[0])\n",
        "        # Filter for vehicle classes: car (2), motorcycle (3), bus (5), truck (7) in COCO dataset\n",
        "        if cls in [2, 3, 5, 7]:\n",
        "            x1, y1, x2, y2 = map(int, r.xyxy[0])\n",
        "            conf = float(r.conf[0])\n",
        "            detections.append([x1, y1, x2, y2, conf])\n",
        "\n",
        "    # Update the tracker with current detections\n",
        "    # Ensure 'tracker' is loaded and accessible in this scope\n",
        "    try:\n",
        "        tracks = tracker.update(np.array(detections))\n",
        "    except NameError:\n",
        "        print(\"Error: SORT tracker 'tracker' not found. Make sure the cell initializing the tracker has been executed.\")\n",
        "        break # Exit the loop if tracker is not found\n",
        "\n",
        "\n",
        "    # Process tracked objects\n",
        "    for t in tracks:\n",
        "        x1, y1, x2, y2, track_id = map(int, t)\n",
        "        cx = int((x1 + x2) / 2)\n",
        "        cy = int((y1 + y2) / 2)\n",
        "\n",
        "        # Draw bounding box and track ID on the frame\n",
        "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0,255,0), 2) # Green bounding box\n",
        "        cv2.putText(frame, f'ID:{int(track_id)}', (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2) # Display track ID\n",
        "\n",
        "        # Count vehicle crossing the line\n",
        "        # Check if the track's center has crossed the line and the ID hasn't been counted yet\n",
        "        if track_id not in counted_ids and cy > crossing_line_y - 10 and cy < crossing_line_y + 10: # Added a small buffer around the line\n",
        "            vehicle_count += 1\n",
        "            counted_ids.add(track_id)\n",
        "\n",
        "    # Draw the crossing line on the frame\n",
        "    cv2.line(frame, crossing_line[0], crossing_line[1], (0,0,255), 2) # Red line\n",
        "\n",
        "    # Display the vehicle count on the frame\n",
        "    cv2.putText(frame, f'Count: {vehicle_count}', (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2) # Blue text\n",
        "\n",
        "    # Write the annotated frame to the output video\n",
        "    out.write(frame)\n",
        "\n",
        "# Release video capture and writer objects\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "print(f\"Processing complete. Annotated video saved as '{output_video_path}'.\")\n",
        "print(f\"Total vehicles counted: {vehicle_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oi9vcw3mgM8D",
        "outputId": "605d6609-38b3-4569-ace5-92277640eb8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 14 cars, 2 buss, 1 truck, 258.2ms\n",
            "Speed: 4.4ms preprocess, 258.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 18 cars, 1 truck, 262.7ms\n",
            "Speed: 3.8ms preprocess, 262.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 16 cars, 1 truck, 252.0ms\n",
            "Speed: 4.0ms preprocess, 252.0ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 16 cars, 1 truck, 273.7ms\n",
            "Speed: 3.6ms preprocess, 273.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 13 cars, 1 truck, 259.5ms\n",
            "Speed: 4.0ms preprocess, 259.5ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 13 cars, 1 truck, 247.5ms\n",
            "Speed: 4.3ms preprocess, 247.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 16 cars, 2 buss, 1 truck, 166.9ms\n",
            "Speed: 3.7ms preprocess, 166.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 16 cars, 2 buss, 159.3ms\n",
            "Speed: 3.5ms preprocess, 159.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 14 cars, 1 bus, 1 truck, 188.9ms\n",
            "Speed: 3.6ms preprocess, 188.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 13 cars, 1 bus, 208.4ms\n",
            "Speed: 3.7ms preprocess, 208.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 15 cars, 1 bus, 179.3ms\n",
            "Speed: 3.6ms preprocess, 179.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 15 cars, 2 buss, 162.4ms\n",
            "Speed: 3.8ms preprocess, 162.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 18 cars, 1 bus, 165.8ms\n",
            "Speed: 3.8ms preprocess, 165.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 16 cars, 1 bus, 150.9ms\n",
            "Speed: 3.3ms preprocess, 150.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 13 cars, 1 bus, 1 truck, 180.3ms\n",
            "Speed: 3.3ms preprocess, 180.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 10 cars, 1 bus, 150.0ms\n",
            "Speed: 3.5ms preprocess, 150.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 14 cars, 1 bus, 169.7ms\n",
            "Speed: 3.4ms preprocess, 169.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 11 cars, 1 bus, 1 truck, 147.7ms\n",
            "Speed: 3.4ms preprocess, 147.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 12 cars, 1 bus, 155.8ms\n",
            "Speed: 3.8ms preprocess, 155.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 16 cars, 1 bus, 173.2ms\n",
            "Speed: 3.5ms preprocess, 173.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 14 cars, 147.5ms\n",
            "Speed: 3.5ms preprocess, 147.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 14 cars, 1 bus, 1 truck, 169.5ms\n",
            "Speed: 3.6ms preprocess, 169.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 13 cars, 1 truck, 169.6ms\n",
            "Speed: 3.9ms preprocess, 169.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 19 cars, 1 truck, 152.6ms\n",
            "Speed: 3.7ms preprocess, 152.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 17 cars, 1 truck, 157.5ms\n",
            "Speed: 3.6ms preprocess, 157.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 17 cars, 1 bus, 1 truck, 144.9ms\n",
            "Speed: 3.8ms preprocess, 144.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 16 cars, 1 bus, 1 truck, 184.2ms\n",
            "Speed: 3.4ms preprocess, 184.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 14 cars, 1 truck, 155.7ms\n",
            "Speed: 3.6ms preprocess, 155.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 16 cars, 1 truck, 164.1ms\n",
            "Speed: 6.7ms preprocess, 164.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 17 cars, 1 bus, 1 truck, 161.7ms\n",
            "Speed: 3.6ms preprocess, 161.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 17 cars, 1 bus, 1 truck, 159.4ms\n",
            "Speed: 3.3ms preprocess, 159.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 13 cars, 1 bus, 1 truck, 155.5ms\n",
            "Speed: 3.2ms preprocess, 155.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 17 cars, 1 truck, 160.2ms\n",
            "Speed: 3.3ms preprocess, 160.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 18 cars, 1 bus, 189.4ms\n",
            "Speed: 3.8ms preprocess, 189.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 18 cars, 1 bus, 1 truck, 164.4ms\n",
            "Speed: 4.0ms preprocess, 164.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 14 cars, 1 bus, 2 trucks, 180.4ms\n",
            "Speed: 4.3ms preprocess, 180.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 13 cars, 1 bus, 2 trucks, 162.6ms\n",
            "Speed: 4.7ms preprocess, 162.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 13 cars, 2 buss, 1 truck, 182.8ms\n",
            "Speed: 3.6ms preprocess, 182.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 14 cars, 2 buss, 1 truck, 164.5ms\n",
            "Speed: 3.5ms preprocess, 164.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 14 cars, 1 bus, 171.5ms\n",
            "Speed: 3.5ms preprocess, 171.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 12 cars, 1 bus, 1 truck, 160.5ms\n",
            "Speed: 3.4ms preprocess, 160.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 15 cars, 1 bus, 1 truck, 159.4ms\n",
            "Speed: 3.5ms preprocess, 159.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 15 cars, 1 bus, 2 trucks, 160.4ms\n",
            "Speed: 3.4ms preprocess, 160.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 14 cars, 1 bus, 2 trucks, 161.0ms\n",
            "Speed: 3.4ms preprocess, 161.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 14 cars, 1 bus, 2 trucks, 159.1ms\n",
            "Speed: 3.9ms preprocess, 159.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 11 cars, 1 bus, 2 trucks, 174.2ms\n",
            "Speed: 3.7ms preprocess, 174.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 12 cars, 1 bus, 2 trucks, 186.6ms\n",
            "Speed: 3.7ms preprocess, 186.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 12 cars, 1 bus, 2 trucks, 160.1ms\n",
            "Speed: 3.6ms preprocess, 160.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 9 cars, 1 bus, 2 trucks, 184.2ms\n",
            "Speed: 3.7ms preprocess, 184.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 11 cars, 1 bus, 2 trucks, 173.2ms\n",
            "Speed: 3.5ms preprocess, 173.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 12 cars, 2 trucks, 167.9ms\n",
            "Speed: 3.6ms preprocess, 167.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 17 cars, 1 bus, 159.8ms\n",
            "Speed: 3.4ms preprocess, 159.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 14 cars, 1 bus, 2 trucks, 160.8ms\n",
            "Speed: 3.5ms preprocess, 160.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Processing complete. Annotated video saved as 'output_tracked.mp4'.\n",
            "Total vehicles counted: 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "d40c98d3",
        "outputId": "e205e4f0-6edd-4e98-d1e4-f1443d1817b5"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('output_tracked.mp4')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6bb1e9eb-5fe0-4d33-bc71-74f208f6995a\", \"output_tracked.mp4\", 706123)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log.append({\n",
        "    'frame': frame_count,\n",
        "    'track_id': track_id,\n",
        "    'bbox': [x1, y1, x2, y2],\n",
        "    'cx': cx,\n",
        "    'cy': cy,\n",
        "})\n"
      ],
      "metadata": {
        "id": "Byd02Tk2ioq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(log).to_csv(\"vehicle_log.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "3JEXbdNoiou1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"vehicle_log.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ifvNEnI6ioyE",
        "outputId": "07fe423a-1b28-4745-a71c-951666c19077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_58c558c1-1441-4930-af57-ffe4406bf339\", \"vehicle_log.csv\", 64)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract\n",
        "!apt install tesseract-ocr\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rd6H34DagM_U",
        "outputId": "970c9184-d238-4ea3-c21c-1b153c23658f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.2.1)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "\n",
        "def detect_license_plate(image):\n",
        "    results = model(image)[0]\n",
        "    for r in results.boxes:\n",
        "        cls = int(r.cls[0])\n",
        "        if cls == 2:  # car\n",
        "            x1, y1, x2, y2 = map(int, r.xyxy[0])\n",
        "            vehicle_crop = image[y1:y2, x1:x2]\n",
        "            # Try to locate license plate inside car region\n",
        "            plate_crop = vehicle_crop[0:int(vehicle_crop.shape[0]*0.3), :]  # top region\n",
        "            plate_text = pytesseract.image_to_string(plate_crop)\n",
        "            return plate_text\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "QBrNd82WgNCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print or store the plate numbers per vehicle ID."
      ],
      "metadata": {
        "id": "-RWkWjExjybU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install filterpy pytesseract\n",
        "!apt install tesseract-ocr\n",
        "!git clone https://github.com/abewley/sort.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQdPNVSkgNIz",
        "outputId": "92fdb60b-1e12-41bc-f978-e826e740971e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: filterpy in /usr/local/lib/python3.11/dist-packages (1.4.5)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.11/dist-packages (0.3.13)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from filterpy) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from filterpy) (1.15.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from filterpy) (3.10.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.2.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->filterpy) (1.17.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "fatal: destination path 'sort' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "from ultralytics import YOLO\n",
        "from sort import Sort\n",
        "\n",
        "# Load detection model\n",
        "model = YOLO('yolov8n.pt')  # or your own trained model\n",
        "\n",
        "# Initialize tracker\n",
        "tracker = Sort()\n",
        "\n",
        "# Store plate info\n",
        "plate_dict = {}\n",
        "\n",
        "# Video setup\n",
        "cap = cv2.VideoCapture(\"your_video.mp4\")\n",
        "frame_count = 0\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    frame_count += 1\n",
        "\n",
        "    results = model(frame)[0]\n",
        "    detections = []\n",
        "\n",
        "    for r in results.boxes:\n",
        "        cls = int(r.cls[0])\n",
        "        if cls in [2, 3, 5, 7]:  # Vehicle classes: car, motorcycle, bus, truck\n",
        "            x1, y1, x2, y2 = map(int, r.xyxy[0])\n",
        "            conf = float(r.conf[0])\n",
        "            detections.append([x1, y1, x2, y2, conf])\n",
        "\n",
        "    detections = np.array(detections)\n",
        "    tracks = tracker.update(detections)\n",
        "\n",
        "    for track in tracks:\n",
        "        x1, y1, x2, y2, track_id = map(int, track)\n",
        "        cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
        "\n",
        "        # Crop vehicle region for OCR\n",
        "        vehicle_crop = frame[y1:y2, x1:x2]\n",
        "        if vehicle_crop.size == 0:\n",
        "            continue\n",
        "\n",
        "        # Heuristic: license plate often in bottom-middle of the vehicle\n",
        "        h, w = vehicle_crop.shape[:2]\n",
        "        plate_region = vehicle_crop[int(h*0.6):h, int(w*0.25):int(w*0.75)]\n",
        "\n",
        "        # OCR\n",
        "        plate_text = pytesseract.image_to_string(plate_region, config='--psm 8')\n",
        "        plate_text = plate_text.strip()\n",
        "\n",
        "        # Store plate text for this ID (first time only or if better result)\n",
        "        if plate_text and (track_id not in plate_dict or len(plate_text) > len(plate_dict[track_id])):\n",
        "            plate_dict[track_id] = plate_text\n",
        "\n",
        "        # Draw everything\n",
        "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0,255,0), 2)\n",
        "        cv2.putText(frame, f\"ID:{track_id}\", (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,0), 2)\n",
        "        cv2.putText(frame, f\"Plate:{plate_text}\", (x1, y2+20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2)\n",
        "\n",
        "    # cv2.imshow(\"Plate Detection\", frame) # Removed\n",
        "    # if cv2.waitKey(1) & 0xFF == ord('q'): # Removed\n",
        "    #     break # Removed\n",
        "\n",
        "cap.release()\n",
        "# cv2.destroyAllWindows() # Removed"
      ],
      "metadata": {
        "id": "4iJAvRaCgNL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "plate_df = pd.DataFrame([\n",
        "    {'track_id': k, 'license_plate': v} for k, v in plate_dict.items()\n",
        "])\n",
        "plate_df.to_csv(\"license_plates.csv\", index=False)\n",
        "print(plate_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElgToD8SgNPM",
        "outputId": "e3a993e9-f435-4f6c-f31e-7a1a032cd2e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"license_plates.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "MyBjQL0Xkc5s",
        "outputId": "fdb36d11-4126-434f-8626-4709af0ab8df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_759720d1-84ec-4e99-84ff-a10ac3417b27\", \"license_plates.csv\", 1)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "speed = distance_pixels / time_seconds"
      ],
      "metadata": {
        "id": "bmoG5Yp8lPvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "previous_positions = {}\n",
        "frame_rate = 30  # adjust this\n",
        "pixel_to_meter = 0.05  # approx 20 pixels = 1 meter\n",
        "\n",
        "for t in tracks:\n",
        "    x1, y1, x2, y2, track_id = map(int, t)\n",
        "    cx = int((x1 + x2) / 2)\n",
        "    cy = int((y1 + y2) / 2)\n",
        "\n",
        "    current_time = time.time()\n",
        "    if track_id in previous_positions:\n",
        "        prev_cx, prev_cy, prev_time = previous_positions[track_id]\n",
        "        dt = current_time - prev_time\n",
        "        dist = np.sqrt((cx - prev_cx)**2 + (cy - prev_cy)**2)\n",
        "        speed_mps = (dist * pixel_to_meter) / dt\n",
        "        speed_kmph = speed_mps * 3.6\n",
        "        cv2.putText(frame, f\"Speed: {int(speed_kmph)} km/h\", (x1, y2 + 20),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,0), 2)\n",
        "    previous_positions[track_id] = (cx, cy, current_time)\n",
        "\n"
      ],
      "metadata": {
        "id": "5ii4D8yfkc9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from sort import Sort\n",
        "from ultralytics import YOLO\n",
        "import time\n",
        "\n",
        "# Load YOLO model\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Load tracker\n",
        "tracker = Sort()\n",
        "\n",
        "# Open video\n",
        "# Assuming \"your_video.mp4\" is the correct input video path. If not, please adjust.\n",
        "cap = cv2.VideoCapture(\"/content/drive/MyDrive/Video/traffic-1.avi\") # Using the path from previous successful video loading\n",
        "\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "pixel_to_meter_ratio = 0.05  # adjust based on your camera (e.g., 20 pixels = 1 meter)\n",
        "\n",
        "# Output video\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "# Change codec to mp4v and extension to .mp4\n",
        "out = cv2.VideoWriter(\"speed_output.mp4\", cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
        "\n",
        "# Store previous positions per track_id\n",
        "prev_positions = {}\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Ensure frame is not None before processing\n",
        "    if frame is None:\n",
        "        print(f\"Warning: Received empty frame. Skipping frame.\")\n",
        "        continue\n",
        "\n",
        "    results = model(frame)[0]\n",
        "    detections = []\n",
        "\n",
        "    for r in results.boxes:\n",
        "        cls = int(r.cls[0])\n",
        "        if cls in [2, 3, 5, 7]:  # Vehicle classes only\n",
        "            x1, y1, x2, y2 = map(int, r.xyxy[0])\n",
        "            conf = float(r.conf[0])\n",
        "            detections.append([x1, y1, x2, y2, conf])\n",
        "\n",
        "    tracks = tracker.update(np.array(detections))\n",
        "\n",
        "    current_time = time.time()\n",
        "\n",
        "    for track in tracks:\n",
        "        x1, y1, x2, y2, track_id = map(int, track)\n",
        "        cx = int((x1 + x2) / 2)\n",
        "        cy = int((y1 + y2) / 2)\n",
        "\n",
        "        # Speed estimation\n",
        "        speed_kmph = None\n",
        "        if track_id in prev_positions:\n",
        "            prev_cx, prev_cy, prev_time = prev_positions[track_id]\n",
        "            dx = cx - prev_cx\n",
        "            dy = cy - prev_cy\n",
        "            dist_pixels = np.sqrt(dx**2 + dy**2)\n",
        "            dt = current_time - prev_time\n",
        "\n",
        "            # Avoid division by zero\n",
        "            if dt > 0:\n",
        "                speed_mps = (dist_pixels * pixel_to_meter_ratio) / dt\n",
        "                speed_kmph = speed_mps * 3.6\n",
        "\n",
        "        prev_positions[track_id] = (cx, cy, current_time)\n",
        "\n",
        "        # Draw\n",
        "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0,255,0), 2)\n",
        "        cv2.putText(frame, f\"ID:{int(track_id)}\", (x1, y1-10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,0), 2)\n",
        "\n",
        "        if speed_kmph:\n",
        "            cv2.putText(frame, f\"{speed_kmph:.1f} km/h\", (x1, y2+20),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2)\n",
        "\n",
        "    out.write(frame)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "print(\"Speed estimation video processing complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BjDDh-skdBM",
        "outputId": "5d430105-3a0d-4c9a-e128-8ec123e718ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 14 cars, 2 buss, 1 truck, 321.0ms\n",
            "Speed: 8.7ms preprocess, 321.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 18 cars, 1 truck, 248.0ms\n",
            "Speed: 7.0ms preprocess, 248.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 16 cars, 1 truck, 246.9ms\n",
            "Speed: 7.6ms preprocess, 246.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 16 cars, 1 truck, 258.9ms\n",
            "Speed: 8.3ms preprocess, 258.9ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 13 cars, 1 truck, 242.5ms\n",
            "Speed: 5.7ms preprocess, 242.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 13 cars, 1 truck, 260.8ms\n",
            "Speed: 6.9ms preprocess, 260.8ms inference, 19.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 16 cars, 2 buss, 1 truck, 253.2ms\n",
            "Speed: 6.7ms preprocess, 253.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 16 cars, 2 buss, 250.9ms\n",
            "Speed: 6.3ms preprocess, 250.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 14 cars, 1 bus, 1 truck, 244.6ms\n",
            "Speed: 6.1ms preprocess, 244.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 13 cars, 1 bus, 157.8ms\n",
            "Speed: 6.8ms preprocess, 157.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 15 cars, 1 bus, 155.2ms\n",
            "Speed: 4.8ms preprocess, 155.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 15 cars, 2 buss, 159.4ms\n",
            "Speed: 5.8ms preprocess, 159.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 18 cars, 1 bus, 195.5ms\n",
            "Speed: 5.1ms preprocess, 195.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 16 cars, 1 bus, 160.1ms\n",
            "Speed: 4.7ms preprocess, 160.1ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 13 cars, 1 bus, 1 truck, 156.6ms\n",
            "Speed: 6.2ms preprocess, 156.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 10 cars, 1 bus, 148.7ms\n",
            "Speed: 5.8ms preprocess, 148.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 14 cars, 1 bus, 155.4ms\n",
            "Speed: 5.0ms preprocess, 155.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 11 cars, 1 bus, 1 truck, 150.2ms\n",
            "Speed: 4.9ms preprocess, 150.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 12 cars, 1 bus, 172.0ms\n",
            "Speed: 4.7ms preprocess, 172.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 16 cars, 1 bus, 183.3ms\n",
            "Speed: 5.3ms preprocess, 183.3ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 14 cars, 160.0ms\n",
            "Speed: 4.2ms preprocess, 160.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 14 cars, 1 bus, 1 truck, 154.1ms\n",
            "Speed: 5.6ms preprocess, 154.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 13 cars, 1 truck, 151.5ms\n",
            "Speed: 5.3ms preprocess, 151.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 19 cars, 1 truck, 163.0ms\n",
            "Speed: 5.3ms preprocess, 163.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 17 cars, 1 truck, 156.9ms\n",
            "Speed: 5.5ms preprocess, 156.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 17 cars, 1 bus, 1 truck, 154.9ms\n",
            "Speed: 5.2ms preprocess, 154.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 16 cars, 1 bus, 1 truck, 157.8ms\n",
            "Speed: 5.1ms preprocess, 157.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 14 cars, 1 truck, 160.3ms\n",
            "Speed: 5.3ms preprocess, 160.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 16 cars, 1 truck, 161.3ms\n",
            "Speed: 5.6ms preprocess, 161.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 17 cars, 1 bus, 1 truck, 196.1ms\n",
            "Speed: 6.0ms preprocess, 196.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 17 cars, 1 bus, 1 truck, 161.1ms\n",
            "Speed: 5.7ms preprocess, 161.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 13 cars, 1 bus, 1 truck, 157.1ms\n",
            "Speed: 5.9ms preprocess, 157.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 17 cars, 1 truck, 158.8ms\n",
            "Speed: 5.9ms preprocess, 158.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 18 cars, 1 bus, 159.4ms\n",
            "Speed: 6.7ms preprocess, 159.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 18 cars, 1 bus, 1 truck, 175.9ms\n",
            "Speed: 16.9ms preprocess, 175.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 14 cars, 1 bus, 2 trucks, 165.2ms\n",
            "Speed: 6.8ms preprocess, 165.2ms inference, 13.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 13 cars, 1 bus, 2 trucks, 157.4ms\n",
            "Speed: 5.8ms preprocess, 157.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 13 cars, 2 buss, 1 truck, 160.5ms\n",
            "Speed: 6.2ms preprocess, 160.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 14 cars, 2 buss, 1 truck, 163.1ms\n",
            "Speed: 6.1ms preprocess, 163.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 14 cars, 1 bus, 165.1ms\n",
            "Speed: 6.9ms preprocess, 165.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 12 cars, 1 bus, 1 truck, 201.5ms\n",
            "Speed: 6.0ms preprocess, 201.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 15 cars, 1 bus, 1 truck, 154.1ms\n",
            "Speed: 6.2ms preprocess, 154.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 15 cars, 1 bus, 2 trucks, 154.9ms\n",
            "Speed: 5.7ms preprocess, 154.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 14 cars, 1 bus, 2 trucks, 157.7ms\n",
            "Speed: 6.1ms preprocess, 157.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 14 cars, 1 bus, 2 trucks, 153.2ms\n",
            "Speed: 5.5ms preprocess, 153.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 11 cars, 1 bus, 2 trucks, 156.8ms\n",
            "Speed: 5.4ms preprocess, 156.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 12 cars, 1 bus, 2 trucks, 175.4ms\n",
            "Speed: 5.6ms preprocess, 175.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 12 cars, 1 bus, 2 trucks, 156.7ms\n",
            "Speed: 5.4ms preprocess, 156.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 9 cars, 1 bus, 2 trucks, 159.1ms\n",
            "Speed: 5.4ms preprocess, 159.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 11 cars, 1 bus, 2 trucks, 180.9ms\n",
            "Speed: 6.7ms preprocess, 180.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 12 cars, 2 trucks, 163.1ms\n",
            "Speed: 6.5ms preprocess, 163.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 17 cars, 1 bus, 195.0ms\n",
            "Speed: 5.5ms preprocess, 195.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 14 cars, 1 bus, 2 trucks, 158.5ms\n",
            "Speed: 5.6ms preprocess, 158.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Speed estimation video processing complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7500237",
        "outputId": "69d958b0-2482-4c1b-fffe-de03ab309123"
      },
      "source": [
        "import os\n",
        "\n",
        "# List files in the current directory\n",
        "print(os.listdir())\n",
        "\n",
        "# Check if the file exists and its size\n",
        "file_path = \"speed_output.avi\"\n",
        "if os.path.exists(file_path):\n",
        "    file_size = os.path.getsize(file_path)\n",
        "    print(f\"File '{file_path}' found with size: {file_size} bytes\")\n",
        "else:\n",
        "    print(f\"File '{file_path}' not found.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['models', 'CONTRIBUTING.md', 'README.md', 'val.py', 'data', 'segment', 'tutorial.ipynb', '.gitignore', 'output_tracked.mp4', 'hubconf.py', 'detect.py', '.github', '.git', 'CITATION.cff', 'classify', 'utils', '.gitattributes', 'yolov5s.pt', 'pyproject.toml', 'README.zh-CN.md', '__pycache__', 'yolov8n.pt', 'benchmarks.py', 'train.py', 'license_plates.csv', 'annotated_video.mp4', 'export.py', 'annotated_video_with_speed.mp4', 'vehicle_log.csv', 'annotated_video_with_speed', 'sort', 'requirements.txt', 'LICENSE', '.dockerignore']\n",
            "File 'speed_output.avi' not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "9cb73e18",
        "outputId": "0b1a9778-6127-4dd1-eec7-0b00b1ebcd00"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"speed_output.mp4\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_218da453-87ba-4598-9920-e244a4b05c68\", \"speed_output.mp4\", 1076153)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "speed_log = []\n",
        "\n",
        "# Inside the loop\n",
        "if speed_kmph:\n",
        "    speed_log.append({\n",
        "        'track_id': int(track_id),\n",
        "        'speed_kmph': speed_kmph,\n",
        "        'frame': int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
        "    })\n",
        "\n",
        "# After the loop\n",
        "import pandas as pd\n",
        "df_speed = pd.DataFrame(speed_log)\n",
        "df_speed.to_csv(\"vehicle_speeds.csv\", index=False)\n",
        "\n",
        "# For download from Colab\n",
        "from google.colab import files\n",
        "files.download(\"vehicle_speeds.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Ws7dl15bkdE1",
        "outputId": "fc32a8fe-7d25-4ab1-ed63-06011b703c71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c3a61db9-4b90-4b31-a4db-beb0eabd2528\", \"vehicle_speeds.csv\", 51)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "from ultralytics import YOLO\n",
        "from sort import Sort\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize model and tracker\n",
        "model = YOLO('yolov8n.pt')  # Or your fine-tuned vehicle model\n",
        "tracker = Sort()\n",
        "\n",
        "# Open video\n",
        "cap = cv2.VideoCapture(\"your_video.mp4\")\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "pixel_to_meter_ratio = 0.05  # Estimate: 20 pixels â‰ˆ 1 meter\n",
        "\n",
        "# For logging\n",
        "prev_positions = {}\n",
        "behavior_log = []\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    results = model(frame)[0]\n",
        "    detections = []\n",
        "\n",
        "    for r in results.boxes:\n",
        "        cls = int(r.cls[0])\n",
        "        if cls in [2, 3, 5, 7]:  # Car, motorbike, bus, truck\n",
        "            x1, y1, x2, y2 = map(int, r.xyxy[0])\n",
        "            conf = float(r.conf[0])\n",
        "            detections.append([x1, y1, x2, y2, conf])\n",
        "\n",
        "    tracks = tracker.update(np.array(detections))\n",
        "    current_time = time.time()\n",
        "\n",
        "    for track in tracks:\n",
        "        x1, y1, x2, y2, track_id = map(int, track)\n",
        "        cx = int((x1 + x2) / 2)\n",
        "        cy = int((y1 + y2) / 2)\n",
        "\n",
        "        speed_kmph = None\n",
        "        behavior = \"Unknown\"\n",
        "\n",
        "        if track_id in prev_positions:\n",
        "            prev_cx, prev_cy, prev_time = prev_positions[track_id]\n",
        "            dx = cx - prev_cx\n",
        "            dy = cy - prev_cy\n",
        "            dt = current_time - prev_time\n",
        "\n",
        "            dist_pixels = np.sqrt(dx**2 + dy**2)\n",
        "            if dt > 0:\n",
        "                speed_mps = (dist_pixels * pixel_to_meter_ratio) / dt\n",
        "                speed_kmph = speed_mps * 3.6\n",
        "\n",
        "                # Classify behavior\n",
        "                if speed_kmph < 5:\n",
        "                    behavior = \"Stopped\"\n",
        "                elif speed_kmph > 50:\n",
        "                    behavior = \"Overspeeding\"\n",
        "                else:\n",
        "                    behavior = \"Moving\"\n",
        "\n",
        "        prev_positions[track_id] = (cx, cy, current_time)\n",
        "\n",
        "        # Annotate on frame\n",
        "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0,255,0), 2)\n",
        "        cv2.putText(frame, f'ID:{int(track_id)}', (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,0), 2)\n",
        "        if speed_kmph:\n",
        "            cv2.putText(frame, f\"{speed_kmph:.1f} km/h\", (x1, y2 + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2)\n",
        "            cv2.putText(frame, f\"{behavior}\", (x1, y2 + 40), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2)\n",
        "\n",
        "            # Log behavior\n",
        "            behavior_log.append({\n",
        "                'frame': int(cap.get(cv2.CAP_PROP_POS_FRAMES)),\n",
        "                'track_id': int(track_id),\n",
        "                'speed_kmph': speed_kmph,\n",
        "                'behavior': behavior,\n",
        "                'cx': cx,\n",
        "                'cy': cy\n",
        "            })\n",
        "\n",
        "    # cv2.imshow(\"Behavior Classification\", frame) # Removed\n",
        "    # if cv2.waitKey(1) & 0xFF == ord('q'): # Removed\n",
        "    #     break # Removed\n",
        "\n",
        "cap.release()\n",
        "# cv2.destroyAllWindows() # Removed"
      ],
      "metadata": {
        "id": "s-HEl7vGkdIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_behavior = pd.DataFrame(behavior_log)\n",
        "df_behavior.to_csv(\"vehicle_behavior_log.csv\", index=False)\n",
        "\n",
        "# Download from Colab\n",
        "from google.colab import files\n",
        "files.download(\"vehicle_behavior_log.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "LGyAOKU6kdbk",
        "outputId": "80b2aaa0-b0df-446d-83c6-6ad62b54d610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d2371943-5e16-4bbd-b6c4-ceda0f206c4d\", \"vehicle_behavior_log.csv\", 1)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_S-fYzbNnYqV",
        "outputId": "5cb0c06b-c20d-454b-d59e-366990b6625b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.46.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.0)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.43.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.6.15)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.25.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.46.0-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.46.0 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "st.title(\"Vehicle Analytics Dashboard\")\n",
        "\n",
        "# Assuming vehicle_log.csv contains the log data with track_id and frame\n",
        "df_log = pd.read_csv(\"vehicle_log.csv\")\n",
        "\n",
        "# Assuming vehicle_speeds.csv contains the speed data with track_id and speed_kmph\n",
        "# If you want to use behavior data, change this to \"vehicle_behavior_log.csv\" and adjust column names\n",
        "try:\n",
        "    df_speed = pd.read_csv(\"vehicle_speeds.csv\")\n",
        "except FileNotFoundError:\n",
        "    st.error(\"vehicle_speeds.csv not found. Please ensure speed calculation and logging were successful.\")\n",
        "    df_speed = pd.DataFrame() # Create an empty DataFrame to prevent further errors\n",
        "\n",
        "if not df_log.empty:\n",
        "    st.metric(\"Total Vehicles\", len(df_log['track_id'].unique()))\n",
        "    st.metric(\"Frames Processed\", df_log['frame'].nunique())\n",
        "else:\n",
        "    st.info(\"No tracking data found in vehicle_log.csv.\")\n",
        "\n",
        "\n",
        "if not df_speed.empty and 'speed_kmph' in df_speed.columns:\n",
        "    st.subheader(\"Speed Distribution\")\n",
        "    # Use the correct DataFrame and column name for speed\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.hist(df_speed['speed_kmph'], bins=20, color='skyblue')\n",
        "    ax.set_xlabel(\"Speed (km/h)\")\n",
        "    ax.set_ylabel(\"Frequency\")\n",
        "    ax.set_title(\"Distribution of Vehicle Speeds\")\n",
        "    st.pyplot(fig)\n",
        "else:\n",
        "    st.info(\"No speed data found in vehicle_speeds.csv to plot distribution.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JRMmybJnYu1",
        "outputId": "82632dd4-4151-4ac8-8801-2b38b0e59372"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-06-25 15:06:29.760 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-25 15:06:29.768 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-25 15:06:29.769 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-25 15:06:29.777 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-25 15:06:29.781 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-25 15:06:29.782 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-25 15:06:29.784 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-25 15:06:29.785 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-25 15:06:29.786 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-25 15:06:29.788 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-25 15:06:29.789 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-25 15:06:29.790 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-25 15:06:29.892 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-25 15:06:30.213 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-25 15:06:30.214 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-25 15:06:30.215 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit pandas matplotlib seaborn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YSHI7jwnY2N",
        "outputId": "9059a543-494c-43af-dde5-ac46e9fc5ea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.46.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.43.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.6.15)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.25.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "st.set_page_config(page_title=\"Vehicle Analytics Dashboard\", layout=\"wide\")\n",
        "st.title(\"ğŸš— Vehicle Detection & Behavior Dashboard\")\n",
        "\n",
        "# Upload or load CSV\n",
        "uploaded_file = st.file_uploader(\"Upload Behavior Log CSV\", type=['csv'])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    df = pd.read_csv(uploaded_file)\n",
        "\n",
        "    # --- Summary Statistics ---\n",
        "    st.subheader(\"ğŸ”¢ Summary Statistics\")\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "    col1.metric(\"Unique Vehicles\", df['track_id'].nunique())\n",
        "    col2.metric(\"Total Frames\", df['frame'].nunique())\n",
        "    col3.metric(\"Avg Speed (km/h)\", f\"{df['speed_kmph'].mean():.2f}\")\n",
        "\n",
        "    # --- Speed Distribution ---\n",
        "    st.subheader(\"ğŸ“Š Speed Distribution\")\n",
        "    fig1, ax1 = plt.subplots()\n",
        "    sns.histplot(df['speed_kmph'], bins=20, kde=True, ax=ax1, color=\"skyblue\")\n",
        "    ax1.set_xlabel(\"Speed (km/h)\")\n",
        "    ax1.set_ylabel(\"Frequency\")\n",
        "    st.pyplot(fig1)\n",
        "\n",
        "    # --- Behavior Breakdown ---\n",
        "    st.subheader(\"ğŸ§  Behavior Distribution\")\n",
        "    behavior_counts = df['behavior'].value_counts()\n",
        "    fig2, ax2 = plt.subplots()\n",
        "    ax2.pie(behavior_counts, labels=behavior_counts.index, autopct='%1.1f%%', startangle=140)\n",
        "    ax2.axis('equal')\n",
        "    st.pyplot(fig2)\n",
        "\n",
        "    # --- Table View ---\n",
        "    st.subheader(\"ğŸ“‹ Behavior Log Table\")\n",
        "    st.dataframe(df.sort_values(by=\"frame\"))\n",
        "\n",
        "else:\n",
        "    st.info(\"ğŸ‘† Upload your `vehicle_behavior_log.csv` file to begin.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrLOaX4hnY6F",
        "outputId": "8fcf512a-057d-42bc-890f-9dadb585222d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-06-25 15:09:46.174 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-25 15:09:46.190 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-25 15:09:46.192 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-25 15:09:46.193 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-25 15:09:46.194 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-25 15:09:46.197 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-25 15:09:46.197 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-25 15:09:46.198 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-25 15:09:46.213 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-25 15:09:46.214 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-25 15:09:46.217 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-25 15:09:46.218 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-25 15:09:46.220 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py # Note: Running interactive Streamlit dashboards directly in Colab may require additional setup (e.g., ngrok) to access the web interface."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXZ-k2b2nY9o",
        "outputId": "9f33604f-8214-44b8-9356-3b77f6cb3ed0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usage: streamlit run [OPTIONS] TARGET [ARGS]...\n",
            "Try 'streamlit run --help' for help.\n",
            "\n",
            "Error: Invalid value: File does not exist: app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lvAVFx72nZA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yIaAeV8Rkdez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "500d1b09",
        "outputId": "acae25fd-0b21-4cd0-a23e-774e777c3f24"
      },
      "source": [
        "# Save the content of cell BrLOaX4hnY6F to app.py\n",
        "app_py_content = \"\"\"\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "st.set_page_config(page_title=\"Vehicle Analytics Dashboard\", layout=\"wide\")\n",
        "st.title(\"ğŸš— Vehicle Detection & Behavior Dashboard\")\n",
        "\n",
        "# Upload or load CSV\n",
        "uploaded_file = st.file_uploader(\"Upload Behavior Log CSV\", type=['csv'])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    df = pd.read_csv(uploaded_file)\n",
        "\n",
        "    # --- Summary Statistics ---\n",
        "    st.subheader(\"ğŸ”¢ Summary Statistics\")\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "    col1.metric(\"Unique Vehicles\", df['track_id'].nunique())\n",
        "    col2.metric(\"Total Frames\", df['frame'].nunique())\n",
        "    col3.metric(\"Avg Speed (km/h)\", f\"{df['speed_kmph'].mean():.2f}\")\n",
        "\n",
        "    # --- Speed Distribution ---\n",
        "    st.subheader(\"ğŸ“Š Speed Distribution\")\n",
        "    fig1, ax1 = plt.subplots()\n",
        "    sns.histplot(df['speed_kmph'], bins=20, kde=True, ax=ax1, color=\"skyblue\")\n",
        "    ax1.set_xlabel(\"Speed (km/h)\")\n",
        "    ax1.set_ylabel(\"Frequency\")\n",
        "    st.pyplot(fig1)\n",
        "\n",
        "    # --- Behavior Breakdown ---\n",
        "    st.subheader(\"ğŸ§  Behavior Distribution\")\n",
        "    behavior_counts = df['behavior'].value_counts()\n",
        "    fig2, ax2 = plt.subplots()\n",
        "    ax2.pie(behavior_counts, labels=behavior_counts.index, autopct='%1.1f%%', startangle=140)\n",
        "    ax2.axis('equal')\n",
        "    st.pyplot(fig2)\n",
        "\n",
        "    # --- Table View ---\n",
        "    st.subheader(\"ğŸ“‹ Behavior Log Table\")\n",
        "    st.dataframe(df.sort_values(by=\"frame\"))\n",
        "\n",
        "else:\n",
        "    st.info(\"ğŸ‘† Upload your `vehicle_behavior_log.csv` file to begin.\")\n",
        "\"\"\"\n",
        "\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(app_py_content)\n",
        "\n",
        "print(\"app.py created successfully.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "app.py created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDFdH3S9qKX1",
        "outputId": "885e80b7-093a-477b-e2a6-a68a93519ccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.106.180.18:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLc7PNk5CJ6E7HFF/Fvmgo",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a94f2790d41c4b0bb90d9836cfb1bc30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2013989b27bf474fa248b2fe1e769a2b",
              "IPY_MODEL_9d8322d6af5d40fab5e674b09f3eca46",
              "IPY_MODEL_b62563dac000461a973d2b6bb989ca94"
            ],
            "layout": "IPY_MODEL_820a511b684b4ab795fd330f6b13269a"
          }
        },
        "2013989b27bf474fa248b2fe1e769a2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea1d795b10e84d85ba00b2eac695c9b5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a90aa6a91f8e4b7a92abcb422221b6f2",
            "value": "100%"
          }
        },
        "9d8322d6af5d40fab5e674b09f3eca46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ede24ab710b24874931a96012bb30b65",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3f5e25841f34bf78eda2ec0df6d7eaf",
            "value": 53
          }
        },
        "b62563dac000461a973d2b6bb989ca94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_909ccdd03f1f4ce5b4bd0d10185e3f3e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_560c75fd19034e649f653bb7179ec91d",
            "value": "â€‡53/53â€‡[00:13&lt;00:00,â€‡â€‡5.30it/s]"
          }
        },
        "820a511b684b4ab795fd330f6b13269a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea1d795b10e84d85ba00b2eac695c9b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a90aa6a91f8e4b7a92abcb422221b6f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ede24ab710b24874931a96012bb30b65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3f5e25841f34bf78eda2ec0df6d7eaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "909ccdd03f1f4ce5b4bd0d10185e3f3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "560c75fd19034e649f653bb7179ec91d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97e0f58283ad419b8e8030bbf89a3b9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4582d720b99a4395a177a3c3c712b191",
              "IPY_MODEL_33c04499ce174fc39421873ef6e3e83f",
              "IPY_MODEL_b6d3f37476264ac993484d4ad8a1bdd1"
            ],
            "layout": "IPY_MODEL_6e1cdba2422044cf8f1e643b67ef4d2d"
          }
        },
        "4582d720b99a4395a177a3c3c712b191": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19441a5c28824ad2b542053592c424a2",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_da6f4b784da9405e9465328e2325408b",
            "value": "100%"
          }
        },
        "33c04499ce174fc39421873ef6e3e83f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b5e94542dcd4ebeb6378c4076e906d3",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9044b43b7a47470aa3cbb8461d6178b4",
            "value": 53
          }
        },
        "b6d3f37476264ac993484d4ad8a1bdd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f11c7a8feb040a58fa2ce55e518c12d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8d235152e2fc477c9fd0be504d9c212c",
            "value": "â€‡53/53â€‡[00:00&lt;00:00,â€‡96.50it/s]"
          }
        },
        "6e1cdba2422044cf8f1e643b67ef4d2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19441a5c28824ad2b542053592c424a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da6f4b784da9405e9465328e2325408b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b5e94542dcd4ebeb6378c4076e906d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9044b43b7a47470aa3cbb8461d6178b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f11c7a8feb040a58fa2ce55e518c12d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d235152e2fc477c9fd0be504d9c212c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}